[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "Welcome to Si Min’s ISSS626 Geospatial Analytics and Applications website!\nPlease find below the latest updates:\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1B\n\n\n17 min\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1A\n\n\n74 min\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5B\n\n\n22 min\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to Si Min’s ISSS626 Geospatial Analytics and Applications website!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating and processing geographically referenced datasets. In this hands-on exercise, I will perform geospatial data science tasks in R using the sf package and acquire the following competencies:\n\ninstall and load sf and tidyverse packages into the R environment\nimport geospatial data using appropriate functions of sf package\nimport aspatial data by using appropriate function of readr package\nexplore the content of simple feature data frame by using appropriate Base R and sf functions\nassign or transform coordinate systems by using appropriate sf functions\nconvert aspatial data into a sf dataframe by using appropriate functions of the sf package\nperform geoprocessing tasks using appropriate functions of sf package\nperform data wrangling tasks by using appropriate functions of dplyr package\nperform exploratory data analysis (EDA) using appropriate functions from ggplot2 package\n\n\n\n\nThe following datasets were downloaded:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\n\n\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data. tidyverse consists of a family of R packages and the following within the family will be used in this exercise\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,tidyverse)\n\n\n\n\n\nWe will import the following geospatial data using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\nNo extension such as .shp,.dbf,.prj and .shx are needed.\n\nmpsz = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe following will be shown after running the code chunk above:\n\n\nIt reveals that the geospatial objects are multipolygon features.\nThere are a total of 323 features and 15 fields in the mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems.\nThe bounding box provides the x extent and y extent of the data.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import import CyclingPath shapefile as a line feature data frame.\n\ncyclingpath = st_read(dsn=\"data/geospatial\",layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe following will be shown after running the code chunk above:\n\n\nIt reveals that the geospatial objects are multiline string features.\nThere are a total of 3138 features and 2 fields in the cyclingpath linestring feature data frame.\ncyclingpath is in svy21 projected coordinates systems.\n\n\n\n\nThe code chunk below is used to import the PreSchoolsLocation data which is in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating and processing geographically referenced datasets. In this hands-on exercise, I will perform geospatial data science tasks in R using the sf package and acquire the following competencies:\n\ninstall and load sf and tidyverse packages into the R environment\nimport geospatial data using appropriate functions of sf package\nimport aspatial data by using appropriate function of readr package\nexplore the content of simple feature data frame by using appropriate Base R and sf functions\nassign or transform coordinate systems by using appropriate sf functions\nconvert aspatial data into a sf dataframe by using appropriate functions of the sf package\nperform geoprocessing tasks using appropriate functions of sf package\nperform data wrangling tasks by using appropriate functions of dplyr package\nperform exploratory data analysis (EDA) using appropriate functions from ggplot2 package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-acquisition",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The following datasets were downloaded:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "sf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data. tidyverse consists of a family of R packages and the following within the family will be used in this exercise\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "We will import the following geospatial data using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\nNo extension such as .shp,.dbf,.prj and .shx are needed.\n\nmpsz = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe following will be shown after running the code chunk above:\n\n\nIt reveals that the geospatial objects are multipolygon features.\nThere are a total of 323 features and 15 fields in the mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems.\nThe bounding box provides the x extent and y extent of the data.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import import CyclingPath shapefile as a line feature data frame.\n\ncyclingpath = st_read(dsn=\"data/geospatial\",layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe following will be shown after running the code chunk above:\n\n\nIt reveals that the geospatial objects are multiline string features.\nThere are a total of 3138 features and 2 fields in the cyclingpath linestring feature data frame.\ncyclingpath is in svy21 projected coordinates systems.\n\n\n\n\nThe code chunk below is used to import the PreSchoolsLocation data which is in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating and processing geographically referenced datasets. In this hands-on exercise, I will perform geospatial data science tasks in R using the sf package and acquire the following competencies:\n\ninstall and load sf and tidyverse packages into the R environment\nimport geospatial data using appropriate functions of sf package\nimport aspatial data by using appropriate function of readr package\nexplore the content of simple feature data frame by using appropriate Base R and sf functions\nassign or transform coordinate systems by using appropriate sf functions\nconvert aspatial data into a sf dataframe by using appropriate functions of the sf package\nperform geoprocessing tasks using appropriate functions of sf package\nperform data wrangling tasks by using appropriate functions of dplyr package\nperform exploratory data analysis (EDA) using appropriate functions from ggplot2 package\n\n\n\n\nThe following datasets were downloaded:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\n\n\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data. tidyverse consists of a family of R packages and the following within the family will be used in this exercise\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,tidyverse)\n\n\n\n\n\nWe will import the following geospatial data using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\nNo extension such as .shp,.dbf,.prj and .shx are needed.\n\nmpsz = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multipolygon features.\nThere are a total of 323 features and 15 fields in the mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems.\nThe bounding box provides the x extent and y extent of the data.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import import CyclingPath shapefile as a line feature data frame.\n\ncyclingpath = st_read(dsn=\"data/geospatial\",layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multiline string features.\nThere are a total of 3138 features and 2 fields in the cyclingpath linestring feature data frame.\ncyclingpath is in svy21 projected coordinates systems.\n\n\n\n\nThe code chunk below is used to import the PreSchoolsLocation data which is in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nIt reveals that preschool is a point feature data frame.\nThere are a total of 2290 features and 2 fields.\nUnlike the previous two simple feature data frames, preschool is in a wgs84 coordinates system.\n\n\n\n\n\nIn this subsection, I will utilise different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data frame that contains the geometries is a list, of class sfc - the geometry list-column can be retrieved using:\n\nmpsz$geom or\nmpsz[[1]]\n\nbut more general way uses st_geometry():\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThe print only displays basic information of the feature class such as type of geometry, geographic extent of the features and the coordinate system of the data.\n\n\n\nTo learn more about the associated attribute information in the data frame, we can use glimpse() of dplyr:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe report reveals the data type of each field. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nTo reveal the complete information of a feature object, we use head()of Base R:\n\nhead(mpsz,n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nWe can change the number in the n argument to reflect different number of records.\n\n\n\n\nIn geospatial data science, we need to visualise the geospatial features, beyond just looking at the feature information.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multiplot of all attributes, up to a reasonable maximum number, as shown above. However, we can choose to plot only the geometry:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute:\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote: plot() is meant to plot the geospatial object for a quick look. For high quality cartographic plot, other R packages such as tmap should be used.\n\n\n\n\n\nMap projection is an important property of a geospatial data. To perform geoprocessing using two geospatial data, there is a need to ensure that both geospatial data are projected using a similar coordinate system.\nThe process of projecting a simple feature data frame from one coordinate system to another coordinate system is called projection transformation.\n\n\nOne common issue that can happen when importing geospatial data is either the coordinate system of the source data is missing or wrongly assigned during the importing process.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the mpsz data frame is projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to the mpsz data frame, st_set_crs() of sf package is used:\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nWe then check whether the EPSG code has been corrected:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is common to transform the original data from one geographic coordinate system to a projected coordinated system. This is because a geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThe print indicates that preschool is in wgs84 coordinate system.\nThis is a scenario for which st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathematically but st_crs() : replacing crs does not reproject data.\nThe projection transformation is performed as follows:\n\npreschool3414 &lt;- st_transform(preschool,crs=3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\n\nDisplaying the content of preschool3414 data frame\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\npreschool3414 is in svy21 projected coordinate system now. Further, as seen from the bounding box, the values are greater than 0 to 360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\n\nAspatial data are non-geospatial data that have data fields that are able to capture the x- and y-coordinate of data points.\nAspatial data can be imported into a R environment, saved as a tibble data frame and further converted into a simple feature data frame.\n\n\nThe listings dataset is in csv format hence the read_csv() function of readr package is used:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nThe output is called a tibble data frame.\nTo examine if the data file has been imported properly, list() of Base R is used instead of glimpse:\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output indicates that the tibble dataframe consists of 3.540 rows and 18 columns. Two useful fields used in next phase are latitude and longitude, which are in decimal degree format. As a guess, it is assumed that the data is in wgs84 geographic coordinate system.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame using st_as_sf() of sf package:\n\nlistings_sf &lt;- st_as_sf(listings,coords=c(\"longitude\",\"latitude\"),crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nLearning points from above:\n\ncoords argument requires the column name of the x-coordinates first followed by the column name of y-coordinates\ncrs argument requires the coordinate system in EPSG format - EPSG 4326 is wgs84 geographic coordinate system while EPSG 3414 is the Singapore svy21 projected coordinate system. Other countries’ EPSG code can be found via EPSG website.\n%&gt;% is used to nest the st_transform() to transform the newly created simple feature data frame into a svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nNote that a new column called geometry has been added into the data frame while the longitude and latitude columns have been dropped from the data frame.\n\n\n\n\nBesides providing functions to handle (i.e. importing, exporting, assigning projection, transforming projection) geospatial data, sf package also offers geoprocessing functions.\nTwo commonly used geoprocessing functions are bufferingand point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. The task is to determine the extent of land that needs to be acquired and the total area.\nThe solution:\nFirst, the st_buffer() of sf package is used to compute the 5-meters buffer around the cycling path:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,dist=5,nQuadSegs = 30)\n\nThe area of the buffers is calculated:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, the sum() of Base R will be used to derive the total land involved:\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission accomplished!\n\n\n\nThe scenario:\nA preschool service group wants to find out the number of preschools in each planning subzone.\nThe solution:\nThe code chunk below performs 2 operations at 1 go:\n(1) Identify preschools located inside each planning subzone using st_intersects()\n(2) length() of Base R is used to calculate the number of preschools that fall inside each planning subzone\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414,preschool3414))\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: st_intersects()should not be confused with st_intersection().\nTo also note that the symbol is ` rather than ’.\n\n\nThe summary statistics of the newly derived PreSch Count field can be shown with the code below:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning zone with the most number of preschools, the top_n() of dplyr package is used as shown in the code chunk below:\n\ntop_n(mpsz3414, 1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nTo calculate the density of preschools by planning zone:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below:\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, appropriate ggplot2 functions will be used to create functional and yet truthful statistical graphs for EDA purposes.\nA histogram is plotted to reveal the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nHowever, the output does not meet publication quality and there is limited room for further customisation using this function. As such, we use ggplot2 functions instead:\n\nggplot(data = mpsz3414,\n       aes(x=as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20,\n                 color='black',\n                 fill='pink')+\n  labs(title=\"Are preschools evenly distributed in Singapore?\",\n       subtitle=\"There are many planning subzones with a single preschool. However, there are two planning subzones with at least 20 preschools.\",\n       x=\"Preschool density (per km sq)\",\n       y=\"Frequency\")\n\n\n\n\n\n\n\n\nA scatterplot is plotted to show the relationship between PreSch Density and PreSch Count:\n\nggplot(data= mpsz3414,\n       aes(y=`PreSch Count`,\n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\")+\n  xlim(0,40)+\n  ylim(0,40)+\n  labs(title=\"Preschool count vs Preschool density\",\n       x=\"Preschool density(per km sq)\",\n       y=\"Preschool count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#learning-outcomes",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating and processing geographically referenced datasets. In this hands-on exercise, I will perform geospatial data science tasks in R using the sf package and acquire the following competencies:\n\ninstall and load sf and tidyverse packages into the R environment\nimport geospatial data using appropriate functions of sf package\nimport aspatial data by using appropriate function of readr package\nexplore the content of simple feature data frame by using appropriate Base R and sf functions\nassign or transform coordinate systems by using appropriate sf functions\nconvert aspatial data into a sf dataframe by using appropriate functions of the sf package\nperform geoprocessing tasks using appropriate functions of sf package\nperform data wrangling tasks by using appropriate functions of dplyr package\nperform exploratory data analysis (EDA) using appropriate functions from ggplot2 package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#data-acquisition",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "The following datasets were downloaded:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#getting-started",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "sf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data. tidyverse consists of a family of R packages and the following within the family will be used in this exercise\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "We will import the following geospatial data using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\nNo extension such as .shp,.dbf,.prj and .shx are needed.\n\nmpsz = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multipolygon features.\nThere are a total of 323 features and 15 fields in the mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems.\nThe bounding box provides the x extent and y extent of the data.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import import CyclingPath shapefile as a line feature data frame.\n\ncyclingpath = st_read(dsn=\"data/geospatial\",layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multiline string features.\nThere are a total of 3138 features and 2 fields in the cyclingpath linestring feature data frame.\ncyclingpath is in svy21 projected coordinates systems.\n\n\n\n\nThe code chunk below is used to import the PreSchoolsLocation data which is in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nIt reveals that preschool is a point feature data frame.\nThere are a total of 2290 features and 2 fields.\nUnlike the previous two simple feature data frames, preschool is in a wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "In this subsection, I will utilise different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data frame that contains the geometries is a list, of class sfc - the geometry list-column can be retrieved using:\n\nmpsz$geom or\nmpsz[[1]]\n\nbut more general way uses st_geometry():\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThe print only displays basic information of the feature class such as type of geometry, geographic extent of the features and the coordinate system of the data.\n\n\n\nTo learn more about the associated attribute information in the data frame, we can use glimpse() of dplyr:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe report reveals the data type of each field. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nTo reveal the complete information of a feature object, we use head()of Base R:\n\nhead(mpsz,n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nWe can change the number in the n argument to reflect different number of records."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "In geospatial data science, we need to visualise the geospatial features, beyond just looking at the feature information.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multiplot of all attributes, up to a reasonable maximum number, as shown above. However, we can choose to plot only the geometry:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute:\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote: plot() is meant to plot the geospatial object for a quick look. For high quality cartographic plot, other R packages such as tmap should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#working-with-projection",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. To perform geoprocessing using two geospatial data, there is a need to ensure that both geospatial data are projected using a similar coordinate system.\nThe process of projecting a simple feature data frame from one coordinate system to another coordinate system is called projection transformation.\n\n\nOne common issue that can happen when importing geospatial data is either the coordinate system of the source data is missing or wrongly assigned during the importing process.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the mpsz data frame is projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to the mpsz data frame, st_set_crs() of sf package is used:\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nWe then check whether the EPSG code has been corrected:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is common to transform the original data from one geographic coordinate system to a projected coordinated system. This is because a geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThe print indicates that preschool is in wgs84 coordinate system.\nThis is a scenario for which st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathematically but st_crs() : replacing crs does not reproject data.\nThe projection transformation is performed as follows:\n\npreschool3414 &lt;- st_transform(preschool,crs=3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\n\nDisplaying the content of preschool3414 data frame\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\npreschool3414 is in svy21 projected coordinate system now. Further, as seen from the bounding box, the values are greater than 0 to 360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "Aspatial data are non-geospatial data that have data fields that are able to capture the x- and y-coordinate of data points.\nAspatial data can be imported into a R environment, saved as a tibble data frame and further converted into a simple feature data frame.\n\n\nThe listings dataset is in csv format hence the read_csv() function of readr package is used:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nThe output is called a tibble data frame.\nTo examine if the data file has been imported properly, list() of Base R is used instead of glimpse:\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output indicates that the tibble dataframe consists of 3.540 rows and 18 columns. Two useful fields used in next phase are latitude and longitude, which are in decimal degree format. As a guess, it is assumed that the data is in wgs84 geographic coordinate system.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame using st_as_sf() of sf package:\n\nlistings_sf &lt;- st_as_sf(listings,coords=c(\"longitude\",\"latitude\"),crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nLearning points from above:\n\ncoords argument requires the column name of the x-coordinates first followed by the column name of y-coordinates\ncrs argument requires the coordinate system in EPSG format - EPSG 4326 is wgs84 geographic coordinate system while EPSG 3414 is the Singapore svy21 projected coordinate system. Other countries’ EPSG code can be found via EPSG website.\n%&gt;% is used to nest the st_transform() to transform the newly created simple feature data frame into a svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nNote that a new column called geometry has been added into the data frame while the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "Besides providing functions to handle (i.e. importing, exporting, assigning projection, transforming projection) geospatial data, sf package also offers geoprocessing functions.\nTwo commonly used geoprocessing functions are bufferingand point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. The task is to determine the extent of land that needs to be acquired and the total area.\nThe solution:\nFirst, the st_buffer() of sf package is used to compute the 5-meters buffer around the cycling path:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,dist=5,nQuadSegs = 30)\n\nThe area of the buffers is calculated:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, the sum() of Base R will be used to derive the total land involved:\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission accomplished!\n\n\n\nThe scenario:\nA preschool service group wants to find out the number of preschools in each planning subzone.\nThe solution:\nThe code chunk below performs 2 operations at 1 go:\n(1) Identify preschools located inside each planning subzone using st_intersects()\n(2) length() of Base R is used to calculate the number of preschools that fall inside each planning subzone\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414,preschool3414))\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: st_intersects()should not be confused with st_intersection().\nTo also note that the symbol is ` rather than ’.\n\n\nThe summary statistics of the newly derived PreSch Count field can be shown with the code below:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning zone with the most number of preschools, the top_n() of dplyr package is used as shown in the code chunk below:\n\ntop_n(mpsz3414, 1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nTo calculate the density of preschools by planning zone:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below:\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01A.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1A",
    "section": "",
    "text": "In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, appropriate ggplot2 functions will be used to create functional and yet truthful statistical graphs for EDA purposes.\nA histogram is plotted to reveal the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nHowever, the output does not meet publication quality and there is limited room for further customisation using this function. As such, we use ggplot2 functions instead:\n\nggplot(data = mpsz3414,\n       aes(x=as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20,\n                 color='black',\n                 fill='pink')+\n  labs(title=\"Are preschools evenly distributed in Singapore?\",\n       subtitle=\"There are many planning subzones with a single preschool. However, there are two planning subzones with at least 20 preschools.\",\n       x=\"Preschool density (per km sq)\",\n       y=\"Frequency\")\n\n\n\n\n\n\n\n\nA scatterplot is plotted to show the relationship between PreSch Density and PreSch Count:\n\nggplot(data= mpsz3414,\n       aes(y=`PreSch Count`,\n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\")+\n  xlim(0,40)+\n  ylim(0,40)+\n  labs(title=\"Preschool count vs Preschool density\",\n       x=\"Preschool density(per km sq)\",\n       y=\"Preschool count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualise selected properties of geographic features that are not naturally visible i.e. population, temperate, crime rate and property prices.\nGeovisualisation works by providing a geographical ideation to render a place, phenomenon or process visible. In this exercise, functional and truthful chloropleth maps will be plot using the tmappackage.\n\n\n\nIn this hands-on exercise, the key R package is the tmappackage and the following packages:\n\nreadrto import delimited text file\ntidyrfor tidying data\ndplyrfor wrangling data\nsfto handle geospatial data\n\nThe first 3 packages above are part of the tidyverse package.\nThe packages are loaded with the following code chunk:\n\npacman::p_load(tmap,tidyverse,sf)\n\n\n\n\n\n\nThe following datasets were used to create the chloropleth map:\n\nMaster Plan 2014 Subzone Boundary (Web) (“MP14_SUBZONE_WEB_PL”) from data.gov.sg in ESRI shapefile format. This is geospatial data comprising the geographical boundary of Singapore at the planning subzone level, based on URA Master Plan 2014.\nSingapore Residents by Planning Area/Subzone, Age Group, Sex and Type of Dwelling, June 2011 to 2020 (“respopagesextod2011to2020.csv”), from Department of Statistics, Singapore, in csv file format. This is an aspatial datafile, it does not contain any coordinates to the “MP14_SUBZONE_WEB_PL” shapefile.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a simple feature data frame.\n\nmpsz &lt;- st_read(dsn=\"data/geospatial\",\n                layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe content of mpsz can be examined using the code below:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nThe read_csv() function of readr package is used to import respopagesextod2011to2020.csv file and saved as a data frame called popdata:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nA data table with year 2020 values, comprising variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY is first prepared.\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMY ACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age groups\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA,SZ,AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from=POP) %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n           rowSums(.[13:15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG`+`AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`,`SZ`,`YOUNG`,`ECONOMY ACTIVE`,`AGED`,`TOTAL`,`DEPENDENCY`)\n\n\n\n\nBefore georelational join can be performed, an added step is needed to convert the values in PA and SZ to uppercase, as they are currently in both upper- and lowercase. On the other hand, the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA,SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE`&gt;0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name i.e. SUBZONE_N and SZ as the common identifier:\n\nmpsz_pop2020 &lt;- left_join(mpsz,popdata2020,by=c(\"SUBZONE_N\"=\"SZ\"))\n\nleft_join() of dplyr is used with the mpsz simple feature data frame as the left data table is used to ensure that the output will be a simple feature data frame.\nThe joined file is then saved:\n\nwrite_rds(mpsz_pop2020,\"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth mapping involves the symbolisation of enumeration units such as countries, provinces, states, counties or census units, using area patterns or graduated colours. For instance, a social scientist may require a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches are used to prepare the thematic map using tmap:\n\nPlotting a thematic map quickly using qtm()\nPlotting a highly customisable thematic map using tmap elements\n\n\n\nqtm() is a concise way to provide a good default visualisation:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill=\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearning points:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used\nfill argument is used to map the attribute i.e. DEPENDENCY\n\n\n\n\nThe disadvantage of qtm() is that the aesthetics of individual layers are harder to control. tmap drawing elements are required to draw a high quality cartographic choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha=0.5)+\n  tm_compass(type=\"8star\",size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning subzone boundary from Urban Redevelopment Authority (URA) and population data from Department of Statistics (DOS)\",\n          position = c(\"left\",\"bottom\")   )\n\n\n\n\n\n\n\n\nThe following section explains the tmap functions that were used to plot the above elements:\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() or tm_polygons()\nIn the code chunk below, tm_shape() is used to define the input data and tm_polygons() is used to draw the planning subzone polygons:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons():\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearning points from tm_polygons():\n\ndefault interval binning used to draw the choropleth map is called “pretty”\ndefault color scheme used is YlOrRd of ColorBrewer\ndefault color for missing value is a grey shade\n\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border():\n\ntm_fill() shades the polygons by using the default color scheme\ntm_borders() add the borders of the shapefile onto the choropleth map\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nWith tm_borders(), light gray border lines are added onto the choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")+\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\n\nalpha argument defines the transparency number between 0 (totally transparent) to 1 (not transparent). by default, the alpha value is 1\ncol defines the border color\nlwd defines the border line width, default is 1\nlty defines the border line type, default is solid\n\n\n\n\n\nMost choropleth maps employ methods of data classification, which aims to take a large number of observations and group them into data ranges or classes.\ntmap provides 10 data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher and jenks.\nThe style argument of tm_fill() or tm_polygons() will need to be used to define the data classification method.\n\n\nQuantile data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"quantile\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nEqual data classification method:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"equal\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nComparing the two methods above, the distribution of the quantile method is more even than the equal distribution method. Maps can lie, below are some other methods of classification and different number of classes being tested out.\n\n\nkmeans data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"kmeans\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nkmeans data classification with 2 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=2,\n          style=\"kmeans\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nfisher data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"fisher\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nfisher data classification with 20 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=20,\n          style=\"fisher\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor all built-in styles, category breaks are computed internally. To override the defaults, the breakpoints can be set explicitly by means of breaks argument to tm_fill().\n\n\n\n\n\n\nImportant\n\n\n\nIn tmap, breaks include a minimum and maximum. To end up with n categories, n+1 elements must be specified in the breaks option (values must be in increasing order)\n\n\nBefore setting the break points, it is important and good practice to obtain the descriptive statistics:\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6751  0.7288  0.8084  0.8092 19.0000      92 \n\n\nWith reference to the results above, we set the break points at 0.60, 0.70, 0.80 and 0.90. We also need to include a minimum and maximum, set at 0 and 1.00 respectively.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks=c(0,0.60,0.70,0.80,0.90,1.00)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap support color ramps defined by the user or a set of predefined color ramps from the RColorBrewer package.\n\n\nThis is done by assigning the preferred color to palette argument of tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette = \"Blues\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nTo reverse the color shading, we add a “-” prefix:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"-Blues\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThis also applies to other palette colors like Greens:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"Greens\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"-Greens\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include title, scale bar, compass, margins and aspect ratios. 1.4.3 Data classification methods of tmap and 1.4.4 Color scheme covered above affect how the map looks.\n\n\nLegend options include changing the placement, format and appearance of the legend:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style=\"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(main.title=\"Distribution of Dependency Ratio by planning subzone \\n(Jenks Classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\",\"bottom\"),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nA variety of layout settings that can be changed are called by using tmap_style():\nClassic style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\")+\n  tm_borders(alpha = 0.5)+\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\ntmap also provides arguments to draw other map furniture like compass, scale bar and grid lines i.e. through the use of tm_compass(), tm_scale_bar() and tm_grid():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = \"8star\",size=2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1,alpha = 0.2)+\n  tm_credits(\"Source: Planning subzone boundary data from Urban Redevelopment Authority (URA) and Population Data from Department of Statistics (DOS)\",\n             position = c(\"left\",\"bottom\"))\n\n\n\n\n\n\n\n\nTo reset to default style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = \"8star\",size=2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1,alpha = 0.2)+\n  tm_credits(\"Source: Planning subzone boundary data from Urban Redevelopment Authority (URA) and Population Data from Department of Statistics (DOS)\",\n             position = c(\"left\",\"bottom\"))+\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps are also referred to as facet maps and comprise many maps arranged side-by-side and sometimes, stacked vertically. Facet maps enable the visualisation of how spatial relationships change with respect to another variable such as time.\nFacet maps can be plotted in 3 ways in tmap:\n\nby assigning multiple values to at least one of the aesthetic arguments\nby defining a group-by variable in tm_facets()\nby creating a multiple standalone maps with tmap_arrange()\n\n\n\nHere, we create facet maps by defining ncols in tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\",\"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\")+\n  tm_layout(legend.position = c(\"right\",\"bottom\"))+\n  tm_borders(alpha = 0.5)+\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nAnother example, we assign different styles and palette:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\",\"quantile\"),\n          palette = list(\"Blues\",\"Greens\"))+\n  tm_layout(legend.position = c(\"right\",\"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0)+\n  tm_facets(by=\"REGION_N\",\n            free.coords = TRUE,\n            drop.shapes = TRUE)+\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\",\"center\"),\n            title.size = 20)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap,agedmap,asp=1,ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, a selection function can also be used to map spatial objects meeting a selection criterion:\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\",])+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\",\"bottom\"),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#learning-outcomes",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating and processing geographically referenced datasets. In this hands-on exercise, I will perform geospatial data science tasks in R using the sf package and acquire the following competencies:\n\ninstall and load sf and tidyverse packages into the R environment\nimport geospatial data using appropriate functions of sf package\nimport aspatial data by using appropriate function of readr package\nexplore the content of simple feature data frame by using appropriate Base R and sf functions\nassign or transform coordinate systems by using appropriate sf functions\nconvert aspatial data into a sf dataframe by using appropriate functions of the sf package\nperform geoprocessing tasks using appropriate functions of sf package\nperform data wrangling tasks by using appropriate functions of dplyr package\nperform exploratory data analysis (EDA) using appropriate functions from ggplot2 package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#data-acquisition",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "The following datasets were downloaded:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#getting-started",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "In this hands-on exercise, the key R package is the tmappackage and the following packages:\n\nreadrto import delimited text file\ntidyrfor tidying data\ndplyrfor wrangling data\nsfto handle geospatial data\n\nThe first 3 packages above are part of the tidyverse package.\nThe packages are loaded with the following code chunk:\n\npacman::p_load(tmap,tidyverse,sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "We will import the following geospatial data using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\nNo extension such as .shp,.dbf,.prj and .shx are needed.\n\nmpsz = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multipolygon features.\nThere are a total of 323 features and 15 fields in the mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems.\nThe bounding box provides the x extent and y extent of the data.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import import CyclingPath shapefile as a line feature data frame.\n\ncyclingpath = st_read(dsn=\"data/geospatial\",layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nIt reveals that the geospatial objects are multiline string features.\nThere are a total of 3138 features and 2 fields in the cyclingpath linestring feature data frame.\ncyclingpath is in svy21 projected coordinates systems.\n\n\n\n\nThe code chunk below is used to import the PreSchoolsLocation data which is in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nIt reveals that preschool is a point feature data frame.\nThere are a total of 2290 features and 2 fields.\nUnlike the previous two simple feature data frames, preschool is in a wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "In this subsection, I will utilise different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data frame that contains the geometries is a list, of class sfc - the geometry list-column can be retrieved using:\n\nmpsz$geom or\nmpsz[[1]]\n\nbut more general way uses st_geometry():\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThe print only displays basic information of the feature class such as type of geometry, geographic extent of the features and the coordinate system of the data.\n\n\n\nTo learn more about the associated attribute information in the data frame, we can use glimpse() of dplyr:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe report reveals the data type of each field. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nTo reveal the complete information of a feature object, we use head()of Base R:\n\nhead(mpsz,n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nWe can change the number in the n argument to reflect different number of records."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "In geospatial data science, we need to visualise the geospatial features, beyond just looking at the feature information.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multiplot of all attributes, up to a reasonable maximum number, as shown above. However, we can choose to plot only the geometry:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute:\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote: plot() is meant to plot the geospatial object for a quick look. For high quality cartographic plot, other R packages such as tmap should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#working-with-projection",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. To perform geoprocessing using two geospatial data, there is a need to ensure that both geospatial data are projected using a similar coordinate system.\nThe process of projecting a simple feature data frame from one coordinate system to another coordinate system is called projection transformation.\n\n\nOne common issue that can happen when importing geospatial data is either the coordinate system of the source data is missing or wrongly assigned during the importing process.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the mpsz data frame is projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to the mpsz data frame, st_set_crs() of sf package is used:\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nWe then check whether the EPSG code has been corrected:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is common to transform the original data from one geographic coordinate system to a projected coordinated system. This is because a geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThe print indicates that preschool is in wgs84 coordinate system.\nThis is a scenario for which st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathematically but st_crs() : replacing crs does not reproject data.\nThe projection transformation is performed as follows:\n\npreschool3414 &lt;- st_transform(preschool,crs=3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\n\nDisplaying the content of preschool3414 data frame\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\npreschool3414 is in svy21 projected coordinate system now. Further, as seen from the bounding box, the values are greater than 0 to 360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Aspatial data are non-geospatial data that have data fields that are able to capture the x- and y-coordinate of data points.\nAspatial data can be imported into a R environment, saved as a tibble data frame and further converted into a simple feature data frame.\n\n\nThe listings dataset is in csv format hence the read_csv() function of readr package is used:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nThe output is called a tibble data frame.\nTo examine if the data file has been imported properly, list() of Base R is used instead of glimpse:\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output indicates that the tibble dataframe consists of 3.540 rows and 18 columns. Two useful fields used in next phase are latitude and longitude, which are in decimal degree format. As a guess, it is assumed that the data is in wgs84 geographic coordinate system.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame using st_as_sf() of sf package:\n\nlistings_sf &lt;- st_as_sf(listings,coords=c(\"longitude\",\"latitude\"),crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nLearning points from above:\n\ncoords argument requires the column name of the x-coordinates first followed by the column name of y-coordinates\ncrs argument requires the coordinate system in EPSG format - EPSG 4326 is wgs84 geographic coordinate system while EPSG 3414 is the Singapore svy21 projected coordinate system. Other countries’ EPSG code can be found via EPSG website.\n%&gt;% is used to nest the st_transform() to transform the newly created simple feature data frame into a svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nNote that a new column called geometry has been added into the data frame while the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Besides providing functions to handle (i.e. importing, exporting, assigning projection, transforming projection) geospatial data, sf package also offers geoprocessing functions.\nTwo commonly used geoprocessing functions are bufferingand point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. The task is to determine the extent of land that needs to be acquired and the total area.\nThe solution:\nFirst, the st_buffer() of sf package is used to compute the 5-meters buffer around the cycling path:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,dist=5,nQuadSegs = 30)\n\nThe area of the buffers is calculated:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, the sum() of Base R will be used to derive the total land involved:\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission accomplished!\n\n\n\nThe scenario:\nA preschool service group wants to find out the number of preschools in each planning subzone.\nThe solution:\nThe code chunk below performs 2 operations at 1 go:\n(1) Identify preschools located inside each planning subzone using st_intersects()\n(2) length() of Base R is used to calculate the number of preschools that fall inside each planning subzone\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414,preschool3414))\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: st_intersects()should not be confused with st_intersection().\nTo also note that the symbol is ` rather than ’.\n\n\nThe summary statistics of the newly derived PreSch Count field can be shown with the code below:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning zone with the most number of preschools, the top_n() of dplyr package is used as shown in the code chunk below:\n\ntop_n(mpsz3414, 1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nTo calculate the density of preschools by planning zone:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below:\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, appropriate ggplot2 functions will be used to create functional and yet truthful statistical graphs for EDA purposes.\nA histogram is plotted to reveal the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nHowever, the output does not meet publication quality and there is limited room for further customisation using this function. As such, we use ggplot2 functions instead:\n\nggplot(data = mpsz3414,\n       aes(x=as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20,\n                 color='black',\n                 fill='pink')+\n  labs(title=\"Are preschools evenly distributed in Singapore?\",\n       subtitle=\"There are many planning subzones with a single preschool. However, there are two planning subzones with at least 20 preschools.\",\n       x=\"Preschool density (per km sq)\",\n       y=\"Frequency\")\n\n\n\n\n\n\n\n\nA scatterplot is plotted to show the relationship between PreSch Density and PreSch Count:\n\nggplot(data= mpsz3414,\n       aes(y=`PreSch Count`,\n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\")+\n  xlim(0,40)+\n  ylim(0,40)+\n  labs(title=\"Preschool count vs Preschool density\",\n       x=\"Preschool density(per km sq)\",\n       y=\"Preschool count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#overview",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualise selected properties of geographic features that are not naturally visible i.e. population, temperate, crime rate and property prices.\nGeovisualisation works by providing a geographical ideation to render a place, phenomenon or process visible. In this exercise, functional and truthful chloropleth maps will be plot using the tmappackage."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#importing-data-into-r",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "The following datasets were used to create the chloropleth map:\n\nMaster Plan 2014 Subzone Boundary (Web) (“MP14_SUBZONE_WEB_PL”) from data.gov.sg in ESRI shapefile format. This is geospatial data comprising the geographical boundary of Singapore at the planning subzone level, based on URA Master Plan 2014.\nSingapore Residents by Planning Area/Subzone, Age Group, Sex and Type of Dwelling, June 2011 to 2020 (“respopagesextod2011to2020.csv”), from Department of Statistics, Singapore, in csv file format. This is an aspatial datafile, it does not contain any coordinates to the “MP14_SUBZONE_WEB_PL” shapefile.\n\n\n\n\nThe following code chunk uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile as a simple feature data frame.\n\nmpsz &lt;- st_read(dsn=\"data/geospatial\",\n                layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe content of mpsz can be examined using the code below:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nThe read_csv() function of readr package is used to import respopagesextod2011to2020.csv file and saved as a data frame called popdata:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nA data table with year 2020 values, comprising variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY is first prepared.\n\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMY ACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age groups\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA,SZ,AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from=POP) %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n           rowSums(.[13:15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG`+`AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`,`SZ`,`YOUNG`,`ECONOMY ACTIVE`,`AGED`,`TOTAL`,`DEPENDENCY`)\n\n\n\n\nBefore georelational join can be performed, an added step is needed to convert the values in PA and SZ to uppercase, as they are currently in both upper- and lowercase. On the other hand, the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA,SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE`&gt;0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name i.e. SUBZONE_N and SZ as the common identifier:\n\nmpsz_pop2020 &lt;- left_join(mpsz,popdata2020,by=c(\"SUBZONE_N\"=\"SZ\"))\n\nleft_join() of dplyr is used with the mpsz simple feature data frame as the left data table is used to ensure that the output will be a simple feature data frame.\nThe joined file is then saved:\n\nwrite_rds(mpsz_pop2020,\"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units such as countries, provinces, states, counties or census units, using area patterns or graduated colours. For instance, a social scientist may require a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches are used to prepare the thematic map using tmap:\n\nPlotting a thematic map quickly using qtm()\nPlotting a highly customisable thematic map using tmap elements\n\n\n\nqtm() is a concise way to provide a good default visualisation:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill=\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearning points:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used\nfill argument is used to map the attribute i.e. DEPENDENCY\n\n\n\n\nThe disadvantage of qtm() is that the aesthetics of individual layers are harder to control. tmap drawing elements are required to draw a high quality cartographic choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha=0.5)+\n  tm_compass(type=\"8star\",size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning subzone boundary from Urban Redevelopment Authority (URA) and population data from Department of Statistics (DOS)\",\n          position = c(\"left\",\"bottom\")   )\n\n\n\n\n\n\n\n\nThe following section explains the tmap functions that were used to plot the above elements:\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() or tm_polygons()\nIn the code chunk below, tm_shape() is used to define the input data and tm_polygons() is used to draw the planning subzone polygons:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons():\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearning points from tm_polygons():\n\ndefault interval binning used to draw the choropleth map is called “pretty”\ndefault color scheme used is YlOrRd of ColorBrewer\ndefault color for missing value is a grey shade\n\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border():\n\ntm_fill() shades the polygons by using the default color scheme\ntm_borders() add the borders of the shapefile onto the choropleth map\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nWith tm_borders(), light gray border lines are added onto the choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")+\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\n\nalpha argument defines the transparency number between 0 (totally transparent) to 1 (not transparent). by default, the alpha value is 1\ncol defines the border color\nlwd defines the border line width, default is 1\nlty defines the border line type, default is solid"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Most choropleth maps employ methods of data classification, which aims to take a large number of observations and group them into data ranges or classes.\ntmap provides 10 data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher and jenks.\nThe style argument of tm_fill() or tm_polygons() will need to be used to define the data classification method.\n\n\nQuantile data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"quantile\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nEqual data classification method:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"equal\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nComparing the two methods above, the distribution of the quantile method is more even than the equal distribution method. Maps can lie, below are some other methods of classification and different number of classes being tested out.\n\n\nkmeans data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"kmeans\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nkmeans data classification with 2 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=2,\n          style=\"kmeans\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nfisher data classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=5,\n          style=\"fisher\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nfisher data classification with 20 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=20,\n          style=\"fisher\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor all built-in styles, category breaks are computed internally. To override the defaults, the breakpoints can be set explicitly by means of breaks argument to tm_fill().\n\n\n\n\n\n\nImportant\n\n\n\nIn tmap, breaks include a minimum and maximum. To end up with n categories, n+1 elements must be specified in the breaks option (values must be in increasing order)\n\n\nBefore setting the break points, it is important and good practice to obtain the descriptive statistics:\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6751  0.7288  0.8084  0.8092 19.0000      92 \n\n\nWith reference to the results above, we set the break points at 0.60, 0.70, 0.80 and 0.90. We also need to include a minimum and maximum, set at 0 and 1.00 respectively.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks=c(0,0.60,0.70,0.80,0.90,1.00)) +\n  tm_borders(alpha=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#color-scheme",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "tmap support color ramps defined by the user or a set of predefined color ramps from the RColorBrewer package.\n\n\nThis is done by assigning the preferred color to palette argument of tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette = \"Blues\")+\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nTo reverse the color shading, we add a “-” prefix:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"-Blues\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThis also applies to other palette colors like Greens:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"Greens\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style = \"quantile\",\n          palette = \"-Greens\")+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#map-layouts",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Map layout refers to the combination of all map elements into a cohesive map. Map elements include title, scale bar, compass, margins and aspect ratios. 1.4.3 Data classification methods of tmap and 1.4.4 Color scheme covered above affect how the map looks.\n\n\nLegend options include changing the placement, format and appearance of the legend:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style=\"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(main.title=\"Distribution of Dependency Ratio by planning subzone \\n(Jenks Classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\",\"bottom\"),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nA variety of layout settings that can be changed are called by using tmap_style():\nClassic style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\")+\n  tm_borders(alpha = 0.5)+\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\ntmap also provides arguments to draw other map furniture like compass, scale bar and grid lines i.e. through the use of tm_compass(), tm_scale_bar() and tm_grid():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = \"8star\",size=2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1,alpha = 0.2)+\n  tm_credits(\"Source: Planning subzone boundary data from Urban Redevelopment Authority (URA) and Population Data from Department of Statistics (DOS)\",\n             position = c(\"left\",\"bottom\"))\n\n\n\n\n\n\n\n\nTo reset to default style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\")+\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = \"8star\",size=2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1,alpha = 0.2)+\n  tm_credits(\"Source: Planning subzone boundary data from Urban Redevelopment Authority (URA) and Population Data from Department of Statistics (DOS)\",\n             position = c(\"left\",\"bottom\"))+\n  tmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Small multiple maps are also referred to as facet maps and comprise many maps arranged side-by-side and sometimes, stacked vertically. Facet maps enable the visualisation of how spatial relationships change with respect to another variable such as time.\nFacet maps can be plotted in 3 ways in tmap:\n\nby assigning multiple values to at least one of the aesthetic arguments\nby defining a group-by variable in tm_facets()\nby creating a multiple standalone maps with tmap_arrange()\n\n\n\nHere, we create facet maps by defining ncols in tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\",\"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\")+\n  tm_layout(legend.position = c(\"right\",\"bottom\"))+\n  tm_borders(alpha = 0.5)+\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nAnother example, we assign different styles and palette:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\",\"quantile\"),\n          palette = list(\"Blues\",\"Greens\"))+\n  tm_layout(legend.position = c(\"right\",\"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0)+\n  tm_facets(by=\"REGION_N\",\n            free.coords = TRUE,\n            drop.shapes = TRUE)+\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\",\"center\"),\n            title.size = 20)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap,agedmap,asp=1,ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "Instead of creating small multiple choropleth map, a selection function can also be used to map spatial objects meeting a selection criterion:\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\",])+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\",\"bottom\"),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01B.html#references",
    "title": "Hands-on Exercise 1B",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Geospatial",
    "section": "",
    "text": "Tips for quarto page settings\n\n\n\nIf true,\n\neval: R will run code\necho: R will display code chunk\nfreeze: whatever document that has already been committed and pushed to github (and if there’s no changes), will no longer be rendereds\n\nIf false,\n\nmessage: avoid printing out warning messages (for added info, warning in markdown is the same as warning in message)\n\n\n\nIn this in-class exercise, the following packages will be used:\n\ntidyverse\nsf\ntmap\nggstatsplot\n\n\n\n\npacman::p_load(tidyverse,sf,tmap,ggstatsplot)\n\n\npacman will first check whether packages are installed before loading\npacman is just called once and not loaded into the environment as its not required for the long-term and to avoid taking up memory\n\n\n\n\n\n\n\n\n\nmpsz14_shp = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ngeometry column store all coordinate pairs\n\n\n\n\n\nmpsz14_kml &lt;- st_read(\"data/geospatial/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nthis kml file is corrupted\nin other cases, if cannot open kml file, can change extension to .kmz and see if it can be unzipped\n\nIt is possible to generate a kml file from shp file as follows:\n\nst_write(mpsz14_shp,\n         \"data/geospatial/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn=TRUE)\n\n\nmpsz14_kml &lt;- st_read(\"data/geospatial/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\ndelete_dsn = TRUE is to overwrite previous file otherwise it will prompt an error that the dataset already exists\n\n\n\n\n\n\n\n\nmpsz19_shp = st_read(dsn=\"data/geospatial\",\n                   layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nnote from printout above that the coordinate system is in WGS84 (geographic coordinate system for which units are in decimal degree)\nWGS84 is popular and used in our handphones but problem is such coordinate systems are not useful for distance and area measurements i.e. 1 degree at equator not equivalent to 1 degree at north pole aka distorted. As such, always use projected coordinated system.\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant to know coordinate system to interpret coordinate points\n\nlatitude, longitude straightforward as typically in degrees BUT\nif in x, y, could be in various units i.e. metres, km\n\n\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nComparing the 2 files, shp file is clearer than kml file hence naturally use the shp file. kml file will require splitting\n\n\n\n\n\n\n\nTip\n\n\n\nGiven the above, always download different versions of the same file and analyse which is the better data to use.\n\n\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"MPSZ-2019\")%&gt;%\n  st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\ndo not create intermediate data, just replace\n\n\n\n\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA,SZ,AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\nr vs python: r starts from 1 and not 0 like python\nnote which rows the age groups fall in\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\n           rowSums(.[15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG`+`AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`,`SZ`,`YOUNG`,`ECONOMY ACTIVE`,`AGED`,`TOTAL`,`DEPENDENCY`)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 1: Geospatial",
    "section": "",
    "text": "pacman::p_load(tidyverse,sf,tmap,ggstatsplot)\n\n\npacman will first check whether packages are installed before loading\npacman is just called once and not loaded into the environment as its not required for the long-term and to avoid taking up memory"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-subzone-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-subzone-data",
    "title": "In-class Exercise 1: Geospatial",
    "section": "",
    "text": "mpsz14_shp = st_read(dsn=\"data/geospatial\",\n               layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ngeometry column store all coordinate pairs\n\n\n\n\n\nmpsz14_kml &lt;- st_read(\"data/geospatial/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nthis kml file is corrupted\nin other cases, if cannot open kml file, can change extension to .kmz and see if it can be unzipped\n\nIt is possible to generate a kml file from shp file as follows:\n\nst_write(mpsz14_shp,\n         \"data/geospatial/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn=TRUE)\n\n\nmpsz14_kml &lt;- st_read(\"data/geospatial/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\ndelete_dsn = TRUE is to overwrite previous file otherwise it will prompt an error that the dataset already exists\n\n\n\n\n\n\n\n\nmpsz19_shp = st_read(dsn=\"data/geospatial\",\n                   layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nnote from printout above that the coordinate system is in WGS84 (geographic coordinate system for which units are in decimal degree)\nWGS84 is popular and used in our handphones but problem is such coordinate systems are not useful for distance and area measurements i.e. 1 degree at equator not equivalent to 1 degree at north pole aka distorted. As such, always use projected coordinated system.\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant to know coordinate system to interpret coordinate points\n\nlatitude, longitude straightforward as typically in degrees BUT\nif in x, y, could be in various units i.e. metres, km\n\n\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nComparing the 2 files, shp file is clearer than kml file hence naturally use the shp file. kml file will require splitting\n\n\n\n\n\n\n\nTip\n\n\n\nGiven the above, always download different versions of the same file and analyse which is the better data to use.\n\n\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"MPSZ-2019\")%&gt;%\n  st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\ndo not create intermediate data, just replace\n\n\n\n\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA,SZ,AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\nr vs python: r starts from 1 and not 0 like python\nnote which rows the age groups fall in\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\n           rowSums(.[15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG`+`AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`,`SZ`,`YOUNG`,`ECONOMY ACTIVE`,`AGED`,`TOTAL`,`DEPENDENCY`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution of a set of points on a surface. The point can be a location of:\n\nevents such as crime, traffic incident and disease onset or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and eldercare\n\nIn this hands-on exercise, we will use appropriate functions of spatstat to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions to be addressed are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next question is where are the locations with higher concentrations of childcare centres?\n\n\n\n\nThree datasets are used in this exercise:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)\n\n\n\n\n\n\nWe will import the geospatial data using st_read() of sf package:\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the sg_sf and mpsz_sf data frames are projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to both data frame, st_set_crs() of sf package is used:\n\nsg_sf3414 &lt;- st_set_crs(sg_sf,3414)\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf,3414)\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(sg_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial dataframe, it is also useful to plot a map to show their spatial patterns. A pin map can be prepared using the code below:\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nAll the geospatial layers are within the same map extend which indicates that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\n\ntmap_mode('plot')\n\nAt interactive mode, tmap is using leaflet for RAPI. The advantage of an interactive pin map is it allows one to navigate and zoom around the map freely as well as query the information of each simple feature (i.e. the point) by clicking on the. The background of the internet map layer can also be changed. At present, three internet map layers are provided: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\nTip\n\n\n\nIt is always important to switch back to plot mode after the interactive map as each interactive mode will consume a connection.\nIt is important to avoid displaying excessive number of interactive maps i.e. not more than 10, in one RMarkdown document when publishing on Netlify.\n\n\n\n\n\n\nWhile simple feature data frame is gaining popularity against Spatial* classes, many geospatial analysis packages require the input geospatial data in to be in Spatial* classes. In this section, simple feature data frame will be converted to Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf3414)\nsg &lt;- as_Spatial(sg_sf3414)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg,\"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\n\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nTaking a look at the summary statistics of the ppp object:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process is simple, that is, that the points cannot be coincidental.\n\n\n\n\n\nWe can check the duplication in a ppp object using the code chunk below:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincidence points, the multiplicity() function is used, as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, the code chunk below is used:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn the event of duplicate points, there are 3 ways to overcome the issue:\n\nDelete the duplicates - easiest way but it will also meant that some useful point events will be lost\nJittering - this method will add a small perturbation to the duplicate points so that they do not occupy the exact same space\nMake each point “unique” and attach the duplicates of the points to the patterns as marks, as attributes of the points. Analytical techniques that take into account these marks would be required.\n\nThe code chunk below implements the jittering approach:\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck for duplicated points:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore’s boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below:\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp:\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, first-order SPPA will be performed using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, we will compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nAs added info, the bandwidth used to compute the kde layer can be retrieved using the code chunk below:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nRe-run density() using the resale data set and plot the output kde map:\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNote that the output image looks identical to the earlier version and that the only change is in the data values (refer to the legend).\n\n\n\n\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm as from their experience, this method tends to produce more appropriate values when the pattern consisted predominantly of tight clusters. However, if the purpose of thestudy is to detect a single tight cluster in the midst of random noise, the bw.diggle() method seemed to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function:\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, a KDE layer will be computed by defining a bandwidth of 600 meter. In the code chunk below, the sigma value used is 0.6. as the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, adaptive kernel density estimation will be derived using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe convert the result to be suitable for mapping purposes:\n\ngridded_kde_childcareSG_bw &lt;- as.im(kde_childcareSG.bw)\nplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n\nNext, the gridded kernal density objects will be converted into a RasterLayer object by using raster() of raster package:\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nTaking a look at the properties of kde_childcareSG_bw_raster RasterLayer:\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNote that the crs property is NA.\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nThe crs property is now completed.\n\n\n\n\nFinally, we will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\nIn this section, the KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas will be compared.\n\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres:\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each area:\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, 250m will be used as the bandwidth:\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nH0 = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area:\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.94527, p-value = 0.4135\nalternative hypothesis: two-sided\n\n\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area:\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79076, p-value = 0.0001592\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#learning-outcomes",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution of a set of points on a surface. The point can be a location of:\n\nevents such as crime, traffic incident and disease onset or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and eldercare\n\nIn this hands-on exercise, we will use appropriate functions of spatstat to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions to be addressed are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next question is where are the locations with higher concentrations of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#data-acquisition",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "Three datasets are used in this exercise:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "sf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "We will import the geospatial data using st_read() of sf package:\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the sg_sf and mpsz_sf data frames are projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to both data frame, st_set_crs() of sf package is used:\n\nsg_sf3414 &lt;- st_set_crs(sg_sf,3414)\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf,3414)\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(sg_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial dataframe, it is also useful to plot a map to show their spatial patterns. A pin map can be prepared using the code below:\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nAll the geospatial layers are within the same map extend which indicates that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\n\ntmap_mode('plot')\n\nAt interactive mode, tmap is using leaflet for RAPI. The advantage of an interactive pin map is it allows one to navigate and zoom around the map freely as well as query the information of each simple feature (i.e. the point) by clicking on the. The background of the internet map layer can also be changed. At present, three internet map layers are provided: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\nTip\n\n\n\nIt is always important to switch back to plot mode after the interactive map as each interactive mode will consume a connection.\nIt is important to avoid displaying excessive number of interactive maps i.e. not more than 10, in one RMarkdown document when publishing on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "While simple feature data frame is gaining popularity against Spatial* classes, many geospatial analysis packages require the input geospatial data in to be in Spatial* classes. In this section, simple feature data frame will be converted to Spatial* class.\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf3414)\nsg &lt;- as_Spatial(sg_sf3414)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg,\"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\n\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nTaking a look at the summary statistics of the ppp object:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process is simple, that is, that the points cannot be coincidental.\n\n\n\n\n\nWe can check the duplication in a ppp object using the code chunk below:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincidence points, the multiplicity() function is used, as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, the code chunk below is used:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn the event of duplicate points, there are 3 ways to overcome the issue:\n\nDelete the duplicates - easiest way but it will also meant that some useful point events will be lost\nJittering - this method will add a small perturbation to the duplicate points so that they do not occupy the exact same space\nMake each point “unique” and attach the duplicates of the points to the patterns as marks, as attributes of the points. Analytical techniques that take into account these marks would be required.\n\nThe code chunk below implements the jittering approach:\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck for duplicated points:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore’s boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below:\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp:\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "In this section, first-order SPPA will be performed using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nIn this section, we will compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nAs added info, the bandwidth used to compute the kde layer can be retrieved using the code chunk below:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nRe-run density() using the resale data set and plot the output kde map:\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNote that the output image looks identical to the earlier version and that the only change is in the data values (refer to the legend).\n\n\n\n\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm as from their experience, this method tends to produce more appropriate values when the pattern consisted predominantly of tight clusters. However, if the purpose of thestudy is to detect a single tight cluster in the midst of random noise, the bw.diggle() method seemed to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function:\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "Next, a KDE layer will be computed by defining a bandwidth of 600 meter. In the code chunk below, the sigma value used is 0.6. as the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, adaptive kernel density estimation will be derived using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe convert the result to be suitable for mapping purposes:\n\ngridded_kde_childcareSG_bw &lt;- as.im(kde_childcareSG.bw)\nplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n\nNext, the gridded kernal density objects will be converted into a RasterLayer object by using raster() of raster package:\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nTaking a look at the properties of kde_childcareSG_bw_raster RasterLayer:\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNote that the crs property is NA.\n\n\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nThe crs property is now completed.\n\n\n\n\nFinally, we will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\nIn this section, the KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas will be compared.\n\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres:\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each area:\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nFor comparison purposes, 250m will be used as the bandwidth:\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02A.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 2A",
    "section": "",
    "text": "In this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nH0 = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area:\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.94527, p-value = 0.4135\nalternative hypothesis: two-sided\n\n\n\n\n\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area:\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79076, p-value = 0.0001592\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution of a set of points on a surface. The point can be a location of:\n\nevents such as crime, traffic incident and disease onset or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and eldercare\n\nIn this hands-on exercise, we will use appropriate functions of spatstat to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions to be addressed are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next question is where are the locations with higher concentrations of childcare centres?\n\n\n\n\nThree datasets are used in this exercise:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)\n\n\n\n\n\n\nWe will import the geospatial data using st_read() of sf package:\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the sg_sf and mpsz_sf data frames are projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to both data frame, st_set_crs() of sf package is used:\n\nsg_sf3414 &lt;- st_set_crs(sg_sf,3414)\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf,3414)\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(sg_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial dataframe, it is also useful to plot a map to show their spatial patterns. A pin map can be prepared using the code below:\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nAll the geospatial layers are within the same map extend which indicates that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\n\ntmap_mode('plot')\n\nAt interactive mode, tmap is using leaflet for RAPI. The advantage of an interactive pin map is it allows one to navigate and zoom around the map freely as well as query the information of each simple feature (i.e. the point) by clicking on the. The background of the internet map layer can also be changed. At present, three internet map layers are provided: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\nTip\n\n\n\nIt is always important to switch back to plot mode after the interactive map as each interactive mode will consume a connection.\nIt is important to avoid displaying excessive number of interactive maps i.e. not more than 10, in one RMarkdown document when publishing on Netlify.\n\n\n\n\n\n\nWhile simple feature data frame is gaining popularity against Spatial* classes, many geospatial analysis packages require the input geospatial data in to be in Spatial* classes. In this section, simple feature data frame will be converted to Spatial* class.\n\n\nThe code chunk below as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nTaking a look at the summary statistics of the ppp object:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process is simple, that is, that the points cannot be coincidental.\n\n\n\n\n\nWe can check the duplication in a ppp object using the code chunk below:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincidence points, the multiplicity() function is used, as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, the code chunk below is used:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\ntmap_mode('view')\ntm_shape(childcare_sf) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn the event of duplicate points, there are 3 ways to overcome the issue:\n\nDelete the duplicates - easiest way but it will also meant that some useful point events will be lost\nJittering - this method will add a small perturbation to the duplicate points so that they do not occupy the exact same space\nMake each point “unique” and attach the duplicates of the points to the patterns as marks, as attributes of the points. Analytical techniques that take into account these marks would be required.\n\nThe code chunk below implements the jittering approach:\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck for duplicated points:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore’s boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below:\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp:\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres:\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will compute G-function estimation using Gest() of spatstat package. A monte carlo simulation test will also be performed using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will compute the F-function estimation by using Fest() of spatstat package. A monte carlo simulation test will also be performed using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function:\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo test with F-function:\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nK-function measures the number of events found up to a given distance of any particular event. In this section, we will compute K-function estimates by using Kest() of spatstat package. We will also perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will compute L-function estimation by using Lest() of spatstat package. We will also perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#learning-outcomes",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution of a set of points on a surface. The point can be a location of:\n\nevents such as crime, traffic incident and disease onset or\nbusiness services (coffee and fast food outlets) or facilities such as childcare and eldercare\n\nIn this hands-on exercise, we will use appropriate functions of spatstat to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions to be addressed are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next question is where are the locations with higher concentrations of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#data-acquisition",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "Three datasets are used in this exercise:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "sf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "We will import the geospatial data using st_read() of sf package:\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWhen the input geospatial data is in shapefile format, two arguments are used:\n\ndsn to define the data path\nlayer to provide the shapefile name\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore using these data for analysis, it is important to ensure that they are projected in the same projection system.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile the sg_sf and mpsz_sf data frames are projected in svy21, the end of the printout above states that the EPSG is 9001 - this is a wrong EPSG code as the correct EPSG code for svy21 should be 3414.\nTo correctly assign the right EPSG code to both data frame, st_set_crs() of sf package is used:\n\nsg_sf3414 &lt;- st_set_crs(sg_sf,3414)\nmpsz_sf3414 &lt;- st_set_crs(mpsz_sf,3414)\n\nChecking whether the EPSG code has been corrected:\n\nst_crs(sg_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nAfter checking the referencing system of each geospatial dataframe, it is also useful to plot a map to show their spatial patterns. A pin map can be prepared using the code below:\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nAll the geospatial layers are within the same map extend which indicates that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\n\ntmap_mode('plot')\n\nAt interactive mode, tmap is using leaflet for RAPI. The advantage of an interactive pin map is it allows one to navigate and zoom around the map freely as well as query the information of each simple feature (i.e. the point) by clicking on the. The background of the internet map layer can also be changed. At present, three internet map layers are provided: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\n\n\n\n\n\nTip\n\n\n\nIt is always important to switch back to plot mode after the interactive map as each interactive mode will consume a connection.\nIt is important to avoid displaying excessive number of interactive maps i.e. not more than 10, in one RMarkdown document when publishing on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "While simple feature data frame is gaining popularity against Spatial* classes, many geospatial analysis packages require the input geospatial data in to be in Spatial* classes. In this section, simple feature data frame will be converted to Spatial* class.\n\n\nThe code chunk below as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nPlotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nTaking a look at the summary statistics of the ppp object:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process is simple, that is, that the points cannot be coincidental.\n\n\n\n\n\nWe can check the duplication in a ppp object using the code chunk below:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincidence points, the multiplicity() function is used, as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nTo know how many locations have more than one point event, the code chunk below is used:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\ntmap_mode('view')\ntm_shape(childcare_sf) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn the event of duplicate points, there are 3 ways to overcome the issue:\n\nDelete the duplicates - easiest way but it will also meant that some useful point events will be lost\nJittering - this method will add a small perturbation to the duplicate points so that they do not occupy the exact same space\nMake each point “unique” and attach the duplicates of the points to the patterns as marks, as attributes of the points. Analytical techniques that take into account these marks would be required.\n\nThe code chunk below implements the jittering approach:\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck for duplicated points:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore’s boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below:\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlotting the newly derived childcareSG_ppp:\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres:\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "The G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will compute G-function estimation using Gest() of spatstat package. A monte carlo simulation test will also be performed using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "The F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will compute the F-function estimation by using Fest() of spatstat package. A monte carlo simulation test will also be performed using envelope() of spatstat package.\n\n\n\n\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function:\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo test with F-function:\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "K-function measures the number of events found up to a given distance of any particular event. In this section, we will compute K-function estimates by using Kest() of spatstat package. We will also perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing:\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02B.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 2B",
    "section": "",
    "text": "In this section, we will compute L-function estimation by using Lest() of spatstat package. We will also perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "sf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nmaptools is retired and binary is removed from CRAN, however it can be downloaded from Posit Public Package Manager (this site is useful for Shiny) snapshots by using the code chunk below. Alternatively, can utilise the CRAN retired website and key in the latest version.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nutilise #| eval: false after installing the packages to avoid the code from re-running everything the page is rendered\n\n\n\n\n\n\nsf is a full programmable GIS software - does all the GIS work\n\n\n\n\nThe code chunk below st_union() is used to derive the coastal outline of sf tibble data.frame\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\n\nplot(sg_sf)\n\n\n\n\n\nspatstat has several sub-packages, the notable ones:\n\nspatstat.geom: if its sp object - use ppp or owin, if its sf object - use as.ppp or as.owin. Prof advised not to use sp object at all, just use sf.\n\nas.ppp - allow creation of point object\nas.owin - create the boundary\n\n\n\n\n\nCode chunk shows 2 different ways to convert KDE output into grid object\n\npar(bg =\"#E4D5C9\")\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\nspplot(gridded_kde_childcareSG_ad)\n\nTo use spatstat.geom method instead of maptools since the latter is now defunct:\n\ngridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive,\n                                 \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\nto ensure reproducibility, to always set a seed before using spatstat functions that involve Monte Carlo simulation\nlikewise, this should be applicable for other randomisation processes\n\n\nset.seed(1234)\n\n\n\n\n\nEdge correction help to avoid biases that arise when estimating spatial statistics near the boundaries of a study area\nimportant when extracting spatial area cause there might be data points close to the edge, for instance:\n\nFor beginners, to test out the different methods for edge correction\nHowever, there is always the option of not carrying out edge correction if points are not near the edge as this process would take up computation time\n\n\n\n\n\nMultiple points can overplot each other i.e. HDB with the same postal code - calculations will not truly reflect distribution\nin hands-on exercise 2, there is no duplicate results hence the steps are actually redundant but is for learning purposes\n\n\n\n\nFor section 1.5.4, to increase nsim as the code chunk only shows 1 time.\n\n\n\n\nsf_geometry\n\n\n\nsp_geometry to remove the attribute"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issues-with-hands-on-ex-2",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issues-with-hands-on-ex-2",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "sf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,tmap,tidyverse)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nmaptools is retired and binary is removed from CRAN, however it can be downloaded from Posit Public Package Manager (this site is useful for Shiny) snapshots by using the code chunk below. Alternatively, can utilise the CRAN retired website and key in the latest version.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nutilise #| eval: false after installing the packages to avoid the code from re-running everything the page is rendered\n\n\n\n\n\n\nsf is a full programmable GIS software - does all the GIS work\n\n\n\n\nThe code chunk below st_union() is used to derive the coastal outline of sf tibble data.frame\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\n\nplot(sg_sf)\n\n\n\n\n\nspatstat has several sub-packages, the notable ones:\n\nspatstat.geom: if its sp object - use ppp or owin, if its sf object - use as.ppp or as.owin. Prof advised not to use sp object at all, just use sf.\n\nas.ppp - allow creation of point object\nas.owin - create the boundary\n\n\n\n\n\nCode chunk shows 2 different ways to convert KDE output into grid object\n\npar(bg =\"#E4D5C9\")\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\nspplot(gridded_kde_childcareSG_ad)\n\nTo use spatstat.geom method instead of maptools since the latter is now defunct:\n\ngridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive,\n                                 \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\nto ensure reproducibility, to always set a seed before using spatstat functions that involve Monte Carlo simulation\nlikewise, this should be applicable for other randomisation processes\n\n\nset.seed(1234)\n\n\n\n\n\nEdge correction help to avoid biases that arise when estimating spatial statistics near the boundaries of a study area\nimportant when extracting spatial area cause there might be data points close to the edge, for instance:\n\nFor beginners, to test out the different methods for edge correction\nHowever, there is always the option of not carrying out edge correction if points are not near the edge as this process would take up computation time\n\n\n\n\n\nMultiple points can overplot each other i.e. HDB with the same postal code - calculations will not truly reflect distribution\nin hands-on exercise 2, there is no duplicate results hence the steps are actually redundant but is for learning purposes\n\n\n\n\nFor section 1.5.4, to increase nsim as the code chunk only shows 1 time.\n\n\n\n\nsf_geometry\n\n\n\nsp_geometry to remove the attribute"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-launching-r-packages",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Key packages that are installed are:\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "title": "Take-home Exercise 1",
    "section": "Importing Data",
    "text": "Importing Data\n\nrdacc_sf &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\n\nNote that incident_datetime and report_datetime are kept in datetime field, so that easier for manipulation later on i.e. extracting day of week, time of day using lubridate. Can be useful in determining the occurrence of incidents at a particular timing i.e. peak hour.\nwhen file is read in sf, can easily convert to ppp\ndissecting the code - it comes in 4 chunks:\n\nthe first to load the file\nthe second to filter missing values\nthe third is to get the coordinates and transform the crs\ntransform it\n\nwithout the filter function in between, running the code will give you error, this is because there are missing values for longitude and latitude"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events that occur on or alongside a network. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand, can be a road network or a river network.\nIn this hands-on exercise, I will use appropriate functions of the spNetwork package to:\n\nderive network kernel density estimation (NKDE) and\nperform network G-function and K-function analysis\n\n\n\n\nIn this study, the spatial distribution of childcare centres in the Punggol Planning Area will be analysed. For this study, two geospatial datasets will be used:\n\nPunggol_St, a line features geospatial data which stores the road network within the Punggol Planning Area\nPunggol_CC, a point features geospatial data which stores the location of childcare centres within the Punggol Planning Area\n\nBoth datasets are in the ESRI shapefile format.\n\n\n\nIn this hands-on exercise, four R packages will be used:\n\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines and polygons.\ntmap which provides functions for plotting cartographic quality static point pattern maps or interactive maps by using leaflet API\n\n\npacman:::p_load(spNetwork,sf,tmap,tidyverse)\n\n\n\n\nThe code chunk below uses st_read() of sf package to import Punggol_St and Pungol_CC geospatial datasets into RStudio as sf dataframes:\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the simple features data tables in RStudio or use the code chunk below to print the content of the network and childcare simple features:\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that spNetwork would require the geospatial data to contain complete CRS information.\n\n\nI also double check the EPSG code for both dataframes to ensure that EPSG code is correctly stated as 3414:\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nBefore going into analysis, it is always a good practice to visualise the geospatial data. There are two ways to do so.\nOne way is to use plot() of Base R as shown in the code chunk below:\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\nA second way is to use the mapping function of tmap package to visualise the geospatial data with high cartographic quality and in an interactive manner:\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots()+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\nIn this section, we will perform NKDE analysis using appropriate functions provided in the spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed using lixelize_lines() of spNetwork:\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 375)\n\nIn the code above,\n\nlength of a lixel, lx_length, is set to 700m and\nminimum length of a lixel, mindist, is set to 350m\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is added to the previous lixel. If NULL, the mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\n\n\n\n\n\nNote\n\n\n\nThere is another function called lixelize_lines.mc() which provides multicore support.\n\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame i.e. samples, with line center points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at the center of the line based on the length of the line.\n\n\n\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nUsing the code above gives an error message that the number of columns of arguments do not match. Comparing both dataframes, it is noted that the childcare dataframe contain points that have z coordinates aka points are 3D while network dataframe contain points in 2D format. Based on Details on NKDE, it seems like 2D points are required for the computation and hence an additional step of dropping the z-dimension of points in childcare dataframe is required. This is done using the st_zm() function:\n\nchildcare &lt;- st_zm(childcare)\n\nRerunning the NKDE computation code:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nLearning lessons from the code chunk above:\n\nkernel_name argument indicates that quartic kernel is used. Other possible kernel methods supported by spNetwork are triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov or uniform\nmethod argument indicate that simple method is used to calculate the NKDE. At present, spNetwork support three popular methods:\n\nsimple: this method proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an area unit.\ndiscontinuous: this method equally divides the mass density of an event at intersections of lixels.\ncontinuous: if the discontinuous method is unbiased, it leads to a discontinuous kernel function which is counter-intuitive. The continuous method divides the mass density at the intersection but adjusts the density before the intersection to make the function continuous.\n\n\n\n\nBefore visualising NKDE values, the code chunk below will be used to insert the computed density values i.e. densities into the samples and lixel objects as density field:\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince the SVY21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from the number of events per metre to number of events per kilometre, to help the mapping:\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below then uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation:\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col = \"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\nIn this section, complete spatial randomness (CSR) test will be performed using kfunctions() of spNetwork package. The null hypothesis is defined as such:\nH0: The observed spatial point events (i.e. distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf the hypothesis is rejected, we may infer that the distribution of the childcare centres is spatially interacting and dependent on each other and thus, may form non-random patterns.\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 50,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nLearning points from the code chunk above - there are 10 arguments used in the code chunk:\n\nlines: a SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame else it may crash if there are invalid geometries\npoints: a SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: a double, the start value for evaluating K- and G-functions\nend: a double, the last value for evaluating K- and G-functions\nstep: a double, the jump for evaluating the K- and G-functions\nwidth: width of each donut for the G-function\nnsim: indicates the number of Monte Carlo simulations required. Most of the time, more simulations are required for inference\nresolution: when simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When the resolution is null, the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points will be selected vertices on the new network.\nconf_int: a double, indicating the width confidence interval (default = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA: ggplot2 object representing the values of the k-function\nplotgA: ggplot2 object representing the values of the g-function\nvaluesA: a dataframe with the values used to build the plots\n\nThe ggplot2 object of k-function can be visualised using the code chunk below:\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol Planning Area. The gray envelope represents the results of the 50 simulations in the interval of 2.5% to 97.5%. As the blue line between the distances of 250m to 400m is below the gray area, we can infer that the childcare centres in Punggol Planning Area resemble regular pattern at the distance of 250m to 400m.\n\n\n\n\nspNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events that occur on or alongside a network. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand, can be a road network or a river network.\nIn this hands-on exercise, I will use appropriate functions of the spNetwork package to:\n\nderive network kernel density estimation (NKDE) and\nperform network G-function and K-function analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this study, the spatial distribution of childcare centres in the Punggol Planning Area will be analysed. For this study, two geospatial datasets will be used:\n\nPunggol_St, a line features geospatial data which stores the road network within the Punggol Planning Area\nPunggol_CC, a point features geospatial data which stores the location of childcare centres within the Punggol Planning Area\n\nBoth datasets are in the ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-launching-the-r-packages",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, four R packages will be used:\n\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines and polygons.\ntmap which provides functions for plotting cartographic quality static point pattern maps or interactive maps by using leaflet API\n\n\npacman:::p_load(spNetwork,sf,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-import-and-preparation",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "The code chunk below uses st_read() of sf package to import Punggol_St and Pungol_CC geospatial datasets into RStudio as sf dataframes:\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the simple features data tables in RStudio or use the code chunk below to print the content of the network and childcare simple features:\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that spNetwork would require the geospatial data to contain complete CRS information.\n\n\nI also double check the EPSG code for both dataframes to ensure that EPSG code is correctly stated as 3414:\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-geospatial-data",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Before going into analysis, it is always a good practice to visualise the geospatial data. There are two ways to do so.\nOne way is to use plot() of Base R as shown in the code chunk below:\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\nA second way is to use the mapping function of tmap package to visualise the geospatial data with high cartographic quality and in an interactive manner:\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots()+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-kde-nkde-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-kde-nkde-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, we will perform NKDE analysis using appropriate functions provided in the spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed using lixelize_lines() of spNetwork:\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 375)\n\nIn the code above,\n\nlength of a lixel, lx_length, is set to 700m and\nminimum length of a lixel, mindist, is set to 350m\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is added to the previous lixel. If NULL, the mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\n\n\n\n\n\nNote\n\n\n\nThere is another function called lixelize_lines.mc() which provides multicore support.\n\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame i.e. samples, with line center points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at the center of the line based on the length of the line.\n\n\n\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nUsing the code above gives an error message that the number of columns of arguments do not match. Comparing both dataframes, it is noted that the childcare dataframe contain points that have z coordinates aka points are 3D while network dataframe contain points in 2D format. Based on Details on NKDE, it seems like 2D points are required for the computation and hence an additional step of dropping the z-dimension of points in childcare dataframe is required. This is done using the st_zm() function:\n\nchildcare &lt;- st_zm(childcare)\n\nRerunning the NKDE computation code:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nLearning lessons from the code chunk above:\n\nkernel_name argument indicates that quartic kernel is used. Other possible kernel methods supported by spNetwork are triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov or uniform\nmethod argument indicate that simple method is used to calculate the NKDE. At present, spNetwork support three popular methods:\n\nsimple: this method proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an area unit.\ndiscontinuous: this method equally divides the mass density of an event at intersections of lixels.\ncontinuous: if the discontinuous method is unbiased, it leads to a discontinuous kernel function which is counter-intuitive. The continuous method divides the mass density at the intersection but adjusts the density before the intersection to make the function continuous.\n\n\n\n\nBefore visualising NKDE values, the code chunk below will be used to insert the computed density values i.e. densities into the samples and lixel objects as density field:\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince the SVY21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from the number of events per metre to number of events per kilometre, to help the mapping:\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below then uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation:\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col = \"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-constrained-g--and-k-function-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#network-constrained-g--and-k-function-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, complete spatial randomness (CSR) test will be performed using kfunctions() of spNetwork package. The null hypothesis is defined as such:\nH0: The observed spatial point events (i.e. distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf the hypothesis is rejected, we may infer that the distribution of the childcare centres is spatially interacting and dependent on each other and thus, may form non-random patterns.\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 50,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nLearning points from the code chunk above - there are 10 arguments used in the code chunk:\n\nlines: a SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame else it may crash if there are invalid geometries\npoints: a SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: a double, the start value for evaluating K- and G-functions\nend: a double, the last value for evaluating K- and G-functions\nstep: a double, the jump for evaluating the K- and G-functions\nwidth: width of each donut for the G-function\nnsim: indicates the number of Monte Carlo simulations required. Most of the time, more simulations are required for inference\nresolution: when simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When the resolution is null, the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points will be selected vertices on the new network.\nconf_int: a double, indicating the width confidence interval (default = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA: ggplot2 object representing the values of the k-function\nplotgA: ggplot2 object representing the values of the g-function\nvaluesA: a dataframe with the values used to build the plots\n\nThe ggplot2 object of k-function can be visualised using the code chunk below:\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol Planning Area. The gray envelope represents the results of the 50 simulations in the interval of 2.5% to 97.5%. As the blue line between the distances of 250m to 400m is below the gray area, we can infer that the childcare centres in Punggol Planning Area resemble regular pattern at the distance of 250m to 400m."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#references",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "spNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events that occur on or alongside a network. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand, can be a road network or a river network.\nIn this hands-on exercise, I will use appropriate functions of the spNetwork package to:\n\nderive network kernel density estimation (NKDE) and\nperform network G-function and K-function analysis\n\n\n\n\nIn this study, the spatial distribution of childcare centres in the Punggol Planning Area will be analysed. For this study, two geospatial datasets will be used:\n\nPunggol_St, a line features geospatial data which stores the road network within the Punggol Planning Area\nPunggol_CC, a point features geospatial data which stores the location of childcare centres within the Punggol Planning Area\n\nBoth datasets are in the ESRI shapefile format.\n\n\n\nIn this hands-on exercise, four R packages will be used:\n\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines and polygons.\ntmap which provides functions for plotting cartographic quality static point pattern maps or interactive maps by using leaflet API\n\n\npacman:::p_load(spNetwork,sf,tmap,tidyverse)\n\n\n\n\nThe code chunk below uses st_read() of sf package to import Punggol_St and Pungol_CC geospatial datasets into RStudio as sf dataframes:\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer=\"Punggol_CC\") %&gt;%\n  st_zm(drop = TRUE,\n        what = \"ZM\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nalways take a look at the data after importing\nuse sf to extract data and save it as a new rds, to avoid re-running data prep steps - this is useful for Take-home Ex01 (sf for geospatial, tidyverse for aspatial)\nspNetwork is different from spatstat - to note that the former has shifted to sf hence input for the former is always in the form of sf\ntidyverse offers lubridate to tidy datetime field\nimporting shp files always need to provide dsn and layer (no need extension)\nfor take-home ex01, to break down folders in “data” file to “rawdata” and “rds” (for derived data) for clarity. all will not be pushed to github as long as “data/” is in .gitignore\nexamining “network” data, linear data must be in LINESTRING, cannot be MULTI-LINESTRING version - if its the latter, have to use st function to break the multi-line into single line, otherwise will have error message\nexamining “childcare” data (from Data.gov, where they convert to kml before converting to shp file hence dimension is XYZ, got Z data vs that of “network” where dimension is XY) however spNetwork can only simple feature hence have to remove z data from “childcare”\n\n\n\nWe can examine the structure of the simple features data tables in RStudio or use the code chunk below to print the content of the network and childcare simple features:\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                  geometry\n1   kml_10 POINT (36173.81 42550.33)\n2   kml_99 POINT (36479.56 42405.21)\n3  kml_100 POINT (36618.72 41989.13)\n4  kml_101 POINT (36285.37 42261.42)\n5  kml_122  POINT (35414.54 42625.1)\n6  kml_161 POINT (36545.16 42580.09)\n7  kml_172 POINT (35289.44 44083.57)\n8  kml_188 POINT (36520.56 42844.74)\n9  kml_205  POINT (36924.01 41503.6)\n10 kml_222 POINT (37141.76 42326.36)\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that spNetwork would require the geospatial data to contain complete CRS information.\n\n\nI also double check the EPSG code for both dataframes to ensure that EPSG code is correctly stated as 3414:\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nBefore going into analysis, it is always a good practice to visualise the geospatial data. There are two ways to do so.\nOne way is to use plot() of Base R as shown in the code chunk below:\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nadd=T means True (short-form)\nthe code above is plotting twice\nimportance of st_geometry: without it, will have more than 1 plot for network (see code below) because “network” has 3 columns - plot(network) will pull out individual columns and plot - so for LINK_ID, colors are mapped to LINK_ID and for ST_NAME, colors are mapped to ST_NAME. st_geometry will hence just pull the geometry (just the road network without the attributes) rather than all columns. does not matter for “childcare” cause you already indicate the color to be the same (red)\n\n\n\n\n\n\nplot(network)\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\nA second way is to use the mapping function of tmap package to visualise the geospatial data with high cartographic quality and in an interactive manner:\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots()+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nCan change the colour of the dots to red to get similar map as above. Define using the extent of the map layer. There are also other symbols that can be used beyond dots (dots vs bubble - former keep size constant when you zoom in and out) (reference):\n\n\n\n\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots(col = \"red\")+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nLeaflet is a lightweight application that allows one to turn on and off the different variables “childcare” and “network”\n\n\n\nCan also toggle between different views\n\n\n\nIf meet with problems rendering, to upgrade tmap\nProf tends to use tmap over plot as it provides more flexibility\nAlways change to plot mode before moving to next section, otherwise it will consume a lot of resources when rendering\n\n\n\n\n\n\n\nIn this section, we will perform NKDE analysis using appropriate functions provided in the spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed using lixelize_lines() of spNetwork:\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 350)\n\nIn the code above,\n\nlength of a lixel, lx_length, is set to 700m and\nminimum length of a lixel, mindist, is set to 350m\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is added to the previous lixel. If NULL, the mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\n\n\n\n\n\nNote\n\n\n\nThere is another function called lixelize_lines.mc() which provides multicore support.\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nProf set the lixel length at 700m as based on NTU study, 700m is a reasonable walking distance based on Singapore weather while minimum distance was set at 350m by instinct. This is also based on the understanding that parents/grandparents walk their children to the childcare centre.\nat length = 700, mindist = 350, lixels generate 2645 observations while network has 2642 observations.\nfor take-home ex1, need to experiment with different length and mindist cause don’t have context for that.\n\nQuestion: what is the basis for a good cut-off? Prof says calculate the nearest neighbour, test with different distances, plot it out to see which one allows to catch accidents, don’t take a distance that don’t allow you to pick up accidents (cause that would be useless) but also also avoid a distance that captures too many\n\n\n\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame i.e. samples, with line center points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at the center of the line based on the length of the line.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\n“samples” and “lixels” should have the same observations, Prof suggest to plot out\n\n\n\n\ntmap_mode('view')\ntm_shape(lixels) +\n  tm_lines() +\ntm_shape(samples) +\n  tm_dots(size=0.01)\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nTry not to use kernel_name = “gaussian” method if density tends to negative\noutput from above is a list of numbers (see “densities” below) which will have to be added as a new field under 3.6.3.1 Visualising NKDE:\n\nNote that if want to do the step above, do not sort the data cause the sequence will change and when you map over, will no longer map to the same point.\n\n\n\nUsing the code above gives an error message that the number of columns of arguments do not match. Comparing both dataframes, it is noted that the childcare dataframe contain points that have z coordinates aka points are 3D while network dataframe contain points in 2D format. Based on Details on NKDE, it seems like 2D points are required for the computation and hence an additional step of dropping the z-dimension of points in childcare dataframe is required. This is done using the st_zm() function:\n\nchildcare &lt;- st_zm(childcare)\n\nRerunning the NKDE computation code:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nLearning lessons from the code chunk above:\n\nkernel_name argument indicates that quartic kernel is used. Other possible kernel methods supported by spNetwork are triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov or uniform\nmethod argument indicate that simple method is used to calculate the NKDE. At present, spNetwork support three popular methods:\n\nsimple: this method proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an area unit.\ndiscontinuous: this method equally divides the mass density of an event at intersections of lixels.\ncontinuous: if the discontinuous method is unbiased, it leads to a discontinuous kernel function which is counter-intuitive. The continuous method divides the mass density at the intersection but adjusts the density before the intersection to make the function continuous.\n\n\n\n\nBefore visualising NKDE values, the code chunk below will be used to insert the computed density values i.e. densities into the samples and lixel objects as density field:\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince the SVY21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from the number of events per metre to number of events per kilometre, to help the mapping:\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nalways note your unit of measurement\n\n\n\nThe code below then uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation:\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col = \"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\nIn this section, complete spatial randomness (CSR) test will be performed using kfunctions() of spNetwork package. The null hypothesis is defined as such:\nH0: The observed spatial point events (i.e. distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf the hypothesis is rejected, we may infer that the distribution of the childcare centres is spatially interacting and dependent on each other and thus, may form non-random patterns.\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 49,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nLearning points from the code chunk above - there are 10 arguments used in the code chunk:\n\nlines: a SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame else it may crash if there are invalid geometries\npoints: a SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: a double, the start value for evaluating K- and G-functions\nend: a double, the last value for evaluating K- and G-functions\nstep: a double, the jump for evaluating the K- and G-functions\nwidth: width of each donut for the G-function\nnsim: indicates the number of Monte Carlo simulations required. Most of the time, more simulations are required for inference\nresolution: when simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When the resolution is null, the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points will be selected vertices on the new network.\nconf_int: a double, indicating the width confidence interval (default = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA: ggplot2 object representing the values of the k-function\nplotgA: ggplot2 object representing the values of the g-function\nvaluesA: a dataframe with the values used to build the plots\n\nThe ggplot2 object of k-function can be visualised using the code chunk below:\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol Planning Area. The gray envelope represents the results of the 50 simulations in the interval of 2.5% to 97.5%. As the blue line between the distances of 250m to 400m is below the gray area, we can infer that the childcare centres in Punggol Planning Area resemble regular pattern at the distance of 250m to 400m.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nnote that you can call either plotk or plotg despite the name of the function being kfunctions()\nbefore 250m and after 400m, is complete spatial randomness\nregular pattern occur between 250m to 400m means that childcare centres have a tendency to occur that distance apart within the Punggol area. contrasts with in-class exercise 2/hands-on exercise 2 finding.\n\n\n\n\n\n\n\nparameters that enable detection of behavioural or environmental factors can be used to create subset point events i.e. to determine whether caused by people drunk, people ruthless driver or whether it occurred at a junction (these are found within the accident report data)\nextent to note that its Bangkok Metropolitan Region (to select out the 6 regions that define the boundary) - note from the Wikipedia page and extract from Thailand - Subnational Administrative Boundaries on HDX (do not use the OpenStreetMap version as its much larger, more data)\nto note to categorise data to “rawdata” and “rds”\nstart the file by going to Quarto Document –&gt; create Take-home_Ex01"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods specially developed for analysing spatial point events that occur on or alongside a network. The spatial point event can be locations of traffic accidents or childcare centres for example. The network, on the other hand, can be a road network or a river network.\nIn this hands-on exercise, I will use appropriate functions of the spNetwork package to:\n\nderive network kernel density estimation (NKDE) and\nperform network G-function and K-function analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#the-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#the-data",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "In this study, the spatial distribution of childcare centres in the Punggol Planning Area will be analysed. For this study, two geospatial datasets will be used:\n\nPunggol_St, a line features geospatial data which stores the road network within the Punggol Planning Area\nPunggol_CC, a point features geospatial data which stores the location of childcare centres within the Punggol Planning Area\n\nBoth datasets are in the ESRI shapefile format."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-launching-the-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-launching-the-r-packages",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, four R packages will be used:\n\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, process and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines and polygons.\ntmap which provides functions for plotting cartographic quality static point pattern maps or interactive maps by using leaflet API\n\n\npacman:::p_load(spNetwork,sf,tmap,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "The code chunk below uses st_read() of sf package to import Punggol_St and Pungol_CC geospatial datasets into RStudio as sf dataframes:\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer=\"Punggol_CC\") %&gt;%\n  st_zm(drop = TRUE,\n        what = \"ZM\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nalways take a look at the data after importing\nuse sf to extract data and save it as a new rds, to avoid re-running data prep steps - this is useful for Take-home Ex01 (sf for geospatial, tidyverse for aspatial)\nspNetwork is different from spatstat - to note that the former has shifted to sf hence input for the former is always in the form of sf\ntidyverse offers lubridate to tidy datetime field\nimporting shp files always need to provide dsn and layer (no need extension)\nfor take-home ex01, to break down folders in “data” file to “rawdata” and “rds” (for derived data) for clarity. all will not be pushed to github as long as “data/” is in .gitignore\nexamining “network” data, linear data must be in LINESTRING, cannot be MULTI-LINESTRING version - if its the latter, have to use st function to break the multi-line into single line, otherwise will have error message\nexamining “childcare” data (from Data.gov, where they convert to kml before converting to shp file hence dimension is XYZ, got Z data vs that of “network” where dimension is XY) however spNetwork can only simple feature hence have to remove z data from “childcare”\n\n\n\nWe can examine the structure of the simple features data tables in RStudio or use the code chunk below to print the content of the network and childcare simple features:\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                  geometry\n1   kml_10 POINT (36173.81 42550.33)\n2   kml_99 POINT (36479.56 42405.21)\n3  kml_100 POINT (36618.72 41989.13)\n4  kml_101 POINT (36285.37 42261.42)\n5  kml_122  POINT (35414.54 42625.1)\n6  kml_161 POINT (36545.16 42580.09)\n7  kml_172 POINT (35289.44 44083.57)\n8  kml_188 POINT (36520.56 42844.74)\n9  kml_205  POINT (36924.01 41503.6)\n10 kml_222 POINT (37141.76 42326.36)\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that spNetwork would require the geospatial data to contain complete CRS information.\n\n\nI also double check the EPSG code for both dataframes to ensure that EPSG code is correctly stated as 3414:\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Before going into analysis, it is always a good practice to visualise the geospatial data. There are two ways to do so.\nOne way is to use plot() of Base R as shown in the code chunk below:\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nadd=T means True (short-form)\nthe code above is plotting twice\nimportance of st_geometry: without it, will have more than 1 plot for network (see code below) because “network” has 3 columns - plot(network) will pull out individual columns and plot - so for LINK_ID, colors are mapped to LINK_ID and for ST_NAME, colors are mapped to ST_NAME. st_geometry will hence just pull the geometry (just the road network without the attributes) rather than all columns. does not matter for “childcare” cause you already indicate the color to be the same (red)\n\n\n\n\n\n\nplot(network)\nplot(childcare,add=T,col='red',pch=19)\n\n\n\n\n\n\n\n\nA second way is to use the mapping function of tmap package to visualise the geospatial data with high cartographic quality and in an interactive manner:\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots()+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nCan change the colour of the dots to red to get similar map as above. Define using the extent of the map layer. There are also other symbols that can be used beyond dots (dots vs bubble - former keep size constant when you zoom in and out) (reference):\n\n\n\n\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots(col = \"red\")+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nLeaflet is a lightweight application that allows one to turn on and off the different variables “childcare” and “network”\n\n\n\nCan also toggle between different views\n\n\n\nIf meet with problems rendering, to upgrade tmap\nProf tends to use tmap over plot as it provides more flexibility\nAlways change to plot mode before moving to next section, otherwise it will consume a lot of resources when rendering"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-kde-nkde-analysis",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-kde-nkde-analysis",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "In this section, we will perform NKDE analysis using appropriate functions provided in the spNetwork package.\n\n\nBefore computing NKDE, the Spatial Lines object needs to be cut into lixels with a specified minimal distance. This task can be performed using lixelize_lines() of spNetwork:\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 350)\n\nIn the code above,\n\nlength of a lixel, lx_length, is set to 700m and\nminimum length of a lixel, mindist, is set to 350m\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is added to the previous lixel. If NULL, the mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified.\n\n\n\n\n\n\nNote\n\n\n\nThere is another function called lixelize_lines.mc() which provides multicore support.\n\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nProf set the lixel length at 700m as based on NTU study, 700m is a reasonable walking distance based on Singapore weather while minimum distance was set at 350m by instinct. This is also based on the understanding that parents/grandparents walk their children to the childcare centre.\nat length = 700, mindist = 350, lixels generate 2645 observations while network has 2642 observations.\nfor take-home ex1, need to experiment with different length and mindist cause don’t have context for that.\n\nQuestion: what is the basis for a good cut-off? Prof says calculate the nearest neighbour, test with different distances, plot it out to see which one allows to catch accidents, don’t take a distance that don’t allow you to pick up accidents (cause that would be useless) but also also avoid a distance that captures too many\n\n\n\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame i.e. samples, with line center points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at the center of the line based on the length of the line.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\n“samples” and “lixels” should have the same observations, Prof suggest to plot out\n\n\n\n\ntmap_mode('view')\ntm_shape(lixels) +\n  tm_lines() +\ntm_shape(samples) +\n  tm_dots(size=0.01)\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nTry not to use kernel_name = “gaussian” method if density tends to negative\noutput from above is a list of numbers (see “densities” below) which will have to be added as a new field under 3.6.3.1 Visualising NKDE:\n\nNote that if want to do the step above, do not sort the data cause the sequence will change and when you map over, will no longer map to the same point.\n\n\n\nUsing the code above gives an error message that the number of columns of arguments do not match. Comparing both dataframes, it is noted that the childcare dataframe contain points that have z coordinates aka points are 3D while network dataframe contain points in 2D format. Based on Details on NKDE, it seems like 2D points are required for the computation and hence an additional step of dropping the z-dimension of points in childcare dataframe is required. This is done using the st_zm() function:\n\nchildcare &lt;- st_zm(childcare)\n\nRerunning the NKDE computation code:\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nLearning lessons from the code chunk above:\n\nkernel_name argument indicates that quartic kernel is used. Other possible kernel methods supported by spNetwork are triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov or uniform\nmethod argument indicate that simple method is used to calculate the NKDE. At present, spNetwork support three popular methods:\n\nsimple: this method proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an area unit.\ndiscontinuous: this method equally divides the mass density of an event at intersections of lixels.\ncontinuous: if the discontinuous method is unbiased, it leads to a discontinuous kernel function which is counter-intuitive. The continuous method divides the mass density at the intersection but adjusts the density before the intersection to make the function continuous.\n\n\n\n\nBefore visualising NKDE values, the code chunk below will be used to insert the computed density values i.e. densities into the samples and lixel objects as density field:\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince the SVY21 projection system is in metres, the computed density values are very small i.e. 0.0000005. The code chunk below is used to rescale the density values from the number of events per metre to number of events per kilometre, to help the mapping:\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nalways note your unit of measurement\n\n\n\nThe code below then uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation:\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col = \"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-g--and-k-function-analysis",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-g--and-k-function-analysis",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "In this section, complete spatial randomness (CSR) test will be performed using kfunctions() of spNetwork package. The null hypothesis is defined as such:\nH0: The observed spatial point events (i.e. distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf the hypothesis is rejected, we may infer that the distribution of the childcare centres is spatially interacting and dependent on each other and thus, may form non-random patterns.\n\nkfun_childcare &lt;- kfunctions(network,\n                             childcare,\n                             start = 0,\n                             end = 1000,\n                             step = 50,\n                             width = 50,\n                             nsim = 49,\n                             resolution = 50,\n                             verbose = FALSE,\n                             conf_int = 0.05)\n\nLearning points from the code chunk above - there are 10 arguments used in the code chunk:\n\nlines: a SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame else it may crash if there are invalid geometries\npoints: a SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: a double, the start value for evaluating K- and G-functions\nend: a double, the last value for evaluating K- and G-functions\nstep: a double, the jump for evaluating the K- and G-functions\nwidth: width of each donut for the G-function\nnsim: indicates the number of Monte Carlo simulations required. Most of the time, more simulations are required for inference\nresolution: when simulating random points on the network, selecting a resolution will greatly reduce the calculation time. When the resolution is null, the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points will be selected vertices on the new network.\nconf_int: a double, indicating the width confidence interval (default = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA: ggplot2 object representing the values of the k-function\nplotgA: ggplot2 object representing the values of the g-function\nvaluesA: a dataframe with the values used to build the plots\n\nThe ggplot2 object of k-function can be visualised using the code chunk below:\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol Planning Area. The gray envelope represents the results of the 50 simulations in the interval of 2.5% to 97.5%. As the blue line between the distances of 250m to 400m is below the gray area, we can infer that the childcare centres in Punggol Planning Area resemble regular pattern at the distance of 250m to 400m.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nnote that you can call either plotk or plotg despite the name of the function being kfunctions()\nbefore 250m and after 400m, is complete spatial randomness\nregular pattern occur between 250m to 400m means that childcare centres have a tendency to occur that distance apart within the Punggol area. contrasts with in-class exercise 2/hands-on exercise 2 finding."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#in-class-notes-on-take-home-ex01",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#in-class-notes-on-take-home-ex01",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "parameters that enable detection of behavioural or environmental factors can be used to create subset point events i.e. to determine whether caused by people drunk, people ruthless driver or whether it occurred at a junction (these are found within the accident report data)\nextent to note that its Bangkok Metropolitan Region (to select out the 6 regions that define the boundary) - note from the Wikipedia page and extract from Thailand - Subnational Administrative Boundaries on HDX (do not use the OpenStreetMap version as its much larger, more data)\nto note to categorise data to “rawdata” and “rds”\nstart the file by going to Quarto Document –&gt; create Take-home_Ex01"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#in-class-notes-from-prof-kam",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#in-class-notes-from-prof-kam",
    "title": "Take-home Exercise 1",
    "section": "In-class notes from Prof Kam:",
    "text": "In-class notes from Prof Kam:\n\nAn example is shown below to extract month and day of the incident_datetime:\n\n\nrdacc_sf &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 32467) %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(dayofweek = day(incident_datetime))\n\n\nThe 2nd month line is more specific and has order since its a factor.\nWGS 84 got 32467 and 324648 - take a good look at it before deciding which is the right one (above is just an example)\nnote that there’s hidden problem inside the data i.e. missing values (can mutate and omit missing values in the code above)\n\n\nwrite_rds(rdacc_sf,\"data/rds/rdacc_sf.rds\")\n\n\nwrite_rds will take care of all the objects within the dataset; once you got this file “#| eval: false” to avoid running the data wrangling code\n\n\nacc &lt;- read_rds(\"data/rds/rdacc_sf.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Note\n\n\n\n\n\n\noptions(timeout = 2000)\n\n\n\n\n\n\nAccording to the World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year and leave between 20 to 50 million people with non-fatal injuries. Vulnerable road users, such as pedestrians, cyclists and motorcyclists, make up more than half of all road traffic deaths.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5 to 29, however two-thirds of road traffic fatalities occur among people of working ages, from 18 to 59 years. Further, nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries make up only around 60% of the world’s vehicles.\nBesides human suffering, road traffic injuries also result in a heavy economic burden on victims and their families, through treatment costs for the injured and loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nAccording to the WHO, Thailand’s roads are the deadliest in Southeast Asia and among the worst in the world - about 20,000 people die in road accidents each year, or about 56 deaths a day.\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which make up the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed as ‘black spots’ which are distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes.\n\n\n\nBy and large, road traffic accidents can be attributed by two major factors, namely behavioural and environmental factors.\n\nBehavioural factors in driving are considered to be major causes of traffic accidents either in direct or indirect manner (Lewin, 1982). These factors can be further grouped into driver behavior (driver/driving style) and driver performance (driver/driving skills) (Elander, West, & French, 1993).\nEnvironmental factors, on the other hand, includes but not limited to weather conditions such as poor visibility during heavy rain or fogs as well as road conditions such as sharp bends, slippery slopes, and blind spots.\n\nPrevious studies have demonstrated the significant potential of Spatial Point Patterns Analysis (SPPA) in exploring and identifying factors influencing road traffic accidents. However, these studies often focus solely on either behavioral or environmental factors, with limited consideration of temporal factors such as season, day of the week, or time of day.\nIn view of this, in this hands-on exercise, we will determine factors that affect road traffic accidents in the Bangkok Metropolitan Region (BMR) by employing both spatial and spatio-temporal point patterns analysis methods.\nThe specific objectives are as follows:\n\nTo visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nTo conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nTo conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods.\n\n\n\n\nKey packages that are installed are:\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)\n\n\n\n\nFor the purpose of this exercise, three basic data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle - comprised records of road accidents in Thailand from ~2019 to 2022, based on information provided by the Office of the Permanent Secretary, Ministry of Transport.\nThailand - Subnational Administrative Boundaries on HDX\nThailand Roads (OpenStreetMap Export) on HDX\n\n\n\n\n\n\nThe data is imported using the code below:\n\nroadacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nTaking a glimpse at the data to determine the fields in the data:\n\nglimpse(roadacc)\n\nRows: 81,735\nColumns: 18\n$ acc_code                    &lt;dbl&gt; 571905, 3790870, 599075, 571924, 599523, 5…\n$ incident_datetime           &lt;dttm&gt; 2019-01-01 00:00:00, 2019-01-01 00:03:00,…\n$ report_datetime             &lt;dttm&gt; 2019-01-02 06:11:00, 2020-02-20 13:48:00,…\n$ province_th                 &lt;chr&gt; \"ลพบุรี\", \"อุบลราชธานี\", \"ประจวบคีรีขันธ์\", \"เชียงใ…\n$ province_en                 &lt;chr&gt; \"Loburi\", \"Ubon Ratchathani\", \"Prachuap Kh…\n$ agency                      &lt;chr&gt; \"department of rural roads\", \"department o…\n$ route                       &lt;chr&gt; \"แยกทางหลวงหมายเลข 21 (กม.ที่ 31+000) - บ้านวั…\n$ vehicle_type                &lt;chr&gt; \"motorcycle\", \"private/passenger car\", \"mo…\n$ presumed_cause              &lt;chr&gt; \"driving under the influence of alcohol\", …\n$ accident_type               &lt;chr&gt; \"other\", \"rollover/fallen on straight road…\n$ number_of_vehicles_involved &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, …\n$ number_of_fatalities        &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, …\n$ number_of_injuries          &lt;dbl&gt; 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, …\n$ weather_condition           &lt;chr&gt; \"clear\", \"clear\", \"clear\", \"clear\", \"clear…\n$ latitude                    &lt;dbl&gt; 14.959105, 15.210738, 12.374259, 18.601721…\n$ longitude                   &lt;dbl&gt; 100.87346, 104.86269, 99.90795, 98.80420, …\n$ road_description            &lt;chr&gt; \"straight road\", \"straight road\", \"wide cu…\n$ slope_description           &lt;chr&gt; \"no slope\", \"no slope\", \"slope area\", \"no …\n\n\nThere are 81735 rows and 18 variables. Further details about the important variables that would be needed for analysis can be found in the dropdown box below:\n\n\n\n\n\n\nMore information about variables for analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nField\nDescription\nPurpose of data i.e. what it might indicate\n\n\n\n\nincident_datetime\nThe date and time of the accident occurrence\nwhether accidents tend to occur at specific:\n\nmonths\nday of week\ntime of the day\n\n\n\nreport_datetime\nThe date and time when the accident was reported\nefficacy at which accident was reported could indicate:\n\nhow busy the road segment is\nhow tightly the road is being monitored/ whether there is a lapse in the management of the road\n\n\n\nprovince_en\nThe name of the province in Thailand, written in English\nsupports the filtering of data to just BMR\n\n\nagency\nThe government agency responsible for the road and traffic management\npinpoints the responsible government agency, could indicate whether there is a need for government agency to take corrective actions\n\n\nroute\nThe route or road segment where the accident occurred\nwhile the data can be used to determine frequency of incident at different locations, it is not useful for our case as it’s in the Thai language\n\n\nvehicle_type\nThe type of vehicle involved in the accident\ncan determine frequency of vehicle types involved in accidents\n\n\npresumed_cause\nThe presumed cause or reason for the accident\ncan determine distribution of cause for accidents\n\n\naccident_type\nThe type or nature of the accident\ncan determine distribution of nature of accidents\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nweather_condition\nThe weather condition at the time of the accident\ncan determine how much weather conditions can affect the occurrence of accidents\n\n\nlatitude\nThe latitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nlongitude\nThe longitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred\ncan determine how road types can affect the occurrence of accidents\n\n\nslope_description\nThe description of the slope condition at the accident location\ncan determine how presence of slopes can affect the occurrence of accidents\n\n\n\n\n\n\n\n\n\nWe will first drop “province_th” as it indicates the provinces in the Thai language.\n\nroadacc &lt;- roadacc[, !names(roadacc) %in% c(\"province_th\",\"route\")]\n\n\n\n\nWe then determine the unique provinces within the dataset and scan through the province names (i.e. in case there are any entries that refer to the same province but are spelt differently/have spelling mistakes) before filtering the data to just include provinces that are within the BMR:\n\nunique_provinces &lt;- roadacc %&gt;% \n  distinct(province_en) %&gt;%\n  arrange(province_en)\n\nDT::datatable(unique_provinces,class = \"compact\")\n\n\n\n\n\nOur region of interest comprises Bangkok and five adjacent provinces of Nakhon Pathom, Nonthaburi, Pathum Thani, Samut Prakan and Samut Sakhon.\n\nroadacc &lt;- roadacc %&gt;% \n  filter(province_en %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves the data with 13336 rows.\n\n\n\nWe further clean the data by removing rows with missing data:\n\nroadacc &lt;- roadacc %&gt;%\n  drop_na()\n\n\n\n\nWe also check if there are duplicate entries in the dataset:\n\nroadacc$acc_code[duplicated(roadacc$acc_code) == TRUE]\n\nnumeric(0)\n\n\nThere are no duplicate entries.\nGenerating summary statistics of roadacc:\n\nsummary(roadacc)\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nDuring class, Prof Kam had advised to study the data carefully and shared that it was important to filter out data with incomplete coordinates (missing either longitude or latitude or both) and shared that one way to do it was via the code below:\n\nroadacc &lt;- roadacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\")\n\nAs with the drop_na() code above, this way will also leave just 12986 rows of data as the missing data were found in either the longitude or latitude variables.\n\n\n\n\n\nWe convert roadacc data frame into a simple feature data frame and also transform the data from geographic coordinate system (EPSG: 4326 WGS84 Geographic Coordinate System) to projected coordinate system:\n\nroadacc &lt;- st_as_sf(roadacc, \n                    coords = c(\"longitude\", \"latitude\"),\n                    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nBased on the summary statistics of roadacc above, it is noted that the minimum longitude is 99.85° and maximum longitude is 100.94°. While there are 2 possible projected coordinate systems for Thailand, EPSG 32647 and 32648, the appropriate projected coordinate system to transform the data to would be EPSG 32647 as the minimum and maximum longitude of roadacc falls within EPSG 32467’s area of use (between 96°E and 102°E). A comparison of the area of use for both projected coordinate systems is shown below:\n\n\n\n\nEPSG 32647\nEPSG 32648\n\n\n\n\nArea of use\nBetween 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\nBetween 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\n\n\n\n\n\n\nThe incident_datetime and report_datetime variables are in datetime field, we hence utilise these variables and the lubridate() function to generate new variables that represent:\n\nmonth: “inc_month”\nday of week: “inc_dayofweek”\ntime of day: “inc_time”\n\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(inc_year = year(incident_datetime)) %&gt;%\n  mutate(inc_month = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(inc_dayofweek = wday(incident_datetime,\n                              week_start = getOption(\"lubridate.week.start\", 1),\n                              label = TRUE,\n                              abbr = TRUE)) %&gt;%\n  mutate(inc_time = hour(incident_datetime))\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nNote that we can generate month in numbers or in factor format via:\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE))\n\n\n\nWe also determine the gap between the incident time and reporting time and create a new variable “timegap” in hours unit:\n\nroadacc$timegap &lt;- time_length(roadacc$report_datetime - roadacc$incident_datetime, \"hours\")\n\nLogically, the date and time when the accident was reported should be after the date and time of the accident occurrence. Looking at the summary statistics below, there are data entries that could have been erroneously recorded resulting in a negative time gap between report time and incident time (i.e. report time was earlier than incident time). As such, the data was further filtered to remove erroneous data to avoid affecting the analysis:\n\nsummary(roadacc$timegap)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n   -6.917   124.183  1408.000  2200.237  3232.571 10915.750 \n\n\n\nroadacc &lt;- roadacc %&gt;%\n  filter(timegap &gt;= 0)\n\nThis leaves us with 12985 rows.\n\n\n\nWe then save this cleaned data as a rds file:\n\nwrite_rds(roadacc,\"data/rds/roadacc.rds\")\n\n\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nIt is good practice to save cleaned file as a new rds file via write_rds() to avoid re-running the data cleaning and wrangling codes. write_rds() will take care of all the objects within the dataset. Once the file is saved, we can add “#| eval: false” to the data cleaning and wrangling codes to avoid re-running them.\n\n\n\n\n\n\nThe data has different files providing details of the administrative boundaries of Thailand at different administrative levels:\n\nLevel 0 (country)\nLevel 1 (province)\nLevel 2 (district)\nLevel 3 (sub-district, tambon)\n\nAs our area of interest is at Level 1 (province level), we will utilise “tha_admbnda_adm1_rtsd_20220121” that reflects details at province levels and import the data using the code chunk below:\n\nprovincedata = st_read(dsn = \"data/rawdata\", \n                  layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nWe note from the above that it is a multipolygon feature data frame. We note that there are 77 features and 16 fields, and the data is in WGS84 geographic coordinate system.\nWe then take a glimpse of the data:\n\nglimpse(provincedata)\n\n\n\n\nWe note from a glimpse of the data above that there are only a few pertinent fields that we require for our analysis, specifically:\n\nADM1_EN: province name in english\nShape_Leng\nShape_Area\ngeometry\n\nWe hence filter the data to only comprise these fields to make the data frame more manageable:\n\nprovincedata &lt;- provincedata %&gt;%\n  select(\"ADM1_EN\", \"Shape_Leng\",\"Shape_Area\",\"geometry\")\n\n\n\n\nWe also filter to keep only data that are relevant to our area of interest which is BMR:\n\nprovincedata &lt;- provincedata %&gt;% \n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves 6 rows of data and 4 variables.\n\n\n\nFrom the code chunk below, it is noted that the EPSG code for the selectedboundaries data frame is EPSG: 4326:\n\nst_crs(provincedata)\n\nWe will need to reproject provincedata from EPSG code to EPSG: 32647 which is the projected coordinate system to use for BMR, our area of interest:\n\nprovincedata32647 &lt;- st_transform(provincedata, \n                              crs = 32647)\n\nWe check if the EPSG code has been correctly assigned:\n\nst_crs(provincedata32647)\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(provincedata32647,\"data/rds/provincedata32647.rds\")\n\n\nprovincedata32647 &lt;- read_rds(\"data/rds/provincedata32647.rds\")\n\nWe visualise our provincedata32647:\n\ntmap_mode('view')\ntm_shape(provincedata32647)+\n  tm_polygons()\n\n\n\n\ntmap_mode('plot')\n\n\n\n\nWe import the data as follows:\n\nroadlines = st_read(dsn = \"data/rawdata\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe then glimpse at the data:\n\nglimpse(roadlines)\n\n\nst_geometry(roadlines)\n\nThe dataset is very large, with 2792590 rows and 15 variables but we only need to extract relevant information that lie within the BMR for analysis.\n\n\n\nBased on the code chunk below, it is noted that the coordinate system of the roadlines data is missing.\n\nst_crs(roadlines)\n\nBased on the values of the geometry in roadlines, the coordinates seem to be in geographic (latitude/longitude) form, in degrees, typically in a CRS like EPSG:4326 (WGS 84) used for global geographic coordinates. We hence assign the missing EPSG code using the code chunk below:\n\nroadlines4326 &lt;- st_set_crs(roadlines,4326)\n\nWe check the CRS using the code chunk below:\n\nst_crs(roadlines4326)\n\nFor analysis, we would eventually need to overlay the roadlines4326 data with the selectedboundaries32647 data to determine the roads that lie within BMR. In order to perform geoprocessing using two geospatial data, both geospatial data would need to be projected using similar coordinate systems - in this case, it its EPSG: 32647:\n\nroadlines32647 &lt;- st_transform(roadlines4326, \n                              crs = 32647)\n\nWe check the CRS code again:\n\nst_crs(roadlines32647)\n\n\n\n\nBased on the columns in the data frame roadlines32647, the columns that seem relevant/useful to retain for analysis are “highway”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge” and “geometry”.\nHowever before going ahead to retain these variables, we determine the presence of missing data within roadlines32647:\n\nmissing_counts &lt;- sapply(roadlines32647, function(x) sum(is.na(x)))\nprint(missing_counts)\n\nBased on the result above, more than 60% of data is missing for the variable “source” and more than 80% of data is missing for the variables “name”, “name_en”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge”, “layer”, “source” and “name_th”. Given the extent of missing data, we will omit these columns as they would not provide useful information for analysis and only retain the relevant/useful columns “highway” and “geometry” with no missing data:\n\nselectedroadlines &lt;- roadlines32647 %&gt;%\n  select(\"highway\", \"geometry\")\n\n\n\n\nThe code chunk below is used to determine the types of highways in the selectedroadlines data frame:\n\nunique_highway &lt;- unique(selectedroadlines$highway)\nunique_highway &lt;- sort(unique_highway)\n\nunique_highway\n\nTo determine which classes of highway to retain for analysis, the default access restrictions based on the interpretation of Thailand’s Road Traffic Act, 1979 was referenced (source):\n\nA detailed explanation on the type of highways and whether they are included for analysis is indicated in the table below:\n\n\n\nTypes of highway\nDetails\nIncluded for analysis?\n\n\n\n\nabandoned\nUnused/Abandoned roads that are only passable on foot/two-wheel vehicles\nNo\n\n\nbarrier\nRoadside barriers used to protect traffic from roadside obstacles or hazards (source)\nNo\n\n\nbridleway\nA bridle path, also bridleway, equestrian trail, horse riding path, ride, bridle road, or horse trail, is a trail or a thoroughfare that is used by people riding on horses. (source)\nNo\n\n\nbusway\nA dedicated, separate way for the use of public transport buses (source)\nYes\n\n\nconstruction\nNo details provided, could be a highway under construction or a highway used for construction purposes.\nNo (due to ambiguity of information)\n\n\ncorridor\nA land corridor is a type of highway or railway infrastructure that links two or more urban areas (source)\nYes\n\n\ncycleway\nBased on table above, its designated for bicycles and travel by foot is allowed\nNo (as the path is designated mainly for cyclists and might not be so useful for the scope of the exercise)\n\n\nescape\nA road, usually ending in a pile of sand, provided on a hill for drivers to drive into if their brakes fail or on a bend if they lose control of the turn (source)\nYes\n\n\nfootway\nBuilt pathways designed mainly or exclusively for pedestrian access (source)\nNo\n\n\nliving_street\nLittle information provided on use but based on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nmotorway\nExpressway with full access control (source)\nYes\n\n\nmotorway_link\nLink roads (slip roads/ramps) leading to and from a motorway (source) and based on above table, otorcars, motorcycles and pedestrians all have access\nYes\n\n\nparth\nNo relevant information found, assume is a spelling error and meant to be “path”.\nYes (to rename to “path” for analysis)\n\n\npath\nMulti-purpose paths intended for all non-motorized vehicles with the exception of motorcycles (source). Based on table above, motorcycles and pedestrians have access.\nYes\n\n\npaved\nGenerally indicates a road that been covered with flat blocks of stone or concrete, so that it is suitable for walking or driving on.\nYes\n\n\npedestrian\nBased on table above, access only allowed for bicycles and travel by foot\nNo\n\n\nprimary\nTop-level urban road across the city connecting trunk to trunk, or road of equal or greater importance than the primary intercity highway that runs through that city (source)\nYes\n\n\nprimary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nproposed\nProposed cycling routes (source)\nNo\n\n\nraceway\nA course for racing (source)\nNo\n\n\nresidential\nA road within a residential area that gives the public access to one or multiple residences. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nroad\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nsecondary\nMain urban road connecting primary to primary or higher, or road of equal or greater importance than the secondary intercity highway that runs through that city. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nsecondary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nservice\nA minor road that gives access to buildings/places outside a residential area such as an estate, religious site, attraction site, or a specific part of a large estate such as an industrial facility or university campus (source)\nYes\n\n\nsteps\nBased on table above, designated for travel by foot\nNo\n\n\ntertiary\nRoads that are more important than regular unclassified or residential roads, or roads that connect several unclassified or residential roads. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntertiary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrack\nA road whose only function is to provide access to the surrounding land (agricultural, forestry purposes). Most of the time unpaved (source)\nYes\n\n\ntrunk\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrunk_link\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nunclassified\nA significant thru-traffic road used to reach the next settlement or another road of equal or higher importance regardless of its physical conditions. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\n\n\nselectedroadlines &lt;- selectedroadlines %&gt;%\n  filter(highway %in% c(\"busway\",\"corridor\",\"escape\",\"living_street\",\"motorway\",\"motorway_link\", \"parth\", \"path\", \"paved\",\"primary\",\"primary_link\",\"residential\",\"road\",\"secondary\",\"secondary_link\",\"service\",\"tertiary\",\"tertiary_link\",\"track\",\"trunk\",\"trunk_link\",\"unclassified\")) %&gt;%\n  mutate(highway = recode(highway, \"parth\" = \"path\"))\n\n\n\n\nWe require only a subset of the selectedroadlines data to just roads within our area of interest, BMR and hence we utilise st_intersection() to find retain roads that are within the BMR boundaries given by provincedata32647:\n\nroadsbkk &lt;- st_intersection(selectedroadlines,provincedata32647)\n\nThis reduced the data to 564485 rows of data.\n\n\n\nWe save this cleaned data as a new rds file in the interim to facilitate further analysis and to avoid re-running st_intersection() function above:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkkinterim.rds\")\n\n\nroadsbkkinterim &lt;- read_rds(\"data/rds/roadsbkkinterim.rds\")\n\n\n\n\nWhile we have managed to trim the original dataset from 2792590 rows to 564485 (~20% of original dataset size), it is important that we plot the geometry of the data to determine if we would be able to meaningfully analyse it. Based on the plot below, it can be seen that there is still too much data causing overcrowding of the map.\n\nplot(st_geometry(roadsbkkinterim))\n\nWe first plot the distribution of classes of highway in the roadsbkkinterim dataset:\n\nroad_counts &lt;- roadsbkkinterim %&gt;%\n  count(highway) %&gt;%\n  mutate(percentage = n / sum(n) * 100)\n\nggplot(road_counts, aes(x = fct_reorder(highway, n))) + \n  geom_bar(aes(y = n), stat = \"identity\", fill = \"lightyellow\") +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\"), y = n + 0.5),\n            vjust = 0,\n            size = 3) +\n  labs(title = \"Distribution of classes of highways\", x = \"Class of Highway\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nFrom the above, it is noted that service and residential highways make up 47.9% and 44.7% of the total road lines in the dataset. Beyond the information provided in the table above on highway details, we note the following about the service and residential highways:\n\nservice: denotes ways used for vehicle access to a building, parking lot, service station, business estate, beach, campsite etc. they are usually not part of the public street network and may be inaccessible to the general public (source)\nresidential: roads are typically short in length and likely to have lower speed limits and traffic calming measures in place (source)\n\nGiven the limited scale (in terms of size and potential impact to the general population) and that the sheer volume of the service and residential roads could overcrowd the other road lines in the data, we will omit them from our analysis:\nDropping service and residential highways:\n\nroadsbkk &lt;- roadsbkkinterim %&gt;%\n  filter(!(highway %in% c(\"service\",\"residential\")))\n\nWe then take a quick look at the geometry - while there are still a lot of data lines, the plot has cleaned up slightly and we will proceed with this data for now:\n\nplot(st_geometry(roadsbkk))\n\n\n\n\nWe then check the geometry of roadsbkk:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\nAs seen from the output above, the roadsbkk data comprises both linestring and multilinestring geometries. Linestring represents a single line, while MultiLinestring represents a collection of multiple lines. We need to simplify the data structure by converting multilinestring to linestring geometry to facilitate downstream analysis as the use of multilinestring might lead to error.\nWe utilise the st_cast() function to break down multilinestring geometries to linestring geometries:\n\nroadsbkk &lt;- st_cast(roadsbkk,\"LINESTRING\",group_or_split = TRUE)\n\nWe double check the geometry types and note from the output below that the geometry is now just linestring:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkk.rds\")\n\n\nroadsbkk &lt;- read_rds(\"data/rds/roadsbkk.rds\")\n\n\n\n\n\nWe carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\nBy yearBy year (at province level)\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that the number of road accidents has generally been increasing from 2019 to 2022.\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nWe save roadacc_month as a rds file:\n\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\n\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\nWe further observe the occurrence of road accidents by month at the province level:\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nSaving them as rds files:\n\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\nLoading the newly created rds files into R:\n\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\np0 &lt;- ggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nggplotly(p0)\n\n\n\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\np1 &lt;- ggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nggplotly(p1)\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur in clear weather conditions, followed by rainy weather conditions and dark weather conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi).\n\n\n\n\n\n\nTo carry out spatial point pattern analysis - the evaluation of the pattern or distribution of a set of points on a surface - we need to convert the data from sf format to ppp format:\n\nroadacc_ppp &lt;- as.ppp(roadacc)\nroadacc_ppp\n\nMarked planar point pattern: 12985 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\nThe code chunk below plots roadacc_ppp for visualisation:\n\nplot(roadacc_ppp)\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the roadacc_ppp object using the code chunk below:\n\nsummary(roadacc_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.217956e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates as the statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple i.e. that the points cannot be coincident. We check for duplication in a ppp object via the code chunk below:\n\nany(duplicated(roadacc_ppp))\n\n[1] FALSE\n\n\nThe data does not have any duplicated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region. The code chunk below is used to covert provincedata32647 SpatialPolygon object into owin object of spatstat:\n\nprovinceowin &lt;- as.owin(provincedata32647)\n\nThe ouput object can be displayed by using plot() function\n\nplot(provinceowin)\n\n\n\n\n\n\n\n\n\nsummary(provinceowin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nWe extract road accident events that are located within the BMR by using the code chunk below:\n\nroadacc_owin_ppp = roadacc_ppp[provinceowin]\n\n\nplot(roadacc_owin_ppp)\n\n\n\n\n\n\n\n\n\nsummary(roadacc_owin_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.693182e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\n\nWe will proceed to compute the KDE of road accidents in the BMR.\n\n\nWe will derive adaptive KDE using density.adaptive() of spatstat. Adaptive schemes adjust itself according to the density of data - shorter bandwidths are used where data are dense and longer where sparse. This helps to mitigate against highly skewed distribution of spatial point patterns.\nHowever, before we do so, we convert the unit of measurement to kilometer as the default unit of measurement of EPSG: 32647 is in metres, which would make the values hard to comprehend:\n\nroadacc_owin_ppp.km &lt;- rescale.ppp(roadacc_owin_ppp,\n                                   1000,\n                                   \"km\")\n\n\nkde_roadacc_adaptive &lt;- adaptive.density(roadacc_owin_ppp.km, method = \"kernel\")\nplot(kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output for mapping purposes:\n\ngridded_kde_roadacc_adaptive &lt;- as.SpatialGridDataFrame.im(kde_roadacc_adaptive)\nspplot(gridded_kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package:\n\nkde_roadacc_adaptive_raster &lt;- raster(kde_roadacc_adaptive)\n\nWe view the properties of kde_roadacc_adaptive_raster RasterLayer:\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nNote that the CRS property is NA.\n\n\n\nWe hence assign CRS information to the kde_roadacc_adaptive_raster RasterLayer:\n\nprojection(kde_roadacc_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nThe CRS property is now completed.\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_roadacc_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk will be used to extract the different provinces:\n\nbkk &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nnp &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Nakhon Pathom\")\nn &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Nonthaburi\")\npt &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Pathum Thani\")\nsp &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Samut Prakan\")\nss &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Samut Sakhon\")\n\n\n\n\n\nbkk_owin = as.owin(bkk)\nnp_owin = as.owin(np)\nn_owin = as.owin(n)\npt_owin = as.owin(pt)\nsp_owin = as.owin(sp)\nss_owin = as.owin(ss)\n\n\n\n\nBy using the code chunk below, we are able to extract road accidents that is within the specific province to carry out our analysis later on.\n\nroadacc_bkk_ppp = roadacc_ppp[bkk_owin]\nroadacc_np_ppp = roadacc_ppp[np_owin]\nroadacc_n_ppp = roadacc_ppp[n_owin]\nroadacc_pt_ppp = roadacc_ppp[pt_owin]\nroadacc_sp_ppp = roadacc_ppp[sp_owin]\nroadacc_ss_ppp = roadacc_ppp[ss_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nroadacc_bkk_ppp.km = rescale.ppp(roadacc_bkk_ppp,1000,\"km\")\nroadacc_np_ppp.km = rescale.ppp(roadacc_np_ppp,1000,\"km\")\nroadacc_n_ppp.km = rescale.ppp(roadacc_n_ppp,1000,\"km\")\nroadacc_pt_ppp.km = rescale.ppp(roadacc_pt_ppp,1000,\"km\")\nroadacc_sp_ppp.km = rescale.ppp(roadacc_sp_ppp,1000,\"km\")\nroadacc_ss_ppp.km = rescale.ppp(roadacc_ss_ppp,1000,\"km\")\n\nWe then plot the 6 provinces and the locations of the road accidents:\n\npar(mfrow=c(3,2))\nplot(roadacc_bkk_ppp.km,main=\"Bangkok\")\nplot(roadacc_np_ppp.km,main=\"Nakhon Pathom\")\nplot(roadacc_n_ppp.km,main=\"Nonthaburi\")\nplot(roadacc_pt_ppp.km,main=\"Pathum Thani\")\nplot(roadacc_sp_ppp.km,main=\"Samut Prakan\")\nplot(roadacc_ss_ppp.km,main=\"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute the KDE of the 6 provinces:\n\noptions(repr.plot.width=12, repr.plot.height=8)\npar(mfrow=c(3,2))\nplot(density(roadacc_bkk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bangkok\")\nplot(density(roadacc_np_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Nakhon Pathom\")\nplot(density(roadacc_n_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Nonthaburi\")\nplot(density(roadacc_pt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Pathum Thani\")\nplot(density(roadacc_sp_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Samut Prakan\")\nplot(density(roadacc_ss_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe will perform the Clark-Evans test of aggregation for spatial point pattern:\nThe test hypotheses are:\nH0: The distribution of road accidents is randomly distributed.\nH1: The distribution of road accidents is not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\nOverall BMRBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nclarkevans.test(roadacc_owin_ppp.km,\n                correction = \"none\",\n                clipregion = \"province_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_owin_ppp.km\nR = 0.19092, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nSince p-value is less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents is not randomly distributed.\n\n\n\nclarkevans.test(roadacc_bkk_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_bkk_ppp.km\nR = 0.12057, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_np_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_np_ppp.km\nR = 0.28949, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_n_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_n_ppp.km\nR = 0.38919, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_pt_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_pt_ppp.km\nR = 0.24798, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_sp_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_sp_ppp.km\nR = 0.14367, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_ss_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_ss_ppp.km\nR = 0.23989, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nBased on the results above, for which p-values are less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents in all provinces is not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "According to the World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year and leave between 20 to 50 million people with non-fatal injuries. Vulnerable road users, such as pedestrians, cyclists and motorcyclists, make up more than half of all road traffic deaths.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5 to 29, however two-thirds of road traffic fatalities occur among people of working ages, from 18 to 59 years. Further, nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries make up only around 60% of the world’s vehicles.\nBesides human suffering, road traffic injuries also result in a heavy economic burden on victims and their families, through treatment costs for the injured and loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nAccording to the WHO, Thailand’s roads are the deadliest in Southeast Asia and among the worst in the world - about 20,000 people die in road accidents each year, or about 56 deaths a day.\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which make up the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed as ‘black spots’ which are distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "By and large, road traffic accidents can be attributed by two major factors, namely behavioural and environmental factors.\n\nBehavioural factors in driving are considered to be major causes of traffic accidents either in direct or indirect manner (Lewin, 1982). These factors can be further grouped into driver behavior (driver/driving style) and driver performance (driver/driving skills) (Elander, West, & French, 1993).\nEnvironmental factors, on the other hand, includes but not limited to weather conditions such as poor visibility during heavy rain or fogs as well as road conditions such as sharp bends, slippery slopes, and blind spots.\n\nPrevious studies have demonstrated the significant potential of Spatial Point Patterns Analysis (SPPA) in exploring and identifying factors influencing road traffic accidents. However, these studies often focus solely on either behavioral or environmental factors, with limited consideration of temporal factors such as season, day of the week, or time of day.\nIn view of this, in this hands-on exercise, we will determine factors that affect road traffic accidents in the Bangkok Metropolitan Region (BMR) by employing both spatial and spatio-temporal point patterns analysis methods.\nThe specific objectives are as follows:\n\nTo visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nTo conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nTo conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "For the purpose of this exercise, three basic data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle - comprised records of road accidents in Thailand from ~2019 to 2022, based on information provided by the Office of the Permanent Secretary, Ministry of Transport.\nThailand - Subnational Administrative Boundaries on HDX\nThailand Roads (OpenStreetMap Export) on HDX"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-cleaning-and-wrangling-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-cleaning-and-wrangling-data",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The data is imported using the code below:\n\nroadacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nTaking a glimpse at the data to determine the fields in the data:\n\nglimpse(roadacc)\n\nRows: 81,735\nColumns: 18\n$ acc_code                    &lt;dbl&gt; 571905, 3790870, 599075, 571924, 599523, 5…\n$ incident_datetime           &lt;dttm&gt; 2019-01-01 00:00:00, 2019-01-01 00:03:00,…\n$ report_datetime             &lt;dttm&gt; 2019-01-02 06:11:00, 2020-02-20 13:48:00,…\n$ province_th                 &lt;chr&gt; \"ลพบุรี\", \"อุบลราชธานี\", \"ประจวบคีรีขันธ์\", \"เชียงใ…\n$ province_en                 &lt;chr&gt; \"Loburi\", \"Ubon Ratchathani\", \"Prachuap Kh…\n$ agency                      &lt;chr&gt; \"department of rural roads\", \"department o…\n$ route                       &lt;chr&gt; \"แยกทางหลวงหมายเลข 21 (กม.ที่ 31+000) - บ้านวั…\n$ vehicle_type                &lt;chr&gt; \"motorcycle\", \"private/passenger car\", \"mo…\n$ presumed_cause              &lt;chr&gt; \"driving under the influence of alcohol\", …\n$ accident_type               &lt;chr&gt; \"other\", \"rollover/fallen on straight road…\n$ number_of_vehicles_involved &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, …\n$ number_of_fatalities        &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, …\n$ number_of_injuries          &lt;dbl&gt; 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, …\n$ weather_condition           &lt;chr&gt; \"clear\", \"clear\", \"clear\", \"clear\", \"clear…\n$ latitude                    &lt;dbl&gt; 14.959105, 15.210738, 12.374259, 18.601721…\n$ longitude                   &lt;dbl&gt; 100.87346, 104.86269, 99.90795, 98.80420, …\n$ road_description            &lt;chr&gt; \"straight road\", \"straight road\", \"wide cu…\n$ slope_description           &lt;chr&gt; \"no slope\", \"no slope\", \"slope area\", \"no …\n\n\nThere are 81735 rows and 18 variables. Further details about the important variables that would be needed for analysis can be found in the dropdown box below:\n\n\n\n\n\n\nMore information about variables for analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nField\nDescription\nPurpose of data i.e. what it might indicate\n\n\n\n\nincident_datetime\nThe date and time of the accident occurrence\nwhether accidents tend to occur at specific:\n\nmonths\nday of week\ntime of the day\n\n\n\nreport_datetime\nThe date and time when the accident was reported\nefficacy at which accident was reported could indicate:\n\nhow busy the road segment is\nhow tightly the road is being monitored/ whether there is a lapse in the management of the road\n\n\n\nprovince_en\nThe name of the province in Thailand, written in English\nsupports the filtering of data to just BMR\n\n\nagency\nThe government agency responsible for the road and traffic management\npinpoints the responsible government agency, could indicate whether there is a need for government agency to take corrective actions\n\n\nroute\nThe route or road segment where the accident occurred\nwhile the data can be used to determine frequency of incident at different locations, it is not useful for our case as it’s in the Thai language\n\n\nvehicle_type\nThe type of vehicle involved in the accident\ncan determine frequency of vehicle types involved in accidents\n\n\npresumed_cause\nThe presumed cause or reason for the accident\ncan determine distribution of cause for accidents\n\n\naccident_type\nThe type or nature of the accident\ncan determine distribution of nature of accidents\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nweather_condition\nThe weather condition at the time of the accident\ncan determine how much weather conditions can affect the occurrence of accidents\n\n\nlatitude\nThe latitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nlongitude\nThe longitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred\ncan determine how road types can affect the occurrence of accidents\n\n\nslope_description\nThe description of the slope condition at the accident location\ncan determine how presence of slopes can affect the occurrence of accidents\n\n\n\n\n\n\n\n\n\nWe will first drop “province_th” as it indicates the provinces in the Thai language.\n\nroadacc &lt;- roadacc[, !names(roadacc) %in% c(\"province_th\",\"route\")]\n\n\n\n\nWe then determine the unique provinces within the dataset and scan through the province names (i.e. in case there are any entries that refer to the same province but are spelt differently/have spelling mistakes) before filtering the data to just include provinces that are within the BMR:\n\nunique_provinces &lt;- roadacc %&gt;% \n  distinct(province_en) %&gt;%\n  arrange(province_en)\n\nDT::datatable(unique_provinces,class = \"compact\")\n\n\n\n\n\nOur region of interest comprises Bangkok and five adjacent provinces of Nakhon Pathom, Nonthaburi, Pathum Thani, Samut Prakan and Samut Sakhon.\n\nroadacc &lt;- roadacc %&gt;% \n  filter(province_en %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves the data with 13336 rows.\n\n\n\nWe further clean the data by removing rows with missing data:\n\nroadacc &lt;- roadacc %&gt;%\n  drop_na()\n\n\n\n\nWe also check if there are duplicate entries in the dataset:\n\nroadacc$acc_code[duplicated(roadacc$acc_code) == TRUE]\n\nnumeric(0)\n\n\nThere are no duplicate entries.\nGenerating summary statistics of roadacc:\n\nsummary(roadacc)\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nDuring class, Prof Kam had advised to study the data carefully and shared that it was important to filter out data with incomplete coordinates (missing either longitude or latitude or both) and shared that one way to do it was via the code below:\n\nroadacc &lt;- roadacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\")\n\nAs with the drop_na() code above, this way will also leave just 12986 rows of data as the missing data were found in either the longitude or latitude variables.\n\n\n\n\n\nWe convert roadacc data frame into a simple feature data frame and also transform the data from geographic coordinate system (EPSG: 4326 WGS84 Geographic Coordinate System) to projected coordinate system:\n\nroadacc &lt;- st_as_sf(roadacc, \n                    coords = c(\"longitude\", \"latitude\"),\n                    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nBased on the summary statistics of roadacc above, it is noted that the minimum longitude is 99.85° and maximum longitude is 100.94°. While there are 2 possible projected coordinate systems for Thailand, EPSG 32647 and 32648, the appropriate projected coordinate system to transform the data to would be EPSG 32647 as the minimum and maximum longitude of roadacc falls within EPSG 32467’s area of use (between 96°E and 102°E). A comparison of the area of use for both projected coordinate systems is shown below:\n\n\n\n\nEPSG 32647\nEPSG 32648\n\n\n\n\nArea of use\nBetween 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\nBetween 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\n\n\n\n\n\n\nThe incident_datetime and report_datetime variables are in datetime field, we hence utilise these variables and the lubridate() function to generate new variables that represent:\n\nmonth: “inc_month”\nday of week: “inc_dayofweek”\ntime of day: “inc_time”\n\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(inc_year = year(incident_datetime)) %&gt;%\n  mutate(inc_month = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(inc_dayofweek = wday(incident_datetime,\n                              week_start = getOption(\"lubridate.week.start\", 1),\n                              label = TRUE,\n                              abbr = TRUE)) %&gt;%\n  mutate(inc_time = hour(incident_datetime))\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nNote that we can generate month in numbers or in factor format via:\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE))\n\n\n\nWe also determine the gap between the incident time and reporting time and create a new variable “timegap” in hours unit:\n\nroadacc$timegap &lt;- time_length(roadacc$report_datetime - roadacc$incident_datetime, \"hours\")\n\nLogically, the date and time when the accident was reported should be after the date and time of the accident occurrence. Looking at the summary statistics below, there are data entries that could have been erroneously recorded resulting in a negative time gap between report time and incident time (i.e. report time was earlier than incident time). As such, the data was further filtered to remove erroneous data to avoid affecting the analysis:\n\nsummary(roadacc$timegap)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n   -6.917   124.183  1408.000  2200.237  3232.571 10915.750 \n\n\n\nroadacc &lt;- roadacc %&gt;%\n  filter(timegap &gt;= 0)\n\nThis leaves us with 12985 rows.\n\n\n\nWe then save this cleaned data as a rds file:\n\nwrite_rds(roadacc,\"data/rds/roadacc.rds\")\n\n\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nIt is good practice to save cleaned file as a new rds file via write_rds() to avoid re-running the data cleaning and wrangling codes. write_rds() will take care of all the objects within the dataset. Once the file is saved, we can add “#| eval: false” to the data cleaning and wrangling codes to avoid re-running them.\n\n\n\n\n\n\nThe data has different files providing details of the administrative boundaries of Thailand at different administrative levels:\n\nLevel 0 (country)\nLevel 1 (province)\nLevel 2 (district)\nLevel 3 (sub-district, tambon)\n\nAs our area of interest is at Level 1 (province level), we will utilise “tha_admbnda_adm1_rtsd_20220121” that reflects details at province levels and import the data using the code chunk below:\n\nprovincedata = st_read(dsn = \"data/rawdata\", \n                  layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nWe note from the above that it is a multipolygon feature data frame. We note that there are 77 features and 16 fields, and the data is in WGS84 geographic coordinate system.\nWe then take a glimpse of the data:\n\nglimpse(provincedata)\n\n\n\n\nWe note from a glimpse of the data above that there are only a few pertinent fields that we require for our analysis, specifically:\n\nADM1_EN: province name in english\nShape_Leng\nShape_Area\ngeometry\n\nWe hence filter the data to only comprise these fields to make the data frame more manageable:\n\nprovincedata &lt;- provincedata %&gt;%\n  select(\"ADM1_EN\", \"Shape_Leng\",\"Shape_Area\",\"geometry\")\n\n\n\n\nWe also filter to keep only data that are relevant to our area of interest which is BMR:\n\nprovincedata &lt;- provincedata %&gt;% \n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves 6 rows of data and 4 variables.\n\n\n\nFrom the code chunk below, it is noted that the EPSG code for the selectedboundaries data frame is EPSG: 4326:\n\nst_crs(provincedata)\n\nWe will need to reproject provincedata from EPSG code to EPSG: 32647 which is the projected coordinate system to use for BMR, our area of interest:\n\nprovincedata32647 &lt;- st_transform(provincedata, \n                              crs = 32647)\n\nWe check if the EPSG code has been correctly assigned:\n\nst_crs(provincedata32647)\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(provincedata32647,\"data/rds/provincedata32647.rds\")\n\n\nprovincedata32647 &lt;- read_rds(\"data/rds/provincedata32647.rds\")\n\nWe visualise our provincedata32647:\n\ntmap_mode('view')\ntm_shape(provincedata32647)+\n  tm_polygons()\n\n\n\n\ntmap_mode('plot')\n\n\n\n\nWe import the data as follows:\n\nroadlines = st_read(dsn = \"data/rawdata\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe then glimpse at the data:\n\nglimpse(roadlines)\n\n\nst_geometry(roadlines)\n\nThe dataset is very large, with 2792590 rows and 15 variables but we only need to extract relevant information that lie within the BMR for analysis.\n\n\n\nBased on the code chunk below, it is noted that the coordinate system of the roadlines data is missing.\n\nst_crs(roadlines)\n\nBased on the values of the geometry in roadlines, the coordinates seem to be in geographic (latitude/longitude) form, in degrees, typically in a CRS like EPSG:4326 (WGS 84) used for global geographic coordinates. We hence assign the missing EPSG code using the code chunk below:\n\nroadlines4326 &lt;- st_set_crs(roadlines,4326)\n\nWe check the CRS using the code chunk below:\n\nst_crs(roadlines4326)\n\nFor analysis, we would eventually need to overlay the roadlines4326 data with the selectedboundaries32647 data to determine the roads that lie within BMR. In order to perform geoprocessing using two geospatial data, both geospatial data would need to be projected using similar coordinate systems - in this case, it its EPSG: 32647:\n\nroadlines32647 &lt;- st_transform(roadlines4326, \n                              crs = 32647)\n\nWe check the CRS code again:\n\nst_crs(roadlines32647)\n\n\n\n\nBased on the columns in the data frame roadlines32647, the columns that seem relevant/useful to retain for analysis are “highway”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge” and “geometry”.\nHowever before going ahead to retain these variables, we determine the presence of missing data within roadlines32647:\n\nmissing_counts &lt;- sapply(roadlines32647, function(x) sum(is.na(x)))\nprint(missing_counts)\n\nBased on the result above, more than 60% of data is missing for the variable “source” and more than 80% of data is missing for the variables “name”, “name_en”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge”, “layer”, “source” and “name_th”. Given the extent of missing data, we will omit these columns as they would not provide useful information for analysis and only retain the relevant/useful columns “highway” and “geometry” with no missing data:\n\nselectedroadlines &lt;- roadlines32647 %&gt;%\n  select(\"highway\", \"geometry\")\n\n\n\n\nThe code chunk below is used to determine the types of highways in the selectedroadlines data frame:\n\nunique_highway &lt;- unique(selectedroadlines$highway)\nunique_highway &lt;- sort(unique_highway)\n\nunique_highway\n\nTo determine which classes of highway to retain for analysis, the default access restrictions based on the interpretation of Thailand’s Road Traffic Act, 1979 was referenced (source):\n\nA detailed explanation on the type of highways and whether they are included for analysis is indicated in the table below:\n\n\n\nTypes of highway\nDetails\nIncluded for analysis?\n\n\n\n\nabandoned\nUnused/Abandoned roads that are only passable on foot/two-wheel vehicles\nNo\n\n\nbarrier\nRoadside barriers used to protect traffic from roadside obstacles or hazards (source)\nNo\n\n\nbridleway\nA bridle path, also bridleway, equestrian trail, horse riding path, ride, bridle road, or horse trail, is a trail or a thoroughfare that is used by people riding on horses. (source)\nNo\n\n\nbusway\nA dedicated, separate way for the use of public transport buses (source)\nYes\n\n\nconstruction\nNo details provided, could be a highway under construction or a highway used for construction purposes.\nNo (due to ambiguity of information)\n\n\ncorridor\nA land corridor is a type of highway or railway infrastructure that links two or more urban areas (source)\nYes\n\n\ncycleway\nBased on table above, its designated for bicycles and travel by foot is allowed\nNo (as the path is designated mainly for cyclists and might not be so useful for the scope of the exercise)\n\n\nescape\nA road, usually ending in a pile of sand, provided on a hill for drivers to drive into if their brakes fail or on a bend if they lose control of the turn (source)\nYes\n\n\nfootway\nBuilt pathways designed mainly or exclusively for pedestrian access (source)\nNo\n\n\nliving_street\nLittle information provided on use but based on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nmotorway\nExpressway with full access control (source)\nYes\n\n\nmotorway_link\nLink roads (slip roads/ramps) leading to and from a motorway (source) and based on above table, otorcars, motorcycles and pedestrians all have access\nYes\n\n\nparth\nNo relevant information found, assume is a spelling error and meant to be “path”.\nYes (to rename to “path” for analysis)\n\n\npath\nMulti-purpose paths intended for all non-motorized vehicles with the exception of motorcycles (source). Based on table above, motorcycles and pedestrians have access.\nYes\n\n\npaved\nGenerally indicates a road that been covered with flat blocks of stone or concrete, so that it is suitable for walking or driving on.\nYes\n\n\npedestrian\nBased on table above, access only allowed for bicycles and travel by foot\nNo\n\n\nprimary\nTop-level urban road across the city connecting trunk to trunk, or road of equal or greater importance than the primary intercity highway that runs through that city (source)\nYes\n\n\nprimary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nproposed\nProposed cycling routes (source)\nNo\n\n\nraceway\nA course for racing (source)\nNo\n\n\nresidential\nA road within a residential area that gives the public access to one or multiple residences. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nroad\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nsecondary\nMain urban road connecting primary to primary or higher, or road of equal or greater importance than the secondary intercity highway that runs through that city. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nsecondary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access\nYes\n\n\nservice\nA minor road that gives access to buildings/places outside a residential area such as an estate, religious site, attraction site, or a specific part of a large estate such as an industrial facility or university campus (source)\nYes\n\n\nsteps\nBased on table above, designated for travel by foot\nNo\n\n\ntertiary\nRoads that are more important than regular unclassified or residential roads, or roads that connect several unclassified or residential roads. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntertiary_link\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrack\nA road whose only function is to provide access to the surrounding land (agricultural, forestry purposes). Most of the time unpaved (source)\nYes\n\n\ntrunk\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrunk_link\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\nunclassified\nA significant thru-traffic road used to reach the next settlement or another road of equal or higher importance regardless of its physical conditions. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\n\n\nselectedroadlines &lt;- selectedroadlines %&gt;%\n  filter(highway %in% c(\"busway\",\"corridor\",\"escape\",\"living_street\",\"motorway\",\"motorway_link\", \"parth\", \"path\", \"paved\",\"primary\",\"primary_link\",\"residential\",\"road\",\"secondary\",\"secondary_link\",\"service\",\"tertiary\",\"tertiary_link\",\"track\",\"trunk\",\"trunk_link\",\"unclassified\")) %&gt;%\n  mutate(highway = recode(highway, \"parth\" = \"path\"))\n\n\n\n\nWe require only a subset of the selectedroadlines data to just roads within our area of interest, BMR and hence we utilise st_intersection() to find retain roads that are within the BMR boundaries given by provincedata32647:\n\nroadsbkk &lt;- st_intersection(selectedroadlines,provincedata32647)\n\nThis reduced the data to 564485 rows of data.\n\n\n\nWe save this cleaned data as a new rds file in the interim to facilitate further analysis and to avoid re-running st_intersection() function above:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkkinterim.rds\")\n\n\nroadsbkkinterim &lt;- read_rds(\"data/rds/roadsbkkinterim.rds\")\n\n\n\n\nWhile we have managed to trim the original dataset from 2792590 rows to 564485 (~20% of original dataset size), it is important that we plot the geometry of the data to determine if we would be able to meaningfully analyse it. Based on the plot below, it can be seen that there is still too much data causing overcrowding of the map.\n\nplot(st_geometry(roadsbkkinterim))\n\nWe first plot the distribution of classes of highway in the roadsbkkinterim dataset:\n\nroad_counts &lt;- roadsbkkinterim %&gt;%\n  count(highway) %&gt;%\n  mutate(percentage = n / sum(n) * 100)\n\nggplot(road_counts, aes(x = fct_reorder(highway, n))) + \n  geom_bar(aes(y = n), stat = \"identity\", fill = \"lightyellow\") +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\"), y = n + 0.5),\n            vjust = 0,\n            size = 3) +\n  labs(title = \"Distribution of classes of highways\", x = \"Class of Highway\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nFrom the above, it is noted that service and residential highways make up 47.9% and 44.7% of the total road lines in the dataset. Beyond the information provided in the table above on highway details, we note the following about the service and residential highways:\n\nservice: denotes ways used for vehicle access to a building, parking lot, service station, business estate, beach, campsite etc. they are usually not part of the public street network and may be inaccessible to the general public (source)\nresidential: roads are typically short in length and likely to have lower speed limits and traffic calming measures in place (source)\n\nGiven the limited scale (in terms of size and potential impact to the general population) and that the sheer volume of the service and residential roads could overcrowd the other road lines in the data, we will omit them from our analysis:\nDropping service and residential highways:\n\nroadsbkk &lt;- roadsbkkinterim %&gt;%\n  filter(!(highway %in% c(\"service\",\"residential\")))\n\nWe then take a quick look at the geometry - while there are still a lot of data lines, the plot has cleaned up slightly and we will proceed with this data for now:\n\nplot(st_geometry(roadsbkk))\n\n\n\n\nWe then check the geometry of roadsbkk:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\nAs seen from the output above, the roadsbkk data comprises both linestring and multilinestring geometries. Linestring represents a single line, while MultiLinestring represents a collection of multiple lines. We need to simplify the data structure by converting multilinestring to linestring geometry to facilitate downstream analysis as the use of multilinestring might lead to error.\nWe utilise the st_cast() function to break down multilinestring geometries to linestring geometries:\n\nroadsbkk &lt;- st_cast(roadsbkk,\"LINESTRING\",group_or_split = TRUE)\n\nWe double check the geometry types and note from the output below that the geometry is now just linestring:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkk.rds\")\n\n\nroadsbkk &lt;- read_rds(\"data/rds/roadsbkk.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Factors to study:\n\nvehicle type\npresumed cause\nnumber of vehicles\nnumber of fatalities\nnumber of injuries\nweather conditions\nroad_description\nslope_description\nmonth\nday of week\ntime of day\ntime gap between incident occurrence and reporting\n\n\nggplot(roadacc, aes(x = province_en)) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nwhen file is read in sf, can easily convert to ppp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, I will compute spatial weights using R. By the end to this hands-on exercise, the aim is to be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nTo carry out the analysis, we install and load the following R packages:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\nThe geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below is used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4,7,15)\n\n\n\n\n\nWe then prepare a basemap and a choropleth map showing the distribution of GDP per capita (GDPPC) 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nIn this section, poly2nb()of spdep package will be used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument takes TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute the Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 regions in Hunan. The most connected region has 11 neighbours. There are two regions with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nThis indicates that Polygon 1 has five neighbours. The numbers represent the polygon IDs stored in hunan SpatialPolygons Data Frame class.\nThe county name of Polygon ID = 1 can be retrieved as follows:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID = 1 is Anxiang county.\nTo reveal the names of the five neighbouring counties, the code chunk below is used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nThe GDPPC of these counties can be obtained via the following code chunk:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe output indicates that the GDPPC of the five nearest neighbours of Anxiang county, based on the Queen’s method, are 20981, 34592, 24473, 21311 and 22879.\nThe complete weight matrix can be displayed using str():\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nThe code chunk below is used to compute the ROOK contiguity weight matrix:\n\nwm_r &lt;- poly2nb(hunan,queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report indicates that there are 88 regions in Hunan. The most connected region has 10 neighbours and there are two regions with just one neighbour.\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. As we are currently working with polygons, we will need to get points in order to make connectivity graphs. The most typical method for this is polygon centroids, which can be calculated using the sf package before moving onto the graphs.\n\n\nWe will need points to associate with each polygon before making the connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound.\nWe need the coordinates in a separate data frame. To do this we will use a mapping function which applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will use a map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference - we access the second value for each centroid with [[2]]:\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWith latitude and longitude, we use cbind to put longitude and latitude into the same object:\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly:\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"ROOK Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will derive distance-based weight matrices using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band of lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, the upper limit for distance band is determined using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() to a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, or otherwise in km.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nThe distance weight matrix is then computed using dnearneigh() as shown in the code chunk below:\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe average number of links refer to the average number of neighbours each region has in a spatial network.\nstr() is then used to display the content of the wm_d62 weight matrix:\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAn alternative way to display the structure of the weight matrix is to combine table() and card() of spdep:\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\nThe n.comb.nb() function is used to analyze the connectivity components of the spatial weights object. The output of 1 indicates that the entire spatial network consists of a single connected component i.e. is a path between any two regions in the spatial network, meaning that all regions are interconnected directly or indirectly\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nThe code above then generates a frequency table of the connected components and the output indicates that all 88 regions in Hunan are part of a unique connected component (ID = 1).\n\n\nThe distance weight matrix is plotted using the following code chunk:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, both lines can be plotted in adjacent charts uing the code chunk below:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below:\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nThe content of the matrix can be displayed by using str():\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNote that each county has six neighbours.\n\n\nThe weight matrix can be plotted using the code chunk below:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, a spatial weight matrix will be derived based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep:\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that the polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but there are other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. Note that this should be used with caution as the user may not be aware of missing neighbors in their dataset however, a zero.policy=FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nEach neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below:\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\n\nIn this section, four different spatial lagged variables will be created:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nWe will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall that in the previous section, the GDPPC of five counties were retrieved using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below:\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following shows the average neighboring income values (stored in the Inc.lag object) for each county:\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below:\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per neighbor. This is done with lapply which applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC:\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nWe examine the results using the code chunk below:\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into the hunan sf data frame by using the code chunk below:\n\nhunan &lt;- left_join(hunan, lag.res)\n\nWe then plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below:\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nThe number of nonzero links, % nonzero weights and average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below:\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNote that ID = 1 now has six instead of five neighbours.\nWe then obtain the weights with nb2listw():\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable:\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame():\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote that the third command line of the code chunk above renames the field names of lag_wm_q.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison:\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element:\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNote that now [1] has six instead of five neighbours .\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw():\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame():\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote that te second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison:\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Neighbours using sf objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, I will compute spatial weights using R. By the end to this hands-on exercise, the aim is to be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#study-area-and-data",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "To carry out the analysis, we install and load the following R packages:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below is used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4,7,15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "We then prepare a basemap and a choropleth map showing the distribution of GDP per capita (GDPPC) 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this section, poly2nb()of spdep package will be used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument takes TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria.\n\n\nThe code chunk below is used to compute the Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 regions in Hunan. The most connected region has 11 neighbours. There are two regions with only one neighbour.\nFor each polygon in the polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nThis indicates that Polygon 1 has five neighbours. The numbers represent the polygon IDs stored in hunan SpatialPolygons Data Frame class.\nThe county name of Polygon ID = 1 can be retrieved as follows:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID = 1 is Anxiang county.\nTo reveal the names of the five neighbouring counties, the code chunk below is used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nThe GDPPC of these counties can be obtained via the following code chunk:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe output indicates that the GDPPC of the five nearest neighbours of Anxiang county, based on the Queen’s method, are 20981, 34592, 24473, 21311 and 22879.\nThe complete weight matrix can be displayed using str():\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nThe code chunk below is used to compute the ROOK contiguity weight matrix:\n\nwm_r &lt;- poly2nb(hunan,queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report indicates that there are 88 regions in Hunan. The most connected region has 10 neighbours and there are two regions with just one neighbour.\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. As we are currently working with polygons, we will need to get points in order to make connectivity graphs. The most typical method for this is polygon centroids, which can be calculated using the sf package before moving onto the graphs.\n\n\nWe will need points to associate with each polygon before making the connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound.\nWe need the coordinates in a separate data frame. To do this we will use a mapping function which applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will use a map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference - we access the second value for each centroid with [[2]]:\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWith latitude and longitude, we use cbind to put longitude and latitude into the same object:\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly:\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"ROOK Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distanced-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distanced-based-neighbours",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this section, we will derive distance-based weight matrices using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band of lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, the upper limit for distance band is determined using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() to a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, or otherwise in km.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nThe distance weight matrix is then computed using dnearneigh() as shown in the code chunk below:\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe average number of links refer to the average number of neighbours each region has in a spatial network.\nstr() is then used to display the content of the wm_d62 weight matrix:\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAn alternative way to display the structure of the weight matrix is to combine table() and card() of spdep:\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\nThe n.comb.nb() function is used to analyze the connectivity components of the spatial weights object. The output of 1 indicates that the entire spatial network consists of a single connected component i.e. is a path between any two regions in the spatial network, meaning that all regions are interconnected directly or indirectly\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nThe code above then generates a frequency table of the connected components and the output indicates that all 88 regions in Hunan are part of a unique connected component (ID = 1).\n\n\nThe distance weight matrix is plotted using the following code chunk:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, both lines can be plotted in adjacent charts uing the code chunk below:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below:\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nThe content of the matrix can be displayed by using str():\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNote that each county has six neighbours.\n\n\nThe weight matrix can be plotted using the code chunk below:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this section, a spatial weight matrix will be derived based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep:\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weight-matrix",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that the polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but there are other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. Note that this should be used with caution as the user may not be aware of missing neighbors in their dataset however, a zero.policy=FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nEach neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below:\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this section, four different spatial lagged variables will be created:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nWe will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall that in the previous section, the GDPPC of five counties were retrieved using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below:\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following shows the average neighboring income values (stored in the Inc.lag object) for each county:\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below:\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per neighbor. This is done with lapply which applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC:\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nWe examine the results using the code chunk below:\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into the hunan sf data frame by using the code chunk below:\n\nhunan &lt;- left_join(hunan, lag.res)\n\nWe then plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below:\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nThe number of nonzero links, % nonzero weights and average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below:\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNote that ID = 1 now has six instead of five neighbours.\nWe then obtain the weights with nb2listw():\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable:\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame():\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote that the third command line of the code chunk above renames the field names of lag_wm_q.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison:\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep:\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element:\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNote that now [1] has six instead of five neighbours .\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw():\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame():\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote that te second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison:\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "Creating Neighbours using sf objects"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nTo carry out the analysis, we install and load the following R packages:\n\npacman::p_load(sf, ggstatsplot, spdep, tmap, tidyverse, knitr,GWmodel)\n\n\n\n\nThe geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport Hunan shapefileImport Hunan 2012Joining Hunan and Hunan 2012\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nnote that above data has not been transformed - this is intentional for this use case so that know that there are packages that have provision for projection\nnote that geometry type is single polygon - always note that administrative boundaries can be captured as polygon or multipolygon\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\ndo not use read.csv (Base R)\n\n\n\nThe code chunk below is used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed using left_join() of dplyr package.\n\nhunan_sf &lt;- left_join(hunan_sf,hunan2012) %&gt;%\n  select(1:3,7,15,16,31,32)\n\n\ncombining spatial data with aspatial data - use dplyr left_join() function but in reality, not so straightforward as need common identifier between the datasets i.e. value in a particular variable must be the same - need to carefully check through the names and actual values in the datasets to make sure they are the same else might not be able to join (recall hands-on ex01 where administrative boundary of singapore is in uppercase while that in singstat data is a mix of upper and lowercase)\nboth datasets have “County” column hence while code chunk did not define the join field, the code automatically uses the “County” column to join. if hunan_sf did not have “County” column, would have mention the join argument by as “NAME_3” in hunan_sf and “County” in hunan2012.\nif there’s a lot of names in the field, can do a unique match to compare\nSelect chooses these columns: “NAME_2”, “ID_3”, “NAME_3”, “County”,“GDPPC”, “GIO”,“Agri”,“Service”, “geometry”\n\n\n\n\n\n\n\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\n\n\nsp separates the components of data under sf:\n\ndata contains all data except geometry data\nunder polygons, geometry data\n\n\nTyping the below into console, we note the data object type:\n\n\n\n\n\n\n\nboth CV and AIC methods produce the same results - that the optimum number of neighbours is 22 but note that this is not always the case i.e. can produce different results\n\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nfirst line is dependent variable ~ independent variable (put an arbitrary number 1 if don’t have independent variable), else without formula, won’t work and give error message –&gt; this is a global model\nsecond line is hunan_sp data\napproach either CV or AIC (see next tab)\nadaptive = FALSE means calculating fixed bandwith, TRUE means adaptive bandwidth –&gt; in this case, indicate the number of neighbours (note that it starts with 62 then slowly bury the number of neighbours)\nkernel is the same as spatial point pattern analysis, can change to other methods, not likely to affect much\nlonglat = T, indicate that its in decimal degree - great circle distances will be calculated\nnote that the results are in km\nbased on GDPPC, optimum number of neighbours is 22\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nsmaller AIC value, the better. at some point, AIC points will converge and no longer change/change rate very small - that would be optimal value\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nnote that the change in AIC becomes very small and eventually stops\nbased on GDPPC, optimum number of neighbours is 22\n\n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nneed to make sure that the bottom 3 fields are the same as the above in 4.5.1 Determine adaptive bandwidth\n is a gwss object (specially customised object - list that contains many things)\n\nmostly are metadata\nwhat is of interest is SDF - spatialdataframe - contains all spatial information + data information\n\ncan click on logo:\n\n\n\nGDPPC_LM: local mean (have 88 local means that is based on average of 22 neighbours)\nGDPPC_LSD: local standard deviation\nGDPPC_LSKe: local standard estimations\nGDPPC_LCV: local co-variance\n\nAll are taking the average of 22 neighbours\n\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame():\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data frame:\n\nhunan_gstat &lt;- cbind(hunan_sf,gwstat_df)\n\n\nnote that only able to use cbind() with the understanding that there’s no change in sequence of data in both dataframes\n\n\n\n\n\nGeographically Weighted MeanThe code\n\n\n\n\n\n\n\n\n\n\n\n\nhelp to generalise the pattern\ntm_fill n=5 sets the number of gradient\ntm_borders draw the border around polygon, =1 is full black, closer to 0 - greater transparency\ntm_layout add in other details\n\n\n\n\ntm_shape(hunan_gstat)+\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)+\n  tm_text(\"County\", size = 0.5)\n\n\n\n\n\n\n\n\nConventional statistical solutionThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnote that results for CV and AIC are not the same - AIC optimum is 160.5517, almost twice of CV optimum of 76.29126 (longer bandwidth have smoother output, shorter bandwidth have more details)\n\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\n\n\n\n\nneed to note how many neighbours you are using to define the correlation\nCorr: parametric vs Spearman: non-parametric - indicate how well each correlate with neighbour\n\n== end ==\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nclean environment, save data image when closing session can help to prevent upload of temporary files\nGWmodel package: bw.gwr recommend optimum number of neighbours"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#study-area-and-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#study-area-and-data",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "To carry out the analysis, we install and load the following R packages:\n\npacman::p_load(sf, ggstatsplot, spdep, tmap, tidyverse, knitr,GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-data",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport Hunan shapefileImport Hunan 2012Joining Hunan and Hunan 2012\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nnote that above data has not been transformed - this is intentional for this use case so that know that there are packages that have provision for projection\nnote that geometry type is single polygon - always note that administrative boundaries can be captured as polygon or multipolygon\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\ndo not use read.csv (Base R)\n\n\n\nThe code chunk below is used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed using left_join() of dplyr package.\n\nhunan_sf &lt;- left_join(hunan_sf,hunan2012) %&gt;%\n  select(1:3,7,15,16,31,32)\n\n\ncombining spatial data with aspatial data - use dplyr left_join() function but in reality, not so straightforward as need common identifier between the datasets i.e. value in a particular variable must be the same - need to carefully check through the names and actual values in the datasets to make sure they are the same else might not be able to join (recall hands-on ex01 where administrative boundary of singapore is in uppercase while that in singstat data is a mix of upper and lowercase)\nboth datasets have “County” column hence while code chunk did not define the join field, the code automatically uses the “County” column to join. if hunan_sf did not have “County” column, would have mention the join argument by as “NAME_3” in hunan_sf and “County” in hunan2012.\nif there’s a lot of names in the field, can do a unique match to compare\nSelect chooses these columns: “NAME_2”, “ID_3”, “NAME_3”, “County”,“GDPPC”, “GIO”,“Agri”,“Service”, “geometry”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "hunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\n\n\nsp separates the components of data under sf:\n\ndata contains all data except geometry data\nunder polygons, geometry data\n\n\nTyping the below into console, we note the data object type:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "both CV and AIC methods produce the same results - that the optimum number of neighbours is 22 but note that this is not always the case i.e. can produce different results\n\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nfirst line is dependent variable ~ independent variable (put an arbitrary number 1 if don’t have independent variable), else without formula, won’t work and give error message –&gt; this is a global model\nsecond line is hunan_sp data\napproach either CV or AIC (see next tab)\nadaptive = FALSE means calculating fixed bandwith, TRUE means adaptive bandwidth –&gt; in this case, indicate the number of neighbours (note that it starts with 62 then slowly bury the number of neighbours)\nkernel is the same as spatial point pattern analysis, can change to other methods, not likely to affect much\nlonglat = T, indicate that its in decimal degree - great circle distances will be calculated\nnote that the results are in km\nbased on GDPPC, optimum number of neighbours is 22\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nsmaller AIC value, the better. at some point, AIC points will converge and no longer change/change rate very small - that would be optimal value\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nnote that the change in AIC becomes very small and eventually stops\nbased on GDPPC, optimum number of neighbours is 22\n\n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nneed to make sure that the bottom 3 fields are the same as the above in 4.5.1 Determine adaptive bandwidth\n is a gwss object (specially customised object - list that contains many things)\n\nmostly are metadata\nwhat is of interest is SDF - spatialdataframe - contains all spatial information + data information\n\ncan click on logo:\n\n\n\nGDPPC_LM: local mean (have 88 local means that is based on average of 22 neighbours)\nGDPPC_LSD: local standard deviation\nGDPPC_LSKe: local standard estimations\nGDPPC_LCV: local co-variance\n\nAll are taking the average of 22 neighbours\n\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame():\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data frame:\n\nhunan_gstat &lt;- cbind(hunan_sf,gwstat_df)\n\n\nnote that only able to use cbind() with the understanding that there’s no change in sequence of data in both dataframes\n\n\n\n\n\nGeographically Weighted MeanThe code\n\n\n\n\n\n\n\n\n\n\n\n\nhelp to generalise the pattern\ntm_fill n=5 sets the number of gradient\ntm_borders draw the border around polygon, =1 is full black, closer to 0 - greater transparency\ntm_layout add in other details\n\n\n\n\ntm_shape(hunan_gstat)+\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)+\n  tm_text(\"County\", size = 0.5)\n\n\n\n\n\n\n\n\nConventional statistical solutionThe code"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "note that results for CV and AIC are not the same - AIC optimum is 160.5517, almost twice of CV optimum of 76.29126 (longer bandwidth have smoother output, shorter bandwidth have more details)\n\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\n\n\n\n\nneed to note how many neighbours you are using to define the correlation\nCorr: parametric vs Spearman: non-parametric - indicate how well each correlate with neighbour\n\n== end ==\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nclean environment, save data image when closing session can help to prevent upload of temporary files\nGWmodel package: bw.gwr recommend optimum number of neighbours"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this hands-on exercise, we will compute Global Measures of Spatial Autocorrelation (GMSA) using spdep package. The learning points of this hands-on exercise are to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics.\n\n\n\n\n\n\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are installed in R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,tidyverse,spdep,tmap)\n\n\n\n\n\nIn this section, we will bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe note that the simple features data has a polygon geometry and has 88 features and 7 fields. It is in WGS84 geographic coordinate system.\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4,7,15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\ntmap_arrange(equal,\n             quantile,\n             asp = 1,\n             ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument can take TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria (which is on the basis of shared boundaries):\nThe code chunk below is used to compute Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan,\n                queen = TRUE)\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours and there are two ara units with only one neighbour.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = \"W\",\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.policy.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\n\n\nIn this section, we will perform Moran’s I statistics testing using moran.test() of spdep.\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC,\n           listw = rswm_q,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\nThe code chunk below performs the permutation test for Moran’s I statistic using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999,\n                 zero.policy = TRUE,\n                 na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nIt is always a good practice to examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\nabline(v = 0,\n       col = \"red\")\n\n\n\n\n\n\n\n\nAlternatively, we can use ggplot2 to plot the graph:\n\nggplot(data.frame(res = bperm$res),aes(x=res)) +\n  geom_histogram(bins = 20,\n                 color=\"black\", \n                 fill=\"grey\") +\n  geom_vline(xintercept = 0,\n             color=\"red\",\n             linetype=\"dashed\")+\n  labs(x = \"Simulated Moran's I\", y=\"Frequency\")+\n  ggtitle(\"Distribution of Moran's I test statistical values\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform Geary’s C statistics testing using appropriate functions of spdep package.\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC,listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC,\n               listw = rswm_q,\n               nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res,\n     freq=TRUE,\n     breaks=20,\n     xlab=\"Simulated Geary's C\")\nabline(v = 1,\n       col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial correlograms are great for examining patterns of spatial autocorrelation in your data or model residuals. They show how correlated pairs of spatial observations are when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I (note method = “I” in code below). The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = \"I\",\n                          style = \"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C (note method = “C” in code below). The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = \"C\",\n                          style = \"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below:\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nOwn notes on why wm_q is used in correlogram rather than rswm_q\n\n\n\n\nThe primary goal of a spatial correlogram is to examine how spatial autocorrelation (e.g., Moran’s I or Geary’s C) changes over different spatial lags or distances. Using the original spatial weights matrix allows the correlogram to reflect the true intensity of spatial autocorrelation at various distances.\nRow-standardizing weights can distort the actual spatial influence by giving an equal contribution to all neighboring observations, regardless of their spatial closeness or the intensity of their spatial relationship. This could obscure patterns of spatial autocorrelation that are distance-dependent."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#overview",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this hands-on exercise, we will compute Global Measures of Spatial Autocorrelation (GMSA) using spdep package. The learning points of this hands-on exercise are to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-started",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are installed in R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,tidyverse,spdep,tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this section, we will bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe note that the simple features data has a polygon geometry and has 88 features and 7 fields. It is in WGS84 geographic coordinate system.\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4,7,15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\ntmap_arrange(equal,\n             quantile,\n             asp = 1,\n             ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-1",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument can take TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria (which is on the basis of shared boundaries):\nThe code chunk below is used to compute Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan,\n                queen = TRUE)\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours and there are two ara units with only one neighbour.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = \"W\",\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.policy.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-morans-i-statistic-testing",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-morans-i-statistic-testing",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this section, we will perform Moran’s I statistics testing using moran.test() of spdep.\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC,\n           listw = rswm_q,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\nThe code chunk below performs the permutation test for Moran’s I statistic using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999,\n                 zero.policy = TRUE,\n                 na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nIt is always a good practice to examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\nabline(v = 0,\n       col = \"red\")\n\n\n\n\n\n\n\n\nAlternatively, we can use ggplot2 to plot the graph:\n\nggplot(data.frame(res = bperm$res),aes(x=res)) +\n  geom_histogram(bins = 20,\n                 color=\"black\", \n                 fill=\"grey\") +\n  geom_vline(xintercept = 0,\n             color=\"red\",\n             linetype=\"dashed\")+\n  labs(x = \"Simulated Moran's I\", y=\"Frequency\")+\n  ggtitle(\"Distribution of Moran's I test statistical values\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "In this section, we will perform Geary’s C statistics testing using appropriate functions of spdep package.\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC,listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC,\n               listw = rswm_q,\n               nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res,\n     freq=TRUE,\n     breaks=20,\n     xlab=\"Simulated Geary's C\")\nabline(v = 1,\n       col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#spatial-correlogram",
    "title": "Hands-on Exercise 5A",
    "section": "",
    "text": "Spatial correlograms are great for examining patterns of spatial autocorrelation in your data or model residuals. They show how correlated pairs of spatial observations are when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance. Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I (note method = “I” in code below). The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = \"I\",\n                          style = \"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C (note method = “C” in code below). The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = \"C\",\n                          style = \"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below:\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nOwn notes on why wm_q is used in correlogram rather than rswm_q\n\n\n\n\nThe primary goal of a spatial correlogram is to examine how spatial autocorrelation (e.g., Moran’s I or Geary’s C) changes over different spatial lags or distances. Using the original spatial weights matrix allows the correlogram to reflect the true intensity of spatial autocorrelation at various distances.\nRow-standardizing weights can distort the actual spatial influence by giving an equal contribution to all neighboring observations, regardless of their spatial closeness or the intensity of their spatial relationship. This could obscure patterns of spatial autocorrelation that are distance-dependent."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. One such example is Local Indicators of Spatial Association (LISA). Beside LISA, Getis-Ord’s Gi-statistics will be introduce as an alternative LMSA statistics that present complementary information or allow us to obtain similar insights for geographically referenced data.\nIn this hands-on exercise, we will compute Local Measures of Spatial Autocorrelation (LMSA) using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package.\n\n\n\n\n\n\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,spdep,tmap,tidyverse)\n\n\n\n\n\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe note that the simple features data has a polygon geometry and has 88 features and 7 fields. It is in WGS84 geographic coordinate system.\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4,7,15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\ntmap_arrange(equal,\n             quantile,\n             asp = 1,\n             ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument can take TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria (which is on the basis of shared boundaries):\nThe code chunk below is used to compute Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan,\n                queen = TRUE)\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours and there are two ara units with only one neighbour.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = \"W\",\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.policy.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\n\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii: the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chunk below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as considered above.\nThe code chunk below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. These are the high-high locations in the lesson slides.\n\n\n\nFirst we will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) of the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that maps neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and center the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories:\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, we place non-significant Moran in the category 0:\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n\nNow, we can build the LISA map by using the code chunk below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n\n\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work.\nTo do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\n\n\n\n\n\n\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks:\n\nFirst, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix().\nNext, cbind() is used to join hunan data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi.\nLastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\n\nThe code chunk below shows the functions used to map Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#overview",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. One such example is Local Indicators of Spatial Association (LISA). Beside LISA, Getis-Ord’s Gi-statistics will be introduce as an alternative LMSA statistics that present complementary information or allow us to obtain similar insights for geographically referenced data.\nIn this hands-on exercise, we will compute Local Measures of Spatial Autocorrelation (LMSA) using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, People Republic of China.\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf,spdep,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "In this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple features object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mooseksm\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe note that the simple features data has a polygon geometry and has 88 features and 7 fields. It is in WGS84 geographic coordinate system.\n\n\n\nNext, we will import Hunan_2012.csv into R using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package:\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4,7,15)\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\",\n            main.title.size = 1,\n            legend.text.size = 0.6,\n            legend.height = 1.20,\n            legend.width = 1.20,\n            frame = TRUE)\n\ntmap_arrange(equal,\n             quantile,\n             asp = 1,\n             ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#local-indicators-of-spatial-association-lisa",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#local-indicators-of-spatial-association-lisa",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Based on the documentation, note that the “queen” argument can take TRUE or FALSE as options. If not specified, the default is set to TRUE and the function will return a list of first order neighbours using the Queen criteria (which is on the basis of shared boundaries):\nThe code chunk below is used to compute Queen contiguity weight matrix:\n\nwm_q &lt;- poly2nb(hunan,\n                queen = TRUE)\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours and there are two ara units with only one neighbour.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = \"W\",\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.policy.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\n\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii: the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chunk below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as considered above.\nThe code chunk below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. These are the high-high locations in the lesson slides.\n\n\n\nFirst we will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) of the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that maps neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and center the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories:\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, we place non-significant Moran in the category 0:\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n\nNow, we can build the LISA map by using the code chunk below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n\n\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work.\nTo do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#computing-gi-statistics",
    "title": "Hands-on Exercise 5B",
    "section": "",
    "text": "fips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks:\n\nFirst, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix().\nNext, cbind() is used to join hunan data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi.\nLastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\n\nThe code chunk below shows the functions used to map Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "We carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\nBy yearBy year (at province level)\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that the number of road accidents has generally been increasing from 2019 to 2022.\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nWe save roadacc_month as a rds file:\n\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\n\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\nWe further observe the occurrence of road accidents by month at the province level:\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nSaving them as rds files:\n\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\nLoading the newly created rds files into R:\n\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\np0 &lt;- ggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nggplotly(p0)\n\n\n\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\np1 &lt;- ggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nggplotly(p1)\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur in clear weather conditions, followed by rainy weather conditions and dark weather conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-for-spatial-point-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-for-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "To carry out spatial point pattern analysis - the evaluation of the pattern or distribution of a set of points on a surface - we need to convert the data from sf format to ppp format:\n\nroadacc_ppp &lt;- as.ppp(roadacc)\nroadacc_ppp\n\nMarked planar point pattern: 12985 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\nThe code chunk below plots roadacc_ppp for visualisation:\n\nplot(roadacc_ppp)\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the roadacc_ppp object using the code chunk below:\n\nsummary(roadacc_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.217956e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\n\nIn spatial point patterns analysis, a significant issue is the presence of duplicates as the statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple i.e. that the points cannot be coincident. We check for duplication in a ppp object via the code chunk below:\n\nany(duplicated(roadacc_ppp))\n\n[1] FALSE\n\n\nThe data does not have any duplicated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region. The code chunk below is used to covert provincedata32647 SpatialPolygon object into owin object of spatstat:\n\nprovinceowin &lt;- as.owin(provincedata32647)\n\nThe ouput object can be displayed by using plot() function\n\nplot(provinceowin)\n\n\n\n\n\n\n\n\n\nsummary(provinceowin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nWe extract road accident events that are located within the BMR by using the code chunk below:\n\nroadacc_owin_ppp = roadacc_ppp[provinceowin]\n\n\nplot(roadacc_owin_ppp)\n\n\n\n\n\n\n\n\n\nsummary(roadacc_owin_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.693182e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation-kde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation-kde",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "We will proceed to compute the KDE of road accidents in the BMR.\n\n\nWe will derive adaptive KDE using density.adaptive() of spatstat. Adaptive schemes adjust itself according to the density of data - shorter bandwidths are used where data are dense and longer where sparse. This helps to mitigate against highly skewed distribution of spatial point patterns.\nHowever, before we do so, we convert the unit of measurement to kilometer as the default unit of measurement of EPSG: 32647 is in metres, which would make the values hard to comprehend:\n\nroadacc_owin_ppp.km &lt;- rescale.ppp(roadacc_owin_ppp,\n                                   1000,\n                                   \"km\")\n\n\nkde_roadacc_adaptive &lt;- adaptive.density(roadacc_owin_ppp.km, method = \"kernel\")\nplot(kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output for mapping purposes:\n\ngridded_kde_roadacc_adaptive &lt;- as.SpatialGridDataFrame.im(kde_roadacc_adaptive)\nspplot(gridded_kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package:\n\nkde_roadacc_adaptive_raster &lt;- raster(kde_roadacc_adaptive)\n\nWe view the properties of kde_roadacc_adaptive_raster RasterLayer:\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nNote that the CRS property is NA.\n\n\n\nWe hence assign CRS information to the kde_roadacc_adaptive_raster RasterLayer:\n\nprojection(kde_roadacc_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nThe CRS property is now completed.\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_roadacc_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk will be used to extract the different provinces:\n\nbkk &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nnp &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Nakhon Pathom\")\nn &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Nonthaburi\")\npt &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Pathum Thani\")\nsp &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Samut Prakan\")\nss &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Samut Sakhon\")\n\n\n\n\n\nbkk_owin = as.owin(bkk)\nnp_owin = as.owin(np)\nn_owin = as.owin(n)\npt_owin = as.owin(pt)\nsp_owin = as.owin(sp)\nss_owin = as.owin(ss)\n\n\n\n\nBy using the code chunk below, we are able to extract road accidents that is within the specific province to carry out our analysis later on.\n\nroadacc_bkk_ppp = roadacc_ppp[bkk_owin]\nroadacc_np_ppp = roadacc_ppp[np_owin]\nroadacc_n_ppp = roadacc_ppp[n_owin]\nroadacc_pt_ppp = roadacc_ppp[pt_owin]\nroadacc_sp_ppp = roadacc_ppp[sp_owin]\nroadacc_ss_ppp = roadacc_ppp[ss_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre:\n\nroadacc_bkk_ppp.km = rescale.ppp(roadacc_bkk_ppp,1000,\"km\")\nroadacc_np_ppp.km = rescale.ppp(roadacc_np_ppp,1000,\"km\")\nroadacc_n_ppp.km = rescale.ppp(roadacc_n_ppp,1000,\"km\")\nroadacc_pt_ppp.km = rescale.ppp(roadacc_pt_ppp,1000,\"km\")\nroadacc_sp_ppp.km = rescale.ppp(roadacc_sp_ppp,1000,\"km\")\nroadacc_ss_ppp.km = rescale.ppp(roadacc_ss_ppp,1000,\"km\")\n\nWe then plot the 6 provinces and the locations of the road accidents:\n\npar(mfrow=c(3,2))\nplot(roadacc_bkk_ppp.km,main=\"Bangkok\")\nplot(roadacc_np_ppp.km,main=\"Nakhon Pathom\")\nplot(roadacc_n_ppp.km,main=\"Nonthaburi\")\nplot(roadacc_pt_ppp.km,main=\"Pathum Thani\")\nplot(roadacc_sp_ppp.km,main=\"Samut Prakan\")\nplot(roadacc_ss_ppp.km,main=\"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute the KDE of the 6 provinces:\n\noptions(repr.plot.width=12, repr.plot.height=8)\npar(mfrow=c(3,2))\nplot(density(roadacc_bkk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bangkok\")\nplot(density(roadacc_np_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Nakhon Pathom\")\nplot(density(roadacc_n_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Nonthaburi\")\nplot(density(roadacc_pt_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Pathum Thani\")\nplot(density(roadacc_sp_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Samut Prakan\")\nplot(density(roadacc_ss_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Samut Sakhon\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nearest-neighbour-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nearest-neighbour-analysis",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "We will perform the Clark-Evans test of aggregation for spatial point pattern:\nThe test hypotheses are:\nH0: The distribution of road accidents is randomly distributed.\nH1: The distribution of road accidents is not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\nOverall BMRBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nclarkevans.test(roadacc_owin_ppp.km,\n                correction = \"none\",\n                clipregion = \"province_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_owin_ppp.km\nR = 0.19092, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nSince p-value is less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents is not randomly distributed.\n\n\n\nclarkevans.test(roadacc_bkk_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_bkk_ppp.km\nR = 0.12057, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_np_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_np_ppp.km\nR = 0.28949, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_n_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_n_ppp.km\nR = 0.38919, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_pt_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_pt_ppp.km\nR = 0.24798, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_sp_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_sp_ppp.km\nR = 0.14367, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_ss_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_ss_ppp.km\nR = 0.23989, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nBased on the results above, for which p-values are less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents in all provinces is not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_EDA.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_EDA.html",
    "title": "Take-home Exercise 1 (Additional EDA)",
    "section": "",
    "text": "Increasing timeout to mitigate error issues during rendering\n\n\n\n\n\n\noptions(timeout = 3000)\n\n\n\n\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)\n\n\n\n\n\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\n\n\n\n\n\n\n\nWe carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\nBy yearBy year (at province level)\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that the number of road accidents has generally been increasing from 2019 to 2022.\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nWe save roadacc_month as a rds file:\n\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\n\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\nWe further observe the occurrence of road accidents by month at the province level:\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nSaving them as rds files:\n\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\nLoading the newly created rds files into R:\n\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\np0 &lt;- ggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nggplotly(p0)\n\n\n\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\np1 &lt;- ggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nggplotly(p1)\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur in clear weather conditions, followed by rainy weather conditions and dark weather conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_EDA.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_EDA.html#exploratory-data-analysis-eda",
    "title": "Take-home Exercise 1 (Additional EDA)",
    "section": "",
    "text": "We carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\nBy yearBy year (at province level)\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that the number of road accidents has generally been increasing from 2019 to 2022.\n\n\n\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nWe save roadacc_month as a rds file:\n\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\n\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\nWe further observe the occurrence of road accidents by month at the province level:\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nSaving them as rds files:\n\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\nLoading the newly created rds files into R:\n\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\np0 &lt;- ggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nggplotly(p0)\n\n\n\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\np1 &lt;- ggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\nggplotly(p1)\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur in clear weather conditions, followed by rainy weather conditions and dark weather conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "According to the World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year and leave between 20 to 50 million people with non-fatal injuries. Vulnerable road users, such as pedestrians, cyclists and motorcyclists, make up more than half of all road traffic deaths.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5 to 29, however two-thirds of road traffic fatalities occur among people of working ages, from 18 to 59 years. Further, nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries make up only around 60% of the world’s vehicles.\nBesides human suffering, road traffic injuries also result in a heavy economic burden on victims and their families, through treatment costs for the injured and loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nAccording to the WHO, Thailand’s roads are the deadliest in Southeast Asia and among the worst in the world - about 20,000 people die in road accidents each year, or about 56 deaths a day.\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which make up the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed as ‘black spots’ which are distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes.\n\n\n\nBy and large, road traffic accidents can be attributed by two major factors, namely behavioural and environmental factors.\n\nBehavioural factors in driving are considered to be major causes of traffic accidents either in direct or indirect manner (Lewin, 1982). These factors can be further grouped into driver behavior (driver/driving style) and driver performance (driver/driving skills) (Elander, West, & French, 1993).\nEnvironmental factors, on the other hand, includes but not limited to weather conditions such as poor visibility during heavy rain or fogs as well as road conditions such as sharp bends, slippery slopes, and blind spots.\n\nPrevious studies have demonstrated the significant potential of Spatial Point Patterns Analysis (SPPA) in exploring and identifying factors influencing road traffic accidents. However, these studies often focus solely on either behavioral or environmental factors, with limited consideration of temporal factors such as season, day of the week, or time of day.\nIn view of this, in this hands-on exercise, we will determine factors that affect road traffic accidents in the Bangkok Metropolitan Region (BMR) by employing both spatial and spatio-temporal point patterns analysis methods.\nThe specific objectives are as follows:\n\nTo visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nTo conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nTo conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods.\n\n\n\n\nKey packages that are installed are:\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)\n\n\n\n\nFor the purpose of this exercise, three basic data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle - comprised records of road accidents in Thailand from ~2019 to 2022, based on information provided by the Office of the Permanent Secretary, Ministry of Transport.\nThailand - Subnational Administrative Boundaries on HDX\nThailand Roads (OpenStreetMap Export) on HDX\n\n\n\n\n\n\nThe data is imported using the code below:\n\nroadacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nTaking a glimpse at the data to determine the fields in the data:\n\nglimpse(roadacc)\n\nThere are 81735 rows and 18 variables. Further details about the important variables that would be needed for analysis can be found in the dropdown box below:\n\n\n\n\n\n\nMore information about variables for analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nField\nDescription\nPurpose of data i.e. what it might indicate\n\n\n\n\nincident_datetime\nThe date and time of the accident occurrence\nwhether accidents tend to occur at specific:\n\nmonths\nday of week\ntime of the day\n\n\n\nreport_datetime\nThe date and time when the accident was reported\nefficacy at which accident was reported could indicate:\n\nhow busy the road segment is\nhow tightly the road is being monitored/ whether there is a lapse in the management of the road\n\n\n\nprovince_en\nThe name of the province in Thailand, written in English\nsupports the filtering of data to just BMR\n\n\nagency\nThe government agency responsible for the road and traffic management\npinpoints the responsible government agency, could indicate whether there is a need for government agency to take corrective actions\n\n\nroute\nThe route or road segment where the accident occurred\nwhile the data can be used to determine frequency of incident at different locations, it is not useful for our case as it’s in the Thai language\n\n\nvehicle_type\nThe type of vehicle involved in the accident\ncan determine frequency of vehicle types involved in accidents\n\n\npresumed_cause\nThe presumed cause or reason for the accident\ncan determine distribution of cause for accidents\n\n\naccident_type\nThe type or nature of the accident\ncan determine distribution of nature of accidents\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nweather_condition\nThe weather condition at the time of the accident\ncan determine how much weather conditions can affect the occurrence of accidents\n\n\nlatitude\nThe latitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nlongitude\nThe longitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred\ncan determine how road types can affect the occurrence of accidents\n\n\nslope_description\nThe description of the slope condition at the accident location\ncan determine how presence of slopes can affect the occurrence of accidents\n\n\n\n\n\n\n\n\n\nWe will first drop “province_th” as it indicates the provinces in the Thai language.\n\nroadacc &lt;- roadacc[, !names(roadacc) %in% c(\"province_th\",\"route\")]\n\n\n\n\nWe then determine the unique provinces within the dataset and scan through the province names (i.e. in case there are any entries that refer to the same province but are spelt differently/have spelling mistakes) before filtering the data to just include provinces that are within the BMR:\n\nunique_provinces &lt;- roadacc %&gt;% \n  distinct(province_en) %&gt;%\n  arrange(province_en)\n\nBased on observations, there were no spelling mistakes. As such we can proceed with filtering the data to keep our region of interest which comprises Bangkok and five adjacent provinces of Nakhon Pathom, Nonthaburi, Pathum Thani, Samut Prakan and Samut Sakhon:\n\nroadacc &lt;- roadacc %&gt;% \n  filter(province_en %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves the data with 13336 rows.\n\n\n\nWe further clean the data by removing rows with missing data:\n\nroadacc &lt;- roadacc %&gt;%\n  drop_na()\n\n\n\n\nWe also check if there are duplicate entries in the dataset:\n\nroadacc$acc_code[duplicated(roadacc$acc_code) == TRUE]\n\nThere are no duplicate entries.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nDuring class, Prof Kam had advised to study the data carefully and shared that it was important to filter out data with incomplete coordinates (missing either longitude or latitude or both) and shared that one way to do it was via the code below:\n\nroadacc &lt;- roadacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\")\n\nAs with the drop_na() code above, this way will also leave just 12986 rows of data as the missing data were found in either the longitude or latitude variables.\n\n\n\n\n\nWe convert roadacc data frame into a simple feature data frame and also transform the data from geographic coordinate system (EPSG: 4326 WGS84 Geographic Coordinate System) to projected coordinate system:\n\nroadacc &lt;- st_as_sf(roadacc, \n                    coords = c(\"longitude\", \"latitude\"),\n                    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nBased on the summary statistics of roadacc above, it is noted that the minimum longitude is 99.85° and maximum longitude is 100.94°. While there are 2 possible projected coordinate systems for Thailand, EPSG 32647 and 32648, the appropriate projected coordinate system to transform the data to would be EPSG 32647 as the minimum and maximum longitude of roadacc falls within EPSG 32467’s area of use (between 96°E and 102°E). A comparison of the area of use for both projected coordinate systems is shown below:\n\n\n\n\nEPSG 32647\nEPSG 32648\n\n\n\n\nArea of use\nBetween 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\nBetween 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\n\n\n\n\n\n\nThe incident_datetime and report_datetime variables are in datetime field, we hence utilise these variables and the lubridate() function to generate new variables that represent:\n\nmonth: “inc_month”\nday of week: “inc_dayofweek”\ntime of day: “inc_time”\n\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(inc_year = year(incident_datetime)) %&gt;%\n  mutate(inc_month = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(inc_dayofweek = wday(incident_datetime,\n                              week_start = getOption(\"lubridate.week.start\", 1),\n                              label = TRUE,\n                              abbr = TRUE)) %&gt;%\n  mutate(inc_time = hour(incident_datetime))\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nNote that we can generate month in numbers or in factor format via:\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE))\n\n\n\nWe also determine the gap between the incident time and reporting time and create a new variable “timegap” in hours unit:\n\nroadacc$timegap &lt;- time_length(roadacc$report_datetime - roadacc$incident_datetime, \"hours\")\n\nLogically, the date and time when the accident was reported should be after the date and time of the accident occurrence. Looking at the summary statistics below, there are data entries that could have been erroneously recorded resulting in a negative time gap between report time and incident time (i.e. report time was earlier than incident time). As such, the data was further filtered to remove erroneous data to avoid affecting the analysis:\n\nsummary(roadacc$timegap)\n\n\nroadacc &lt;- roadacc %&gt;%\n  filter(timegap &gt;= 0)\n\nThis leaves us with 12985 rows.\n\n\n\nWe then save this cleaned data as a rds file:\n\nwrite_rds(roadacc,\"data/rds/roadacc.rds\")\n\n\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nIt is good practice to save cleaned file as a new rds file via write_rds() to avoid re-running the data cleaning and wrangling codes. write_rds() will take care of all the objects within the dataset. Once the file is saved, we can add “#| eval: false” to the data cleaning and wrangling codes to avoid re-running them.\n\n\n\n\n\n\nThe data has different files providing details of the administrative boundaries of Thailand at different administrative levels:\n\nLevel 0 (country)\nLevel 1 (province)\nLevel 2 (district)\nLevel 3 (sub-district, tambon)\n\nAs our area of interest is at Level 1 (province level), we will utilise “tha_admbnda_adm1_rtsd_20220121” that reflects details at province levels and import the data using the code chunk below:\n\nprovincedata = st_read(dsn = \"data/rawdata\", \n                  layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nWe note from the above that it is a multipolygon feature data frame. We note that there are 77 features and 16 fields, and the data is in WGS84 geographic coordinate system.\nWe then take a glimpse of the data:\n\nglimpse(provincedata)\n\n\n\n\nWe note from a glimpse of the data above that there are only a few pertinent fields that we require for our analysis, specifically:\n\nADM1_EN: province name in english\nShape_Leng\nShape_Area\ngeometry\n\nWe hence filter the data to only comprise these fields to make the data frame more manageable:\n\nprovincedata &lt;- provincedata %&gt;%\n  select(\"ADM1_EN\", \"Shape_Leng\",\"Shape_Area\",\"geometry\")\n\n\n\n\nWe also filter to keep only data that are relevant to our area of interest which is BMR:\n\nprovincedata &lt;- provincedata %&gt;% \n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves 6 rows of data and 4 variables.\n\n\n\nFrom the code chunk below, it is noted that the EPSG code for the selectedboundaries data frame is EPSG: 4326:\n\nst_crs(provincedata)\n\nWe will need to reproject provincedata from EPSG code to EPSG: 32647 which is the projected coordinate system to use for BMR, our area of interest:\n\nprovincedata32647 &lt;- st_transform(provincedata, \n                              crs = 32647)\n\nWe check if the EPSG code has been correctly assigned:\n\nst_crs(provincedata32647)\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(provincedata32647,\"data/rds/provincedata32647.rds\")\n\n\nprovincedata32647 &lt;- read_rds(\"data/rds/provincedata32647.rds\")\n\nWe visualise our provincedata32647:\n\ntmap_mode('plot')\ntm_shape(provincedata32647)+\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nWe import the data as follows:\n\nroadlines = st_read(dsn = \"data/rawdata\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe then glimpse at the data:\n\nglimpse(roadlines)\n\n\nst_geometry(roadlines)\n\nThe dataset is of the multilinestring geometry and is very large, with 2792590 rows and 15 variables but we only need to extract relevant information that lie within the BMR for analysis.\n\n\n\nBased on the code chunk below, it is noted that the coordinate system of the roadlines data is missing.\n\nst_crs(roadlines)\n\nBased on the values of the geometry in roadlines, the coordinates seem to be in geographic (latitude/longitude) form, in degrees, typically in a CRS like EPSG:4326 (WGS 84) used for global geographic coordinates. We hence assign the missing EPSG code using the code chunk below:\n\nroadlines4326 &lt;- st_set_crs(roadlines,4326)\n\nWe check the CRS using the code chunk below:\n\nst_crs(roadlines4326)\n\nFor analysis, we would eventually need to overlay the roadlines4326 data with the selectedboundaries32647 data to determine the roads that lie within BMR. In order to perform geoprocessing using two geospatial data, both geospatial data would need to be projected using similar coordinate systems - in this case, it its EPSG: 32647:\n\nroadlines32647 &lt;- st_transform(roadlines4326, crs = 32647)\n\nWe check the CRS code again:\n\nst_crs(roadlines32647)\n\n\n\n\nBased on the columns in the data frame roadlines32647, the columns that seem relevant/useful to retain for analysis are “highway”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge” and “geometry”.\nHowever before going ahead to retain these variables, we determine the presence of missing data within roadlines32647:\n\nmissing_counts &lt;- sapply(roadlines32647, function(x) sum(is.na(x)))\nprint(missing_counts)\n\nBased on the result we obtained, more than 60% of data is missing for the variable “source” and more than 80% of data is missing for the variables “name”, “name_en”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge”, “layer”, “source” and “name_th”. Given the extent of missing data, we will omit these columns as they would not provide useful information for analysis and only retain the relevant/useful columns “highway” and “geometry” with no missing data:\n\nselectedroadlines &lt;- roadlines32647 %&gt;%\n  select(\"highway\", \"geometry\")\n\n\n\n\nThe code chunk below is used to determine the types of highways in the selectedroadlines data frame:\n\nunique_highway &lt;- unique(selectedroadlines$highway)\nunique_highway &lt;- sort(unique_highway)\n\nunique_highway\n\nWhile there are several classes of highway, our analysis will focus on the major classes of highway as stated on Thailand Highway Classification, otherwise the map will be too overcrowded for analysis and we might also experience lags in rendering the Quarto document.\nA detailed explanation on the selected major highways is indicated in the table below:\n\n\n\nTypes of highway\nDetails\nIncluded for analysis?\n\n\n\n\nmotorway\nExpressway with full access control (source)\nYes\n\n\nprimary\nTop-level urban road across the city connecting trunk to trunk, or road of equal or greater importance than the primary intercity highway that runs through that city (source)\nYes\n\n\nsecondary\nMain urban road connecting primary to primary or higher, or road of equal or greater importance than the secondary intercity highway that runs through that city. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntertiary\nRoads that are more important than regular unclassified or residential roads, or roads that connect several unclassified or residential roads. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrunk\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\n\n\nselectedroadlines &lt;- selectedroadlines %&gt;%\n  filter(highway %in% c(\"motorway\",\"primary\",\"secondary\",\"tertiary\",\"trunk\"))\n\n\n\n\nWe require only a subset of the selectedroadlines data to just roads within our area of interest, BMR and hence we utilise st_intersection() to find retain roads that are within the BMR boundaries given by provincedata32647:\n\nroadsbkk &lt;- st_intersection(selectedroadlines,provincedata32647)\n\nThis reduced the data to 19386 rows of data.\nWe take a quick look at the geometry and note that the plot has cleaned up significantly. We will proceed with this data:\n\nplot(st_geometry(roadsbkk))\n\n\n\n\nWe then check the geometry of roadsbkk:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\nBased on the output from above, the roadsbkk data comprises both linestring and multilinestring geometries. Linestring represents a single line, while MultiLinestring represents a collection of multiple lines. We need to simplify the data structure by converting multilinestring to linestring geometry to facilitate downstream analysis as the use of multilinestring might lead to error.\nWe utilise the st_cast() function to break down multilinestring geometries to linestring geometries:\n\nroadsbkk &lt;- st_cast(roadsbkk,\"LINESTRING\",group_or_split = TRUE)\n\nWe double check the geometry types and note from the output below that the geometry is now just linestring:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkk.rds\")\n\n\nroadsbkk &lt;- read_rds(\"data/rds/roadsbkk.rds\")\n\n\n\n\n\nWe carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\n\nCode\ntmap_mode('plot')\ntm_shape(provincedata32647) + \n  tm_polygons() +           \n  tm_shape(roadacc) + \n  tm_dots(col ='red') +\n  tm_shape(roadsbkk)+\n  tm_lines(col = 'black')\n\n\n\n\n\n\n\n\n\nAs seen from the map above, road accidents within the BMR seem to be more concentrated within the provinces on the right side (Bangkok, Pathum Thani and Samut Prakan). Plotting the distribution of road accidents across provinces, we note from the plot below that Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\n\n\nTo plot the distribution of road accidents by months across the years, we create a roadacc_month file that groups the road accidents per month for each year.\n\n\nCode\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\n\n\nCode\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\n\n\nCode\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\nCode\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\n\n\nCode\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\nSaving them as rds files:\n\n\nCode\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\n\nLoading the newly created rds files into R:\n\n\nCode\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n\n\n\n\n\n\n\n\n\nCode\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, it can be seen that road accidents most frequently occur during clear weather conditions followed by rainy and then dark conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi).\nTo minimise the slow loading of the page, the Take-home Exercise 1 has been divided into 2 parts - please refer to Part 1B which covers spatial point pattern analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#background",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "According to the World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year and leave between 20 to 50 million people with non-fatal injuries. Vulnerable road users, such as pedestrians, cyclists and motorcyclists, make up more than half of all road traffic deaths.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5 to 29, however two-thirds of road traffic fatalities occur among people of working ages, from 18 to 59 years. Further, nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries make up only around 60% of the world’s vehicles.\nBesides human suffering, road traffic injuries also result in a heavy economic burden on victims and their families, through treatment costs for the injured and loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nAccording to the WHO, Thailand’s roads are the deadliest in Southeast Asia and among the worst in the world - about 20,000 people die in road accidents each year, or about 56 deaths a day.\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which make up the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed as ‘black spots’ which are distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#objectives",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "By and large, road traffic accidents can be attributed by two major factors, namely behavioural and environmental factors.\n\nBehavioural factors in driving are considered to be major causes of traffic accidents either in direct or indirect manner (Lewin, 1982). These factors can be further grouped into driver behavior (driver/driving style) and driver performance (driver/driving skills) (Elander, West, & French, 1993).\nEnvironmental factors, on the other hand, includes but not limited to weather conditions such as poor visibility during heavy rain or fogs as well as road conditions such as sharp bends, slippery slopes, and blind spots.\n\nPrevious studies have demonstrated the significant potential of Spatial Point Patterns Analysis (SPPA) in exploring and identifying factors influencing road traffic accidents. However, these studies often focus solely on either behavioral or environmental factors, with limited consideration of temporal factors such as season, day of the week, or time of day.\nIn view of this, in this hands-on exercise, we will determine factors that affect road traffic accidents in the Bangkok Metropolitan Region (BMR) by employing both spatial and spatio-temporal point patterns analysis methods.\nThe specific objectives are as follows:\n\nTo visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nTo conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nTo conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#installing-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#installing-and-launching-r-packages",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "Key packages that are installed are:\n\nsf for importing, managing, and processing vector-based geospatial data, and\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nspNetwork which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (`listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\nThe packages are loaded with the following code chunk:\n\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#data",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "For the purpose of this exercise, three basic data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle - comprised records of road accidents in Thailand from ~2019 to 2022, based on information provided by the Office of the Permanent Secretary, Ministry of Transport.\nThailand - Subnational Administrative Boundaries on HDX\nThailand Roads (OpenStreetMap Export) on HDX"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#importing-cleaning-and-wrangling-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#importing-cleaning-and-wrangling-data",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "The data is imported using the code below:\n\nroadacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\")\n\nTaking a glimpse at the data to determine the fields in the data:\n\nglimpse(roadacc)\n\nThere are 81735 rows and 18 variables. Further details about the important variables that would be needed for analysis can be found in the dropdown box below:\n\n\n\n\n\n\nMore information about variables for analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nField\nDescription\nPurpose of data i.e. what it might indicate\n\n\n\n\nincident_datetime\nThe date and time of the accident occurrence\nwhether accidents tend to occur at specific:\n\nmonths\nday of week\ntime of the day\n\n\n\nreport_datetime\nThe date and time when the accident was reported\nefficacy at which accident was reported could indicate:\n\nhow busy the road segment is\nhow tightly the road is being monitored/ whether there is a lapse in the management of the road\n\n\n\nprovince_en\nThe name of the province in Thailand, written in English\nsupports the filtering of data to just BMR\n\n\nagency\nThe government agency responsible for the road and traffic management\npinpoints the responsible government agency, could indicate whether there is a need for government agency to take corrective actions\n\n\nroute\nThe route or road segment where the accident occurred\nwhile the data can be used to determine frequency of incident at different locations, it is not useful for our case as it’s in the Thai language\n\n\nvehicle_type\nThe type of vehicle involved in the accident\ncan determine frequency of vehicle types involved in accidents\n\n\npresumed_cause\nThe presumed cause or reason for the accident\ncan determine distribution of cause for accidents\n\n\naccident_type\nThe type or nature of the accident\ncan determine distribution of nature of accidents\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident\ncan determine the scale of accidents at different locations i.e. how severe/deadly\n\n\nweather_condition\nThe weather condition at the time of the accident\ncan determine how much weather conditions can affect the occurrence of accidents\n\n\nlatitude\nThe latitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nlongitude\nThe longitude coordinate of the accident location\nused for mapping and for analysis with other datasets\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred\ncan determine how road types can affect the occurrence of accidents\n\n\nslope_description\nThe description of the slope condition at the accident location\ncan determine how presence of slopes can affect the occurrence of accidents\n\n\n\n\n\n\n\n\n\nWe will first drop “province_th” as it indicates the provinces in the Thai language.\n\nroadacc &lt;- roadacc[, !names(roadacc) %in% c(\"province_th\",\"route\")]\n\n\n\n\nWe then determine the unique provinces within the dataset and scan through the province names (i.e. in case there are any entries that refer to the same province but are spelt differently/have spelling mistakes) before filtering the data to just include provinces that are within the BMR:\n\nunique_provinces &lt;- roadacc %&gt;% \n  distinct(province_en) %&gt;%\n  arrange(province_en)\n\nBased on observations, there were no spelling mistakes. As such we can proceed with filtering the data to keep our region of interest which comprises Bangkok and five adjacent provinces of Nakhon Pathom, Nonthaburi, Pathum Thani, Samut Prakan and Samut Sakhon:\n\nroadacc &lt;- roadacc %&gt;% \n  filter(province_en %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves the data with 13336 rows.\n\n\n\nWe further clean the data by removing rows with missing data:\n\nroadacc &lt;- roadacc %&gt;%\n  drop_na()\n\n\n\n\nWe also check if there are duplicate entries in the dataset:\n\nroadacc$acc_code[duplicated(roadacc$acc_code) == TRUE]\n\nThere are no duplicate entries.\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nDuring class, Prof Kam had advised to study the data carefully and shared that it was important to filter out data with incomplete coordinates (missing either longitude or latitude or both) and shared that one way to do it was via the code below:\n\nroadacc &lt;- roadacc %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\")\n\nAs with the drop_na() code above, this way will also leave just 12986 rows of data as the missing data were found in either the longitude or latitude variables.\n\n\n\n\n\nWe convert roadacc data frame into a simple feature data frame and also transform the data from geographic coordinate system (EPSG: 4326 WGS84 Geographic Coordinate System) to projected coordinate system:\n\nroadacc &lt;- st_as_sf(roadacc, \n                    coords = c(\"longitude\", \"latitude\"),\n                    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nBased on the summary statistics of roadacc above, it is noted that the minimum longitude is 99.85° and maximum longitude is 100.94°. While there are 2 possible projected coordinate systems for Thailand, EPSG 32647 and 32648, the appropriate projected coordinate system to transform the data to would be EPSG 32647 as the minimum and maximum longitude of roadacc falls within EPSG 32467’s area of use (between 96°E and 102°E). A comparison of the area of use for both projected coordinate systems is shown below:\n\n\n\n\nEPSG 32647\nEPSG 32648\n\n\n\n\nArea of use\nBetween 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\nBetween 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\n\n\n\n\n\n\nThe incident_datetime and report_datetime variables are in datetime field, we hence utilise these variables and the lubridate() function to generate new variables that represent:\n\nmonth: “inc_month”\nday of week: “inc_dayofweek”\ntime of day: “inc_time”\n\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(inc_year = year(incident_datetime)) %&gt;%\n  mutate(inc_month = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;%\n  mutate(inc_dayofweek = wday(incident_datetime,\n                              week_start = getOption(\"lubridate.week.start\", 1),\n                              label = TRUE,\n                              abbr = TRUE)) %&gt;%\n  mutate(inc_time = hour(incident_datetime))\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\nNote that we can generate month in numbers or in factor format via:\n\nroadacc &lt;- roadacc %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE))\n\n\n\nWe also determine the gap between the incident time and reporting time and create a new variable “timegap” in hours unit:\n\nroadacc$timegap &lt;- time_length(roadacc$report_datetime - roadacc$incident_datetime, \"hours\")\n\nLogically, the date and time when the accident was reported should be after the date and time of the accident occurrence. Looking at the summary statistics below, there are data entries that could have been erroneously recorded resulting in a negative time gap between report time and incident time (i.e. report time was earlier than incident time). As such, the data was further filtered to remove erroneous data to avoid affecting the analysis:\n\nsummary(roadacc$timegap)\n\n\nroadacc &lt;- roadacc %&gt;%\n  filter(timegap &gt;= 0)\n\nThis leaves us with 12985 rows.\n\n\n\nWe then save this cleaned data as a rds file:\n\nwrite_rds(roadacc,\"data/rds/roadacc.rds\")\n\n\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\n\n\n\n\n\n\n\nIn-class notes from Prof Kam:\n\n\n\n\nIt is good practice to save cleaned file as a new rds file via write_rds() to avoid re-running the data cleaning and wrangling codes. write_rds() will take care of all the objects within the dataset. Once the file is saved, we can add “#| eval: false” to the data cleaning and wrangling codes to avoid re-running them.\n\n\n\n\n\n\nThe data has different files providing details of the administrative boundaries of Thailand at different administrative levels:\n\nLevel 0 (country)\nLevel 1 (province)\nLevel 2 (district)\nLevel 3 (sub-district, tambon)\n\nAs our area of interest is at Level 1 (province level), we will utilise “tha_admbnda_adm1_rtsd_20220121” that reflects details at province levels and import the data using the code chunk below:\n\nprovincedata = st_read(dsn = \"data/rawdata\", \n                  layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nWe note from the above that it is a multipolygon feature data frame. We note that there are 77 features and 16 fields, and the data is in WGS84 geographic coordinate system.\nWe then take a glimpse of the data:\n\nglimpse(provincedata)\n\n\n\n\nWe note from a glimpse of the data above that there are only a few pertinent fields that we require for our analysis, specifically:\n\nADM1_EN: province name in english\nShape_Leng\nShape_Area\ngeometry\n\nWe hence filter the data to only comprise these fields to make the data frame more manageable:\n\nprovincedata &lt;- provincedata %&gt;%\n  select(\"ADM1_EN\", \"Shape_Leng\",\"Shape_Area\",\"geometry\")\n\n\n\n\nWe also filter to keep only data that are relevant to our area of interest which is BMR:\n\nprovincedata &lt;- provincedata %&gt;% \n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\",\"Samut Prakan\",\"Samut Sakhon\"))\n\nThis leaves 6 rows of data and 4 variables.\n\n\n\nFrom the code chunk below, it is noted that the EPSG code for the selectedboundaries data frame is EPSG: 4326:\n\nst_crs(provincedata)\n\nWe will need to reproject provincedata from EPSG code to EPSG: 32647 which is the projected coordinate system to use for BMR, our area of interest:\n\nprovincedata32647 &lt;- st_transform(provincedata, \n                              crs = 32647)\n\nWe check if the EPSG code has been correctly assigned:\n\nst_crs(provincedata32647)\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(provincedata32647,\"data/rds/provincedata32647.rds\")\n\n\nprovincedata32647 &lt;- read_rds(\"data/rds/provincedata32647.rds\")\n\nWe visualise our provincedata32647:\n\ntmap_mode('plot')\ntm_shape(provincedata32647)+\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nWe import the data as follows:\n\nroadlines = st_read(dsn = \"data/rawdata\",\n                    layer = \"hotosm_tha_roads_lines_shp\")\n\nWe then glimpse at the data:\n\nglimpse(roadlines)\n\n\nst_geometry(roadlines)\n\nThe dataset is of the multilinestring geometry and is very large, with 2792590 rows and 15 variables but we only need to extract relevant information that lie within the BMR for analysis.\n\n\n\nBased on the code chunk below, it is noted that the coordinate system of the roadlines data is missing.\n\nst_crs(roadlines)\n\nBased on the values of the geometry in roadlines, the coordinates seem to be in geographic (latitude/longitude) form, in degrees, typically in a CRS like EPSG:4326 (WGS 84) used for global geographic coordinates. We hence assign the missing EPSG code using the code chunk below:\n\nroadlines4326 &lt;- st_set_crs(roadlines,4326)\n\nWe check the CRS using the code chunk below:\n\nst_crs(roadlines4326)\n\nFor analysis, we would eventually need to overlay the roadlines4326 data with the selectedboundaries32647 data to determine the roads that lie within BMR. In order to perform geoprocessing using two geospatial data, both geospatial data would need to be projected using similar coordinate systems - in this case, it its EPSG: 32647:\n\nroadlines32647 &lt;- st_transform(roadlines4326, crs = 32647)\n\nWe check the CRS code again:\n\nst_crs(roadlines32647)\n\n\n\n\nBased on the columns in the data frame roadlines32647, the columns that seem relevant/useful to retain for analysis are “highway”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge” and “geometry”.\nHowever before going ahead to retain these variables, we determine the presence of missing data within roadlines32647:\n\nmissing_counts &lt;- sapply(roadlines32647, function(x) sum(is.na(x)))\nprint(missing_counts)\n\nBased on the result we obtained, more than 60% of data is missing for the variable “source” and more than 80% of data is missing for the variables “name”, “name_en”, “surface”, “smoothness”, “width”, “lanes”, “oneway”, “bridge”, “layer”, “source” and “name_th”. Given the extent of missing data, we will omit these columns as they would not provide useful information for analysis and only retain the relevant/useful columns “highway” and “geometry” with no missing data:\n\nselectedroadlines &lt;- roadlines32647 %&gt;%\n  select(\"highway\", \"geometry\")\n\n\n\n\nThe code chunk below is used to determine the types of highways in the selectedroadlines data frame:\n\nunique_highway &lt;- unique(selectedroadlines$highway)\nunique_highway &lt;- sort(unique_highway)\n\nunique_highway\n\nWhile there are several classes of highway, our analysis will focus on the major classes of highway as stated on Thailand Highway Classification, otherwise the map will be too overcrowded for analysis and we might also experience lags in rendering the Quarto document.\nA detailed explanation on the selected major highways is indicated in the table below:\n\n\n\nTypes of highway\nDetails\nIncluded for analysis?\n\n\n\n\nmotorway\nExpressway with full access control (source)\nYes\n\n\nprimary\nTop-level urban road across the city connecting trunk to trunk, or road of equal or greater importance than the primary intercity highway that runs through that city (source)\nYes\n\n\nsecondary\nMain urban road connecting primary to primary or higher, or road of equal or greater importance than the secondary intercity highway that runs through that city. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntertiary\nRoads that are more important than regular unclassified or residential roads, or roads that connect several unclassified or residential roads. Based on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\ntrunk\nBased on table above, motorcars, motorcycles and pedestrians all have access (source)\nYes\n\n\n\n\nselectedroadlines &lt;- selectedroadlines %&gt;%\n  filter(highway %in% c(\"motorway\",\"primary\",\"secondary\",\"tertiary\",\"trunk\"))\n\n\n\n\nWe require only a subset of the selectedroadlines data to just roads within our area of interest, BMR and hence we utilise st_intersection() to find retain roads that are within the BMR boundaries given by provincedata32647:\n\nroadsbkk &lt;- st_intersection(selectedroadlines,provincedata32647)\n\nThis reduced the data to 19386 rows of data.\nWe take a quick look at the geometry and note that the plot has cleaned up significantly. We will proceed with this data:\n\nplot(st_geometry(roadsbkk))\n\n\n\n\nWe then check the geometry of roadsbkk:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\nBased on the output from above, the roadsbkk data comprises both linestring and multilinestring geometries. Linestring represents a single line, while MultiLinestring represents a collection of multiple lines. We need to simplify the data structure by converting multilinestring to linestring geometry to facilitate downstream analysis as the use of multilinestring might lead to error.\nWe utilise the st_cast() function to break down multilinestring geometries to linestring geometries:\n\nroadsbkk &lt;- st_cast(roadsbkk,\"LINESTRING\",group_or_split = TRUE)\n\nWe double check the geometry types and note from the output below that the geometry is now just linestring:\n\ngeometry_types &lt;- roadsbkk %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\ngeometry_types\n\n\n\n\nWe save this cleaned data as a rds file:\n\nwrite_rds(roadsbkk,\"data/rds/roadsbkk.rds\")\n\n\nroadsbkk &lt;- read_rds(\"data/rds/roadsbkk.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01A.html#exploratory-data-analysis-eda",
    "title": "Take-home Exercise 1A",
    "section": "",
    "text": "We carry some EDA to understand how the occurrences of road accidents could be influenced by different factors.\n\n\n\n\nCode\ntmap_mode('plot')\ntm_shape(provincedata32647) + \n  tm_polygons() +           \n  tm_shape(roadacc) + \n  tm_dots(col ='red') +\n  tm_shape(roadsbkk)+\n  tm_lines(col = 'black')\n\n\n\n\n\n\n\n\n\nAs seen from the map above, road accidents within the BMR seem to be more concentrated within the provinces on the right side (Bangkok, Pathum Thani and Samut Prakan). Plotting the distribution of road accidents across provinces, we note from the plot below that Bangkok has the highest occurrences of road accidents in the BMR, followed by Samut Prakan, Pathum Thani, Samut Sakhon, Nakhon Pathom and Nonthaburi.\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(province_en, province_en, .fun = length))) + \n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Distribution of Road Accidents across Provinces\", x = \"Province\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(agency, agency, .fun = length))) + \n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Distribution of Road Accidents by Agency\", x = \"Agency\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAs noted from the plot, the Department of Highways is responsible for the most occurrences of road accidents in the BMR, followed by Department of Rural Roads and Expressway Authority of Thailand.\n\n\n\nWe also analyse the road accidents by time, namely by year, by month, by day of week and by time of day.\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_year)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Year\", x = \"Year\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\n\nWe note from above that the number of road accidents has generally been increasing in Bangkok and Samut Prakan from 2019 to 2022.\n\nThis is with the exception of a drop in 2021 in Bangkok - this could potentially be due to the surge of COVID-19 cases in Thailand in 2021 which led to a lockdown which meant that there were less tourists, vehicles and pedestrians on the roads, and lower occurrences of road accidents.\n\nWe note that the number of road accidents in Nonthaburi and Pathum Thani increased from 2019 to 2021 and fell in 2022.\nWe note that the number of road accidents in Samut Sakhon fell from 2019 to 2021 but increased in 2022.\nOf the 6 provinces, we note that only Nakhon Pathom experienced a fall in road accidents from 2019 to 2022.\n\n\n\n\nWe also observe the data by month using cycle plots that would enable us to observe cyclical/seasonal patterns, if present.\n\n\n\nTo plot the distribution of road accidents by months across the years, we create a roadacc_month file that groups the road accidents per month for each year.\n\n\nCode\nroadacc_month &lt;- roadacc %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\n\n\nCode\nwrite_rds(roadacc_month,\"data/rds/roadacc_month.rds\")\n\n\n\n\nCode\nroadacc_month &lt;- read_rds(\"data/rds/roadacc_month.rds\")\n\n\n\n\nCode\nhline.data &lt;- roadacc_month %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nBased on the plot, we observe the following:\n\nOccurrences of road accidents in Jan and Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 for both months falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul, Aug, Oct to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun and Sep generally do not fluctuate much over the years.\n\n\n\n\n\n\nCode\nroadacc_month_bkk &lt;- roadacc %&gt;%\n  filter(province_en==\"Bangkok\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_sp &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Prakan\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_n &lt;- roadacc %&gt;%\n  filter(province_en==\"Nonthaburi\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_pt &lt;- roadacc %&gt;%\n  filter(province_en==\"Pathum Thani\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_np &lt;- roadacc %&gt;%\n  filter(province_en==\"Nakhon Pathom\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nroadacc_month_ss &lt;- roadacc %&gt;%\n  filter(province_en==\"Samut Sakhon\") %&gt;%\n  group_by(inc_year,inc_month) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\nSaving them as rds files:\n\n\nCode\nwrite_rds(roadacc_month_bkk,\"data/rds/roadacc_month_bkk.rds\")\nwrite_rds(roadacc_month_sp,\"data/rds/roadacc_month_sp.rds\")\nwrite_rds(roadacc_month_n,\"data/rds/roadacc_month_n.rds\")\nwrite_rds(roadacc_month_pt,\"data/rds/roadacc_month_pt.rds\")\nwrite_rds(roadacc_month_np,\"data/rds/roadacc_month_np.rds\")\nwrite_rds(roadacc_month_ss,\"data/rds/roadacc_month_ss.rds\")\n\n\nLoading the newly created rds files into R:\n\n\nCode\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\nBangkokSamut PrakanNonthaburiPathum ThaniNakhon PathomSamut Sakhon\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_bkk %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_bkk, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Bangkok Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to be fluctuating, with the number of road accidents decreasing from 2019 to 2021 then increasing in 2022.\nOccurrences of road accidents in Feb seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Jul to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the rainy season between Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar to Jun generally do not fluctuate much over the years.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_sp %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_sp, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Prakan Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan seem to generally be decreasing over the years, with the number of road accidents in 2022 falling below the average number of road accidents for the month across 2019 to 2022.\nOccurrences of road accidents in Apr to Aug and Nov to Dec seem to generally be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Apr to Aug and the presence of a higher population due to peak tourist seasons in May, Jun, Nov and Dec.\nOccurrences of road accidents in Feb to Mar and Sep to Oct increased initially then fell towards 2022.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_n %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_n, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nonthaburi Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Feb seem to generally be decreasing over the years.\nOccurrences of road accidents in Jan seem to generally be increasing over the years.\nOccurrences of road accidents in Jul, Aug, Nov and Dec increased initially then fell towards 2022.\nOccurrences of road accidents in Mar to Jun, Sep and Oct seem to fluctuate generally around the monthly average across the years.\nAs compared to Bangkok, Samut Prakan and Pathum Thani, the number of road accidents in Nonthaburi seem to be lesser, indicating that roads are more well managed in Nonthaburi.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_pt %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_pt, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Pathum Thani Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jun to Aug and Oct seem to generally be increasing over the years. This could be explained by the rainier seasons in Thailand during this period.\nOccurrences of road accidents in Mar, Apr, May and Nov increased initially then fell towards 2022.\nOccurrences of road accidents in Jan, Feb, Sep and Dec seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_np %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_np, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Nakhon Pathom Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan to Mar, May, Jul to Dec seem to generally be decreasing over the years.\nOccurrences of road accidents in Apr and Jun seem to be fluctuating around the monthly average across the years.\nBased on these observations, it seems like road accidents are much lesser in Nakhon Pathom as compared to the other provinces and it is the only province with no obvious increase in occurrences of road accidents across the years, this indicates that the province is more well managed as compared to the other 5 provinces.\n\n\n\n\n\nCode\nhline.data &lt;- roadacc_month_ss %&gt;%\n  group_by(inc_month) %&gt;%\n  summarise(avgvalue = mean(count))\n\nggplot(data = roadacc_month_ss, aes(x = inc_year, y = count)) +\n  geom_line(aes(group = inc_month, colour = as.factor(inc_month))) +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5)+\n  facet_wrap(~inc_month,scales = \"free_x\")+\n  labs(title = \"Samut Sakhon Road accidents by month from 2019 to 2022\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Number of Road Accidents\")+\n  scale_color_brewer(palette = \"Paired\") + \n  theme(axis.text.x = element_text(angle = 90),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe following observations were made:\n\nOccurrences of road accidents in Jan, Feb, Apr and Jun seem to generally be decreasing over the years.\nOccurrences of road accidents in Jul to Dec seem to be increasing over the years. Based on this observation alone, the increase in road accidents could potentially be due to the hotter and rainier seasons in Jul to Oct and the presence of a higher population due to peak tourist seasons in Nov and Dec.\nOccurrences of road accidents in Mar and May seem to fluctuate generally around the monthly average across the years.\n\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nWe note from the plot that road accidents occur mostly on Fri and Sat and this could be explained by these days being the start of the weekend, and more people and vehicles may be out on the roads and in public places, which increase the chances of road accidents occuring.\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_dayofweek)) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Day of Week\", x = \"Day of Week\", y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")\n\n\n\n\n\n\n\n\n\nCode\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 8\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\n\nAcross the provinces, it is obvious that road accidents occur most often on Fri and Sat in Bangkok. However, for the other provinces, the difference is not so obvious and it seems like the occurrences of road accidents are more well spread out across the week. This could be explained by Bangkok being a prime tourist destination and major urban centre, and it could attract a greater crowd from within and outside of Thailand over the weekend, hence leading to greater traffic on the road and higher chances of road accidents occurring.\n\n\n\n\n\n\n\nOverallBreakdown by province\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the chart, it is observed that road accidents occur more often between 7am to 11pm as compared to 12 midnight to 6am. This could be explained by 7am to 11pm being the time when most are awake for their daily activities and the roads are likely to have higher activity, which result in higher chances of occurrences of road accidents. The top two timings at which road accidents occur are at 9am and 7pm and this could be explained by it being the peak hour at which the general population i.e. workers, school students get to and get off work and school.\n\n\n\n\nCode\nggplot(roadacc, aes(x = inc_time)) + \n  geom_histogram(binwidth = 1, fill = \"slategrey\", color = \"black\") +\n  scale_x_continuous(breaks = seq(0, 23, 1))+\n  labs(title = \"Distribution of Road Accidents by Time of Day\", \n       x = \"Time of Day\",\n       y = \"Count\") +\n  facet_wrap(~province_en, scales = \"fixed\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBangkok, Samut Prakan and Pathum Thani also seem to follow the general observation seen under the overall chart for occurrences of road accidents by time day i.e. road accidents generally occur more during 7am to 11pm and peak timings are during the going to and getting off work/school hours at around 9am and 7pm. This is less obvious for the other provinces.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, it can be seen that road accidents most frequently occur during clear weather conditions followed by rainy and then dark conditions. This could imply that road accidents are more heavily influenced by other behavioural or environmental factors besides the weather condition.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(weather_condition, weather_condition, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Weather Condition\", x = \"Weather Condition\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur during clear weather conditions, followed by rainy and then dark weather conditions.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps. Combining this observation with that for weather conditions - that road accidents mostly occur during clear weather conditions and straight roads - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(road_description, road_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Road Description\", x = \"Road Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on straight roads, roads categorised as other, followed by wide curve and then grade-separated intersection/ramps.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents where there are no slopes. Combining this observation with the above observations - that road accidents mostly occur during clear weather conditions and on straight roads with no slope - which are conditions under which one would not expect road accidents to occur, it could imply that the occurrence of road accidents are more heavily influenced by behavioural factors.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(slope_description, slope_description, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Slope Description\", x = \"Slope Description\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nAcross provinces, similar observations were made as it was observed that road accidents mostly occur on roads with no slope.\n\n\n\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBased on the plot, road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. These are small to mid-sized vehicles.\n\n\nWe do a more detailed analysis at the province level:\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(vehicle_type, vehicle_type, .fun = length))) +\n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Vehicle Type\", x = \"Vehicle Type\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 8))\n\n\n\n\n\n\n\n\n\nBangkok and Samut Prakan follow the same general observation seen under the overall chart for vehicle type involved in road accidents i.e. road accidents mostly involve private/passenger car, followed by 4-wheel pickup truck, motorcycle as the top 3 vehicles. However the following were observed for the other provinces:\n\nRoad accidents in Nakhon Pathom, Pathum Thani and Samut Sakhon mostly involved 4-wheel pickup truck\n4-wheel pickup truck is not one of the top 3 vehicles involved in road accidents in Nonthaburi\n\n\n\n\n\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(presumed_cause, presumed_cause, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Presumed Cause\", x = \"Presumed Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe top presumed cause for accident is speeding.\n\n\n\n\nOverallBreakdown by Province\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe top two presumed cause for road accidents are rear-end collision and rollover/fallen on straight road.\n\n\n\n\nCode\nggplot(roadacc, aes(x = fct_reorder(accident_type, accident_type, .fun = length))) + \n  geom_bar(fill = \"slategrey\") +\n  labs(title = \"Distribution of Road Accidents by Accident Type\", x = \"Accident Type Cause\", y = \"Count\") +\n  facet_wrap(~province_en)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nBangkok, Pathum Thani and Samut Prakan follow the same general observation seen under the overall chart that the top two presumed cause for road accidents are rear-end collision followed by rollover/fallen on straight road. For Nakhon Pathom, Nonthaburi and Samut Sakhon, the top presumed cause is rollover/fallen on straight road followed by rear-end collision.\n\n\n\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_vehicles = median(number_of_vehicles_involved, na.rm = TRUE),\n    mean_vehicles = mean(number_of_vehicles_involved, na.rm = TRUE),\n    min_vehicles = min(number_of_vehicles_involved,na.rm = TRUE),\n    q25 = quantile(number_of_vehicles_involved, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_vehicles_involved, 0.75, na.rm = TRUE),\n    max_vehicles = max(number_of_vehicles_involved,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_vehicles,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_vehicles, 1), \n                        \"\\nMean: \", round(mean_vehicles, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax vehicles: \", round(max_vehicles,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_vehicles_involved,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Vehicles Involved\") +\n  labs(title = \"Distribution of Road Accidents by Number of Vehicles Involved\", x = \"Number of Vehicles Involved\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of vehicles involved in road accidents are either one or two. However, the maximum number of vehicles that had been involved in road accidents were 12 (Pathum Thani), 11 (Bangkok), 10 (Samut Prakan), 9 (Nonthaburi and Samut Sakhon) and 8 (Nakhon Pathom), indicating that while not common, there are large-scale incidents involving large number of vehicles.\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_fatalities = median(number_of_fatalities, na.rm = TRUE),\n    mean_fatalities = mean(number_of_fatalities, na.rm = TRUE),\n    min_fatalities = min(number_of_fatalities,na.rm = TRUE),\n    q25 = quantile(number_of_fatalities, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_fatalities, 0.75, na.rm = TRUE),\n    max_fatalities = max(number_of_fatalities,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_fatalities,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_fatalities, 1), \n                        \"\\nMean: \", round(mean_fatalities, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax fatalities: \", round(max_fatalities,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_fatalities,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Fatalities\") +\n  labs(title = \"Distribution of Road Accidents by Number of Fatalities\", x = \"Number of Fatalities\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of fatalities is 0. However, while few, there are road accidents that occur with higher number of fatalities - the highest being 13 (Samut Prakan), followed by 6 (Pathum Thani), 3 (Bangkok, Nonthaburi) and 2 (Nakhon Pathom and Samut Sakhon).\n\n\n\n\n\nCode\nsummary_stats &lt;- roadacc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(\n    median_injuries = median(number_of_injuries, na.rm = TRUE),\n    mean_injuries = mean(number_of_injuries, na.rm = TRUE),\n    min_injuries = min(number_of_injuries,na.rm = TRUE),\n    q25 = quantile(number_of_injuries, 0.25, na.rm = TRUE),\n    q75 = quantile(number_of_injuries, 0.75, na.rm = TRUE),\n    max_injuries = max(number_of_injuries,na.rm = TRUE),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(label = paste0(\"Min: \", round(min_injuries,1),\n                        \"\\nq25: \", round(q25,1),\n                        \"\\nMedian: \", round(median_injuries, 1), \n                        \"\\nMean: \", round(mean_injuries, 1),\n                        \"\\nq75: \", round(q75,1),\n                        \"\\nMax injuries: \", round(max_injuries,1)\n                        ))\n\nggplot(roadacc,\n       aes(x=province_en,\n           y=number_of_injuries,\n           fill = province_en))+\n  geom_boxplot(width = .20,\n               outlier.shape = NA)+\n  geom_text(data = summary_stats, \n            aes(x = province_en, y = q75, label = label), \n            vjust = -0.5, \n            size = 3)+\n  ggtitle(\"Distribution of Road Accidents by Number of Injuries\") +\n  labs(title = \"Distribution of Road Accidents by Number of Injuries\", x = \"Number of Injuries\", y = \"Count\")+\n  theme(legend.position = \"none\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nAcross the provinces, the median number of injuries is 0. However, while few, there are road accidents that occur with higher number of injuries - the highest being 51 (Pathum Thani), followed by 31 (Bangkok), 30 (Nakhon Pathom), 28 (Samut Prakan), 14 (Samut Sakhon) and 11 (Nonthaburi).\nTo minimise the slow loading of the page, the Take-home Exercise 1 has been divided into 2 parts - please refer to Part 1B which covers spatial point pattern analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "Code\npacman::p_load(sf,spatstat,raster,maptools,tmap,tidyverse,spNetwork,DT,forcats,ggthemes,plotly)\n\n\n\n\nCode\n# loading datasets for analysis\n#refer to Part 1A for earlier steps on data wrangling\nroadacc &lt;- read_rds(\"data/rds/roadacc.rds\")\nroadsbkk &lt;- read_rds(\"data/rds/roadsbkk.rds\")\nprovincedata32647 &lt;- read_rds(\"data/rds/provincedata32647.rds\")\nroadacc_month_bkk &lt;- read_rds(\"data/rds/roadacc_month_bkk.rds\")\nroadacc_month_sp &lt;- read_rds(\"data/rds/roadacc_month_sp.rds\")\nroadacc_month_n &lt;- read_rds(\"data/rds/roadacc_month_n.rds\")\nroadacc_month_pt &lt;- read_rds(\"data/rds/roadacc_month_pt.rds\")\nroadacc_month_np &lt;- read_rds(\"data/rds/roadacc_month_np.rds\")\nroadacc_month_ss &lt;- read_rds(\"data/rds/roadacc_month_ss.rds\")\n\n\n\n\n\nWe will conduct a Spatial Point Pattern Analysis (SPPA) to evaluate the distribution of road accidents within the Bangkok Metropolitan Region (BMR).\nThe specific questions we would like to answer are as follows:\n\nare the road accidents in BMR randomly distributed throughout the region?\nif no, then where are the locations with higher concentration of road accidents?\n\nSpecifically, we will be carrying out the following SPPA methods:\n\nFirst-order SPPA\nSpatial analysis of road traffic accidents using Network SPPA methods.\nSpatio-temporal analysis of road accidents using Temporal Network SPPA methods.\n\n\n\n\n\n\nBefore we carry out spatial point pattern analysis, we need to convert the data from sf format to ppp format:\n\nroadacc_ppp &lt;- as.ppp(roadacc)\nroadacc_ppp\n\nMarked planar point pattern: 12985 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\nThe code chunk below plots roadacc_ppp for visualisation:\n\nplot(roadacc_ppp)\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the roadacc_ppp object using the code chunk below:\n\nsummary(roadacc_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.217956e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\n\nIn SPPA, a significant issue is the presence of duplicates as the statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple i.e. that the points cannot be coincident. We check for duplication in a ppp object via the code chunk below:\n\nany(duplicated(roadacc_ppp))\n\n[1] FALSE\n\n\nThe data does not have any duplicated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region. The code chunk below is used to covert provincedata32647 SpatialPolygon object into owin object of spatstat:\n\nprovinceowin &lt;- as.owin(provincedata32647)\n\nThe ouput object can be displayed by using plot() function\n\nplot(provinceowin)\n\n\n\n\n\n\n\n\n\nsummary(provinceowin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nWe extract road accident events that are located within the BMR by using the code chunk below:\n\nroadacc_owin_ppp = roadacc_ppp[provinceowin]\n\n\nplot(roadacc_owin_ppp)\n\n\n\n\n\n\n\n\n\nsummary(roadacc_owin_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.693182e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\n\nThe first-order SPPA will study how the intensity of road accidents vary across the BMR i.e. identify whether road accidents are more concentrated in areas due to underlying properties of the spatial environment.\nFor first-order SPPA, we will:\n\nderive the kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperform Confirmatory SPPA using Nearest Neighbour statistics to determine if the road accidents are randomly distributed or influenced by underlying properties of the spatial environment.\n\n\n\nWe will proceed to compute the KDE of road accidents in the BMR. However, before we do so, we convert the unit of measurement to kilometer as the default unit of measurement of EPSG: 32647 is in metres, which would make the values hard to comprehend:\n\nroadacc_owin_ppp.km &lt;- rescale.ppp(roadacc_owin_ppp,1000,\"km\")\n\n\n\n\nWe will derive adaptive KDE using density.adaptive() of spatstat. Adaptive schemes adjust itself according to the density of data - shorter bandwidths are used where data are dense and longer where sparse. This helps to mitigate against highly skewed distribution of spatial point patterns.\n\nkde_roadacc_adaptive &lt;- adaptive.density(roadacc_owin_ppp.km, method = \"kernel\")\n\n\nplot(kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output for mapping purposes:\n\ngridded_kde_roadacc_adaptive &lt;- as.SpatialGridDataFrame.im(kde_roadacc_adaptive)\n\nspplot(gridded_kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package:\n\nkde_roadacc_adaptive_raster &lt;- raster(kde_roadacc_adaptive)\n\nWe view the properties of kde_roadacc_adaptive_raster RasterLayer:\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nNote that the CRS property is NA.\n\n\n\nWe hence assign CRS information to the kde_roadacc_adaptive_raster RasterLayer:\n\nprojection(kde_roadacc_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nThe CRS property is now completed.\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_roadacc_adaptive_raster)+   \n  tm_raster(\"layer\",palette = \"viridis\")+   \n  tm_layout(legend.outside = TRUE,             \n            legend.outside.position = \"right\",             \n            legend.position = c(\"right\",\"bottom\"),             \n            main.title = \"Distribution of road accidents (adaptive bandwidth)\", \n            main.title.size = 0.8,             \n            frame = FALSE)\n\n\n\n\n\n\n\n\nFrom the plot above, we note that road accidents occur more intensely along the road lines in Bangkok and Samut Prakan. To better understand how the intensity of road accidents occur across the BMR, we will extract the six provinces as different study areas for analysis and comparison in the next section.\n\n\n\n\n\n\nThe code chunk will be used to extract the different provinces as different study areas:\n\nbkk &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nnp &lt;- provincedata32647 %&gt;% \n  filter(ADM1_EN == \"Nakhon Pathom\") \nn &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Nonthaburi\") \npt &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Pathum Thani\") \nsp &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Samut Prakan\") \nss &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Samut Sakhon\")\n\n\n\n\n\nbkk_owin = as.owin(bkk)\nnp_owin = as.owin(np) \nn_owin = as.owin(n) \npt_owin = as.owin(pt) \nsp_owin = as.owin(sp) \nss_owin = as.owin(ss)\n\n\n\n\nBy using the code chunk below, we are able to extract road accidents that is within the specific province to carry out our analysis later on.\n\nroadacc_bkk_ppp = roadacc_ppp[bkk_owin]\nroadacc_np_ppp = roadacc_ppp[np_owin]\nroadacc_n_ppp = roadacc_ppp[n_owin]\nroadacc_pt_ppp = roadacc_ppp[pt_owin]\nroadacc_sp_ppp = roadacc_ppp[sp_owin]\nroadacc_ss_ppp = roadacc_ppp[ss_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metres to kilometres as EPSG: 32647 is in metres which would produce density values that are too small to comprehend.\n\nroadacc_bkk_ppp.km = rescale.ppp(roadacc_bkk_ppp,1000,\"km\")\nroadacc_np_ppp.km = rescale.ppp(roadacc_np_ppp,1000,\"km\")\nroadacc_n_ppp.km = rescale.ppp(roadacc_n_ppp,1000,\"km\")\nroadacc_pt_ppp.km = rescale.ppp(roadacc_pt_ppp,1000,\"km\")\nroadacc_sp_ppp.km = rescale.ppp(roadacc_sp_ppp,1000,\"km\")\nroadacc_ss_ppp.km = rescale.ppp(roadacc_ss_ppp,1000,\"km\")\n\nWe then plot the 6 provinces and the locations of the road accidents:\n\npar(mfrow=c(2,3))\nplot(roadacc_bkk_ppp.km,main=\"Bangkok\")\nplot(roadacc_np_ppp.km,main=\"Nakhon Pathom\")\nplot(roadacc_n_ppp.km,main=\"Nonthaburi\") \nplot(roadacc_pt_ppp.km,main=\"Pathum Thani\")\nplot(roadacc_sp_ppp.km,main=\"Samut Prakan\")\nplot(roadacc_ss_ppp.km,main=\"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\n\n\nWe will also derive adaptive KDE using density.adaptive() of spatstat for all six provinces:\n\nkde_bkk_adaptive &lt;- adaptive.density(roadacc_bkk_ppp.km, method = \"kernel\")\nkde_np_adaptive &lt;- adaptive.density(roadacc_np_ppp.km, method = \"kernel\")\nkde_n_adaptive &lt;- adaptive.density(roadacc_n_ppp.km, method = \"kernel\")\nkde_pt_adaptive &lt;- adaptive.density(roadacc_pt_ppp.km, method = \"kernel\")\nkde_sp_adaptive &lt;- adaptive.density(roadacc_sp_ppp.km, method = \"kernel\")\nkde_ss_adaptive &lt;- adaptive.density(roadacc_ss_ppp.km, method = \"kernel\")\n\nWe will then convert the KDE output into a grid object for mapping purposes:\n\ngridded_kde_bkk_adaptive &lt;- as.SpatialGridDataFrame.im(kde_bkk_adaptive)\ngridded_kde_np_adaptive &lt;- as.SpatialGridDataFrame.im(kde_np_adaptive)\ngridded_kde_n_adaptive &lt;- as.SpatialGridDataFrame.im(kde_n_adaptive)\ngridded_kde_pt_adaptive &lt;- as.SpatialGridDataFrame.im(kde_pt_adaptive)\ngridded_kde_sp_adaptive &lt;- as.SpatialGridDataFrame.im(kde_sp_adaptive)\ngridded_kde_ss_adaptive &lt;- as.SpatialGridDataFrame.im(kde_ss_adaptive)\n\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nspplot(gridded_kde_bkk_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_np_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_n_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_pt_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_sp_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_ss_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package and assign the CRS of EPSG 32647:\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nkde_bkk_adaptive_raster &lt;- raster(kde_bkk_adaptive)\nprojection(kde_bkk_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_bkk_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.5157047, 0.4002078  (x, y)\nextent     : 643.5344, 709.5446, 1492.136, 1543.363  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -3.287751e-16, 366.6161  (min, max)\n\n\n\n\n\nkde_np_adaptive_raster &lt;- raster(kde_np_adaptive)\nprojection(kde_np_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_np_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4431169, 0.4584598  (x, y)\nextent     : 587.8935, 644.6125, 1509.208, 1567.891  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : 4.371169e-10, 18.36673  (min, max)\n\n\n\n\n\nkde_n_adaptive_raster &lt;- raster(kde_n_adaptive)\nprojection(kde_n_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_n_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.2577626, 0.3028132  (x, y)\nextent     : 636.3416, 669.3352, 1524.865, 1563.625  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : 0.0004333219, 47.02454  (min, max)\n\n\n\n\n\nkde_pt_adaptive_raster &lt;- raster(kde_pt_adaptive)\nprojection(kde_pt_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_pt_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.5218025, 0.3122371  (x, y)\nextent     : 643.7786, 710.5693, 1539.11, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.098021e-16, 223.7231  (min, max)\n\n\n\n\n\nkde_sp_adaptive_raster &lt;- raster(kde_sp_adaptive)\nprojection(kde_sp_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_sp_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4386052, 0.2064404  (x, y)\nextent     : 656.299, 712.4405, 1490.796, 1517.22  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -6.855306e-14, 734.734  (min, max)\n\n\n\n\n\nkde_ss_adaptive_raster &lt;- raster(kde_ss_adaptive)\nprojection(kde_ss_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_ss_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.332527, 0.2598575  (x, y)\nextent     : 611.1044, 653.6678, 1484.414, 1517.676  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.736085e-16, 285.6541  (min, max)\n\n\n\n\n\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\ntm_shape(kde_bkk_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Bangkok (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_np_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Nakhon Pathom (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_n_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Nonthaburi (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_pt_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Pathum Thani (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_sp_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Samut Prakan (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_ss_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Samut Sakhon (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above, we note the maximum KDE for each province (in descending order) and details for each province as follows:\n\nSamut Prakan - up to 600 to 800. Most of the road accidents optically seem to occur at 4 short segments.\nBangkok - up to 300 to 400. Most of the road accidents optically seem to occur at 4 short segments.\nSamut Sakhon: Max density up to 250 to 300. Most of the road accidents seem to occur along the same major road.\nPathum Thani - up to 200 to 250. Most of the road accidents seem to occur along the same major road.\nNonthaburi - up to 40 to 50. Most of the road accidents optically seem to occur at 8 segments.\nNakhon Pathom - up to 15 to 20. Most of the road accidents optically seem to occur at one major road and 3 mid-sized road segments.\n\nFurther observations are as follows:\n\nNotably, while Bangkok is a known tourist destination/major urban hub, it ranks second to Samut Prakan in terms of road accident density.\n\n\n\nRoad accidents seem more scattered in Nonthaburi and Nakhon Pathom which suggest that there could be more complex road systems in these areas where accidents could occur at various points.\n\n\n\n\n\nAfter running KDE which shows the density of road accidents over the BMR, we will perform the Clark-Evans test of aggregation to statistically validate the degree of spatial clustering or dispersion of the road accident points by comparing the observed mean nearest neighbor distance with the expected average distance between neighbours in a hypothetical random distribution.\nThe test hypotheses are:\nH0: The distribution of road accidents is randomly distributed.\nH1: The distribution of road accidents is not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\n\n\n\nclarkevans.test(roadacc_owin_ppp.km,\n                correction = \"none\",\n                clipregion = \"province_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_owin_ppp.km\nR = 0.19092, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nSince p-value is less than 0.05, there is sufficient evidence to reject the null hypothesis H0 that the distribution of road accidents is randomly distributed.\nThis is further supported by the R value of 0.19092. As this R value is less than 1, it indicates that the pattern exhibits clustering and that the road accidents tend to occur close to one another and not in a dispersed/regular manner.\n\n\n\n\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nclarkevans.test(roadacc_bkk_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_bkk_ppp.km\nR = 0.12057, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_np_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_n_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_pt_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_sp_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_ss_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nBased on the results above, for which all R values are less than 1 and all p-values are less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents in all provinces is not randomly distributed and instead exhibit clustering.\n\n\n\n\n\ntmap_mode('view')\ntm_shape(roadacc)+\n  tm_dots()+\n  tm_shape(roadsbkk)+\n  tm_lines()\ntmap_mode('plot')\n\n\n\n\n\n\nBefore computing NKDE, the roadsbkk object needs to be cut into lixels with a specified minimal distance. We do this using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(roadsbkk,                          5000,                          mindist = NULL)\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line.\n\n\n\n\nPrior to performing NKDE calculations:\n\nfuture::plan(future::multisession(workers=2))\n\nWe will compute NKDE using the code chunk below:\n\ndensities &lt;- nkde(roadsbkk,\n                  events = roadacc,\n                  w = rep(1,nrow(roadacc)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"discontinuous\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(10,10),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\nBefore visualising NKDE values, we use the code chunk below to insert the computed density values into samples and lixels objects as density field. We also multiply the densities by 1000 to rescale the density values from metres (as the EPSG 32647 projection system is in metres which make the computed density values very small and hard to comprehend) to number of events per kilometer:\n\nsamples$density &lt;- densities*1000 \nlixels$density &lt;- densities*1000"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#spatial-point-pattern-analysis-sppa",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#spatial-point-pattern-analysis-sppa",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "We will conduct a Spatial Point Pattern Analysis (SPPA) to evaluate the distribution of road accidents within the Bangkok Metropolitan Region (BMR).\nThe specific questions we would like to answer are as follows:\n\nare the road accidents in BMR randomly distributed throughout the region?\nif no, then where are the locations with higher concentration of road accidents?\n\nSpecifically, we will be carrying out the following SPPA methods:\n\nFirst-order SPPA\nSpatial analysis of road traffic accidents using Network SPPA methods.\nSpatio-temporal analysis of road accidents using Temporal Network SPPA methods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#data-wrangling-for-sppa",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#data-wrangling-for-sppa",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "Before we carry out spatial point pattern analysis, we need to convert the data from sf format to ppp format:\n\nroadacc_ppp &lt;- as.ppp(roadacc)\nroadacc_ppp\n\nMarked planar point pattern: 12985 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\n\nThe code chunk below plots roadacc_ppp for visualisation:\n\nplot(roadacc_ppp)\n\n\n\n\n\n\n\n\nWe take a quick look at the summary statistics of the roadacc_ppp object using the code chunk below:\n\nsummary(roadacc_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.217956e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\n\n\n\nIn SPPA, a significant issue is the presence of duplicates as the statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple i.e. that the points cannot be coincident. We check for duplication in a ppp object via the code chunk below:\n\nany(duplicated(roadacc_ppp))\n\n[1] FALSE\n\n\nThe data does not have any duplicated points.\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region. The code chunk below is used to covert provincedata32647 SpatialPolygon object into owin object of spatstat:\n\nprovinceowin &lt;- as.owin(provincedata32647)\n\nThe ouput object can be displayed by using plot() function\n\nplot(provinceowin)\n\n\n\n\n\n\n\n\n\nsummary(provinceowin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\n\n\n\nWe extract road accident events that are located within the BMR by using the code chunk below:\n\nroadacc_owin_ppp = roadacc_ppp[provinceowin]\n\n\nplot(roadacc_owin_ppp)\n\n\n\n\n\n\n\n\n\nsummary(roadacc_owin_ppp)\n\nMarked planar point pattern:  12985 points\nAverage intensity 1.693182e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3833867 4314374 6092695 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#first-order-sppa",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#first-order-sppa",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "The first-order SPPA will study how the intensity of road accidents vary across the BMR i.e. identify whether road accidents are more concentrated in areas due to underlying properties of the spatial environment.\nFor first-order SPPA, we will:\n\nderive the kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperform Confirmatory SPPA using Nearest Neighbour statistics to determine if the road accidents are randomly distributed or influenced by underlying properties of the spatial environment.\n\n\n\nWe will proceed to compute the KDE of road accidents in the BMR. However, before we do so, we convert the unit of measurement to kilometer as the default unit of measurement of EPSG: 32647 is in metres, which would make the values hard to comprehend:\n\nroadacc_owin_ppp.km &lt;- rescale.ppp(roadacc_owin_ppp,1000,\"km\")\n\n\n\n\nWe will derive adaptive KDE using density.adaptive() of spatstat. Adaptive schemes adjust itself according to the density of data - shorter bandwidths are used where data are dense and longer where sparse. This helps to mitigate against highly skewed distribution of spatial point patterns.\n\nkde_roadacc_adaptive &lt;- adaptive.density(roadacc_owin_ppp.km, method = \"kernel\")\n\n\nplot(kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nWe convert the KDE output for mapping purposes:\n\ngridded_kde_roadacc_adaptive &lt;- as.SpatialGridDataFrame.im(kde_roadacc_adaptive)\n\nspplot(gridded_kde_roadacc_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package:\n\nkde_roadacc_adaptive_raster &lt;- raster(kde_roadacc_adaptive)\n\nWe view the properties of kde_roadacc_adaptive_raster RasterLayer:\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nNote that the CRS property is NA.\n\n\n\nWe hence assign CRS information to the kde_roadacc_adaptive_raster RasterLayer:\n\nprojection(kde_roadacc_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nkde_roadacc_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.973023, 0.7395512  (x, y)\nextent     : 587.8935, 712.4405, 1484.414, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -4.248362e-15, 233.4632  (min, max)\n\n\nThe CRS property is now completed.\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\ntm_shape(kde_roadacc_adaptive_raster)+   \n  tm_raster(\"layer\",palette = \"viridis\")+   \n  tm_layout(legend.outside = TRUE,             \n            legend.outside.position = \"right\",             \n            legend.position = c(\"right\",\"bottom\"),             \n            main.title = \"Distribution of road accidents (adaptive bandwidth)\", \n            main.title.size = 0.8,             \n            frame = FALSE)\n\n\n\n\n\n\n\n\nFrom the plot above, we note that road accidents occur more intensely along the road lines in Bangkok and Samut Prakan. To better understand how the intensity of road accidents occur across the BMR, we will extract the six provinces as different study areas for analysis and comparison in the next section.\n\n\n\n\n\n\nThe code chunk will be used to extract the different provinces as different study areas:\n\nbkk &lt;- provincedata32647 %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nnp &lt;- provincedata32647 %&gt;% \n  filter(ADM1_EN == \"Nakhon Pathom\") \nn &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Nonthaburi\") \npt &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Pathum Thani\") \nsp &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Samut Prakan\") \nss &lt;- provincedata32647 %&gt;%   \n  filter(ADM1_EN == \"Samut Sakhon\")\n\n\n\n\n\nbkk_owin = as.owin(bkk)\nnp_owin = as.owin(np) \nn_owin = as.owin(n) \npt_owin = as.owin(pt) \nsp_owin = as.owin(sp) \nss_owin = as.owin(ss)\n\n\n\n\nBy using the code chunk below, we are able to extract road accidents that is within the specific province to carry out our analysis later on.\n\nroadacc_bkk_ppp = roadacc_ppp[bkk_owin]\nroadacc_np_ppp = roadacc_ppp[np_owin]\nroadacc_n_ppp = roadacc_ppp[n_owin]\nroadacc_pt_ppp = roadacc_ppp[pt_owin]\nroadacc_sp_ppp = roadacc_ppp[sp_owin]\nroadacc_ss_ppp = roadacc_ppp[ss_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metres to kilometres as EPSG: 32647 is in metres which would produce density values that are too small to comprehend.\n\nroadacc_bkk_ppp.km = rescale.ppp(roadacc_bkk_ppp,1000,\"km\")\nroadacc_np_ppp.km = rescale.ppp(roadacc_np_ppp,1000,\"km\")\nroadacc_n_ppp.km = rescale.ppp(roadacc_n_ppp,1000,\"km\")\nroadacc_pt_ppp.km = rescale.ppp(roadacc_pt_ppp,1000,\"km\")\nroadacc_sp_ppp.km = rescale.ppp(roadacc_sp_ppp,1000,\"km\")\nroadacc_ss_ppp.km = rescale.ppp(roadacc_ss_ppp,1000,\"km\")\n\nWe then plot the 6 provinces and the locations of the road accidents:\n\npar(mfrow=c(2,3))\nplot(roadacc_bkk_ppp.km,main=\"Bangkok\")\nplot(roadacc_np_ppp.km,main=\"Nakhon Pathom\")\nplot(roadacc_n_ppp.km,main=\"Nonthaburi\") \nplot(roadacc_pt_ppp.km,main=\"Pathum Thani\")\nplot(roadacc_sp_ppp.km,main=\"Samut Prakan\")\nplot(roadacc_ss_ppp.km,main=\"Samut Sakhon\")\n\n\n\n\n\n\n\n\n\n\n\nWe will also derive adaptive KDE using density.adaptive() of spatstat for all six provinces:\n\nkde_bkk_adaptive &lt;- adaptive.density(roadacc_bkk_ppp.km, method = \"kernel\")\nkde_np_adaptive &lt;- adaptive.density(roadacc_np_ppp.km, method = \"kernel\")\nkde_n_adaptive &lt;- adaptive.density(roadacc_n_ppp.km, method = \"kernel\")\nkde_pt_adaptive &lt;- adaptive.density(roadacc_pt_ppp.km, method = \"kernel\")\nkde_sp_adaptive &lt;- adaptive.density(roadacc_sp_ppp.km, method = \"kernel\")\nkde_ss_adaptive &lt;- adaptive.density(roadacc_ss_ppp.km, method = \"kernel\")\n\nWe will then convert the KDE output into a grid object for mapping purposes:\n\ngridded_kde_bkk_adaptive &lt;- as.SpatialGridDataFrame.im(kde_bkk_adaptive)\ngridded_kde_np_adaptive &lt;- as.SpatialGridDataFrame.im(kde_np_adaptive)\ngridded_kde_n_adaptive &lt;- as.SpatialGridDataFrame.im(kde_n_adaptive)\ngridded_kde_pt_adaptive &lt;- as.SpatialGridDataFrame.im(kde_pt_adaptive)\ngridded_kde_sp_adaptive &lt;- as.SpatialGridDataFrame.im(kde_sp_adaptive)\ngridded_kde_ss_adaptive &lt;- as.SpatialGridDataFrame.im(kde_ss_adaptive)\n\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nspplot(gridded_kde_bkk_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_np_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_n_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_pt_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_sp_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nspplot(gridded_kde_ss_adaptive)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will convert the gridded KDE object into a RasterLayer object using raster() of raster package and assign the CRS of EPSG 32647:\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nkde_bkk_adaptive_raster &lt;- raster(kde_bkk_adaptive)\nprojection(kde_bkk_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_bkk_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.5157047, 0.4002078  (x, y)\nextent     : 643.5344, 709.5446, 1492.136, 1543.363  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -3.287751e-16, 366.6161  (min, max)\n\n\n\n\n\nkde_np_adaptive_raster &lt;- raster(kde_np_adaptive)\nprojection(kde_np_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_np_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4431169, 0.4584598  (x, y)\nextent     : 587.8935, 644.6125, 1509.208, 1567.891  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : 4.371169e-10, 18.36673  (min, max)\n\n\n\n\n\nkde_n_adaptive_raster &lt;- raster(kde_n_adaptive)\nprojection(kde_n_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_n_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.2577626, 0.3028132  (x, y)\nextent     : 636.3416, 669.3352, 1524.865, 1563.625  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : 0.0004333219, 47.02454  (min, max)\n\n\n\n\n\nkde_pt_adaptive_raster &lt;- raster(kde_pt_adaptive)\nprojection(kde_pt_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_pt_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.5218025, 0.3122371  (x, y)\nextent     : 643.7786, 710.5693, 1539.11, 1579.076  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.098021e-16, 223.7231  (min, max)\n\n\n\n\n\nkde_sp_adaptive_raster &lt;- raster(kde_sp_adaptive)\nprojection(kde_sp_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")  \nkde_sp_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4386052, 0.2064404  (x, y)\nextent     : 656.299, 712.4405, 1490.796, 1517.22  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -6.855306e-14, 734.734  (min, max)\n\n\n\n\n\nkde_ss_adaptive_raster &lt;- raster(kde_ss_adaptive)\nprojection(kde_ss_adaptive_raster) &lt;- CRS(\"+init=EPSG:32647\")\nkde_ss_adaptive_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.332527, 0.2598575  (x, y)\nextent     : 611.1044, 653.6678, 1484.414, 1517.676  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=47 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.736085e-16, 285.6541  (min, max)\n\n\n\n\n\n\n\n\nWe will display the raster in cartographic quality map using tmap package:\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\ntm_shape(kde_bkk_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Bangkok (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_np_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Nakhon Pathom (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_n_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Nonthaburi (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_pt_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Pathum Thani (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_sp_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Samut Prakan (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(kde_ss_adaptive_raster)+\n  tm_raster(\"layer\",palette = \"viridis\")+\n  tm_layout(legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            legend.position = c(\"right\",\"bottom\"),\n            main.title = \"Distribution of road accidents in Samut Sakhon (adaptive bandwidth)\",\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above, we note the maximum KDE for each province (in descending order) and details for each province as follows:\n\nSamut Prakan - up to 600 to 800. Most of the road accidents optically seem to occur at 4 short segments.\nBangkok - up to 300 to 400. Most of the road accidents optically seem to occur at 4 short segments.\nSamut Sakhon: Max density up to 250 to 300. Most of the road accidents seem to occur along the same major road.\nPathum Thani - up to 200 to 250. Most of the road accidents seem to occur along the same major road.\nNonthaburi - up to 40 to 50. Most of the road accidents optically seem to occur at 8 segments.\nNakhon Pathom - up to 15 to 20. Most of the road accidents optically seem to occur at one major road and 3 mid-sized road segments.\n\nFurther observations are as follows:\n\nNotably, while Bangkok is a known tourist destination/major urban hub, it ranks second to Samut Prakan in terms of road accident density.\n\n\n\nRoad accidents seem more scattered in Nonthaburi and Nakhon Pathom which suggest that there could be more complex road systems in these areas where accidents could occur at various points."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#nearest-neighbour-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#nearest-neighbour-analysis",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "After running KDE which shows the density of road accidents over the BMR, we will perform the Clark-Evans test of aggregation to statistically validate the degree of spatial clustering or dispersion of the road accident points by comparing the observed mean nearest neighbor distance with the expected average distance between neighbours in a hypothetical random distribution.\nThe test hypotheses are:\nH0: The distribution of road accidents is randomly distributed.\nH1: The distribution of road accidents is not randomly distributed.\nThe 95% confidence interval will be used.\n\n\n\n\n\n\nclarkevans.test(roadacc_owin_ppp.km,\n                correction = \"none\",\n                clipregion = \"province_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_owin_ppp.km\nR = 0.19092, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nSince p-value is less than 0.05, there is sufficient evidence to reject the null hypothesis H0 that the distribution of road accidents is randomly distributed.\nThis is further supported by the R value of 0.19092. As this R value is less than 1, it indicates that the pattern exhibits clustering and that the road accidents tend to occur close to one another and not in a dispersed/regular manner.\n\n\n\n\n\nBangkokNakhon PathomNonthaburiPathum ThaniSamut PrakanSamut Sakhon\n\n\n\nclarkevans.test(roadacc_bkk_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  roadacc_bkk_ppp.km\nR = 0.12057, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(roadacc_np_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_n_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_pt_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_sp_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nclarkevans.test(roadacc_ss_ppp.km,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n\nBased on the results above, for which all R values are less than 1 and all p-values are less than 0.05, we reject the null hypothesis at 95% confidence interval. There is sufficient evidence to indicate that the distribution of road accidents in all provinces is not randomly distributed and instead exhibit clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#network-constrained-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#network-constrained-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "tmap_mode('view')\ntm_shape(roadacc)+\n  tm_dots()+\n  tm_shape(roadsbkk)+\n  tm_lines()\ntmap_mode('plot')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#network-kde-nkde-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#network-kde-nkde-analysis",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "Before computing NKDE, the roadsbkk object needs to be cut into lixels with a specified minimal distance. We do this using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(roadsbkk,                          5000,                          mindist = NULL)\n\n\n\n\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below:\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#performing-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01B.html#performing-nkde",
    "title": "Take-home Exercise 1B",
    "section": "",
    "text": "Prior to performing NKDE calculations:\n\nfuture::plan(future::multisession(workers=2))\n\nWe will compute NKDE using the code chunk below:\n\ndensities &lt;- nkde(roadsbkk,\n                  events = roadacc,\n                  w = rep(1,nrow(roadacc)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"discontinuous\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(10,10),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\nBefore visualising NKDE values, we use the code chunk below to insert the computed density values into samples and lixels objects as density field. We also multiply the densities by 1000 to rescale the density values from metres (as the EPSG 32647 projection system is in metres which make the computed density values very small and hard to comprehend) to number of events per kilometer:\n\nsamples$density &lt;- densities*1000 \nlixels$density &lt;- densities*1000"
  }
]