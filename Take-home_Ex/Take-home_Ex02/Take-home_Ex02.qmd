---
title: "Take-home Exercise 2"
author: "Kock Si Min"
date: October 2, 2024
date-modified: "last-modified"
toc: true
execute:
  eval: true
  echo: true
  freeze: true
  warning: false
  message: false
---

# Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics

## 1. Setting the Scene

Tourism is one of Thailand’s largest industries, accounting for \~20% of the gross domestic product (GDP). In 2019, Thailand earned US\$90 billion from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to US\$24 billion in 2020.

The figure below shows the total revenue receipt from tourism sector between Jan 2019 to Feb 2023, and indicates that the revenue from tourism industry has been gradually recovering since Sep 2021.

![](images/clipboard-378385426.png){width="460"}

However, it is important to note that the tourism economy of Thailand is not evenly distributed. The figure below reveals that the tourism economy of Thailand in 2019 was mainly focused on five provinces, namely Bangkok, Phuket, Chon Buri, Krabi and Chiang Mai.

## 2. Objectives

The objectives of this take-home exercise will be to discover:

-   if the key indicators of tourism economy of Thailand are independent from space and space and time.

-   If the tourism economy is indeed spatial and spatio-temporal dependent, and if so, where the clusters, outliers and emerging hot spot/cold spot areas are.

## 3. The Task

The specific tasks of this take-home exercise are as follows:

-   Using appropriate function of **sf** and **tidyverse**, prepare the following geospatial data layer:

    -   a study area layer in sf polygon features. It must be at [province level](https://en.wikipedia.org/wiki/Provinces_of_Thailand) (including Bangkok) of Thailand.

    -   a tourism economy indicators layer within the study area in sf polygon features.

    -   a derived tourism economy indicator layer in [**spacetime s3 class of sfdep**](https://sfdep.josiahparry.com/articles/spacetime-s3). Keep the time series at **month and year levels**.

-   Using the extracted data, perform global spatial autocorrelation analysis using [sfdep methods](https://is415-gaa-tskam.netlify.app/in-class_ex/in-class_ex05/in-class_ex05-glsa).

-   Using the extracted data, perform local spatial autocorrelation analysis using [sfdep methods](https://r4gdsa.netlify.app/chap10.html).

-   Using the extracted data, perform emerging hotspot analysis using [sfdep methods](https://is415-gaa-tskam.netlify.app/in-class_ex/in-class_ex05/in-class_ex05-ehsa).

-   Describe the spatial patterns revealed by the analysis above.

## 4. Installing and Loading the necessary R packages

We use the following code chunk to install and load the necessary R packages for our analysis:

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, knitr, plotly, Kendall, VIM, naniar, DT)
```

## 5. The Data

Two data sets shall be used:

-   [Thailand Domestic Tourism Statistics](https://www.kaggle.com/datasets/thaweewatboy/thailand-domestic-tourism-statistics) at Kaggle - **version 2** of the data set will be used.

-   [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) at HDX - the province boundary data set will be used.

### 5.1 Thailand Domestic Tourism Statistics

### 5.1.1 Importing the csv file

The code chunk below uses [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) of readr package to load the Thailand Domestic Tourism Statistics:

```{r}
tourism <- read_csv("data/rawdata/thailand_domestic_tourism_2019_2023_ver2.csv")
```

The *thai_tourism* data has 30,800 rows and 7 variables, namely *date, province_thai, province_eng, region_thai, region_eng, variable* and *value.*

### 5.1.2 Cleaning the data

#### 5.1.2.1 Dropping unwanted variables

We will drop the columns *province_thai* and *region_thai* as these variables are in the Thai language which we do not understand and hence will not be helpful for our analysis:

```{r}
tourism <- tourism[,!names(tourism) %in% c("province_thai","region_thai")]
```

#### 5.1.2.2 Determine the presence of missing data

We determine the presence of missing values using the *vis_miss()* function of the [naniar](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html) package:

```{r}
vis_miss(tourism)
```

From the output above, we note that there are no missing data.

#### 5.1.2.3 Creating new year, month and day variables

From the code chunk below, we note that the *date* variable in *tourism* data frame is in the Date vector format:

```{r}
class(tourism$date)
```

We form new variables *year* and *month* using the lubridate package:

```{r}
tourism <- tourism %>%
  mutate(year_month = ymd(date),
         year = year(date),
         month = month(date,
                       label = TRUE,
                       abbr = TRUE),
.before = 2)
```

#### 5.1.2.4 Determine the distribution of provinces and corresponding regions

We first study the distribution of regions in the data:

```{r}
ggplot(tourism, 
       aes(x = fct_reorder(region_eng, region_eng, .fun = length))) + 
  geom_bar() +
  labs(title = "Distribution of domestic tourism statistics across regions", x = "Regions", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

From the output above, we note that there 5 different types of regions represented, notably the western region is not represented in the data.

We take a more detailed look by determining the unique provinces represented in the data and their corresponding regions. This step aims to check for two things:

-   whether there are any duplicate data entries i.e. entries that are meant to represent the same province but have spelling errors.

-   whether the regions for the provinces are accurately indicated

```{r}
tourism_unique <- tourism %>%
  select(province_eng,region_eng) %>%
  distinct() %>%
  arrange(region_eng,province_eng)

tourism_unique
```

From the output above, we note that all 77 Thailand provinces are represented in the data, and that there are no spelling errors/misrepresented provinces.

However, with reference to the [source on provinces in Thailand](https://en.wikipedia.org/wiki/Provinces_of_Thailand), we note a few mistakes in the regions indicated for the provinces.

-   Kanchanaburi, Phetchaburi, Prachuap Khiri Khan and Ratchaburi are stated as being in the central region but actually reside in the west region

-   Nakhon Nayok is stated as being in the east region but actually resides in the central region

-   The *east_northeast* region can actually be renamed as *northeast* region for clarity and consistency with how detailed the other provinces are labelled

-   Kamphaeng Phet, Nakhon Sawan, Phetchabun, Phichit, Phitsanulok, Sukhothai and Uthai Thani are stated as being in the north region but actually reside in central region

-   Tak is stated as being in the north region but actually resides in the west region

-   Sisaket is stated as being in the south region but actually resides in the northeast region

#### 5.1.2.4.1 Correcting the erroneous regions of provinces

We use the code chunk below to rename the "east_northeast" region to just "northeast" and correct the erroneous regions of the provinces mentioned above:

```{r}
tourism <- tourism %>%
  mutate(region_eng = case_when(
    region_eng == "east_northeast" ~ "northeast",
    province_eng %in% c("Kanchanaburi", "Phetchaburi", "Prachuap Khiri Khan", "Ratchaburi", "Tak") ~ "west",
    province_eng %in% c("Nakhon Nayok","Kamphaeng Phet","Nakhon Sawan","Phetchabun","Phichit","Phitsanulok","Sukhothai","Uthai Thani") ~ "central",
    province_eng == "Sisaket" ~ "northeast",
    TRUE ~ region_eng
  ))
```

We check by generating the data table of provinces and their corresponding regions:

```{r}
tourism_unique <- tourism %>%
  select(province_eng,region_eng) %>%
  distinct() %>%
  arrange(region_eng,province_eng)

datatable(tourism_unique)
```

Re-plotting the distribution of domestic tourism statistics across the regions:

```{r}
ggplot(tourism, 
       aes(x = fct_reorder(region_eng, region_eng, .fun = length))) + 
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of domestic tourism statistics across regions", x = "Regions", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We note that most of the domestic tourism statistics come from the central region, followed by northeast, south, north, east and finally the west region.

#### 5.1.2.5 Determine the distribution of variables and corresponding values

```{r}
ggplot(tourism, 
       aes(x = fct_reorder(variable, variable, .fun = length))) + 
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of Variable", x = "Variable", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We note that there are 8 different types of variables:

| S/N   | Variable           | Definition                                                                  |
|----------------|------------------------------|---------------------------------------|
| **1** | no_tourist_all     | The total number of domestic tourists who visited the province              |
| **2** | no_tourist_thai    | The number of Thai tourists who visited the province                        |
| **3** | no_tourist_foreign | The number of foreign tourists who visited the province                     |
| **4** | no_tourist_stay    | The total number of tourists who stay overnight                             |
| **5** | ratio_tourist_stay | Ratio of tourists that stay overnight                                       |
| **6** | revenue_all        | The revenue generated by the tourism industry in the province, in Thai Baht |
| **7** | revenue_foreign    | The revenue generated by foreign tourists in the province, in Thai Baht     |
| **8** | revenue_thai       | The revenue generated by Thai tourists in the province, in Thai Baht        |

#### 5.1.2.5.1 pivot_wider() to expand variables as individual columns

We utilise the *pivot_wider()* function to separate the different variable types as individual columns:

```{r}
tourism_wider <- tourism %>%
  pivot_wider(names_from = variable, values_from = value)
```

#### 5.1.2.5.2 Checking the revenue figures

Based on the definition of the different variable types, we note that "revenue_all" should equal to the sum of "revenue_foreign" and "revenue_thai". We check through the data using the code chunk below:

```{r}
revenue_numbers <- tourism_wider %>%
  group_by(province_eng,year_month) %>%
  summarise(
    sum_revenue = sum(revenue_foreign, revenue_thai, na.rm = TRUE),
  revenue_all = sum(revenue_all,na.rm = TRUE),
            .groups = "drop") %>%
  mutate(is_rev_equal = sum_revenue == revenue_all)

revenue_numbers
```

We note from the output below that the data entries for revenue match up:

```{r}
revenue_numbers %>%
  filter(!is_rev_equal)
```

#### 5.1.2.5.3 Checking the tourist numbers

Similarly, based on the definition of the different variable types, we note that "no_tourist_all" should equal to the sum of "no_tourist_foreign" and "no_tourist_thai". We check through the data using the code chunk below:

```{r}
tourism_numbers <- tourism_wider %>%
  group_by(province_eng,year_month) %>%
  summarise(
    sum_tourists = sum(no_tourist_foreign, no_tourist_thai, na.rm = TRUE),
  tourists_all = sum(no_tourist_all,na.rm = TRUE),
            .groups = "drop") %>%
  mutate(is_touristno_equal = sum_tourists == tourists_all)

tourism_numbers
```

We note from the output below that the data entries for tourist numbers match up:

```{r}
tourism_numbers %>%
  filter(!is_touristno_equal)
```

#### 5.1.2.5.4 Checking the distribution of values of each variable

-   Revenue

```{r}
selected_revenue <- tourism %>%
  filter(variable %in% c("revenue_all", "revenue_thai", "revenue_foreign"))

# Calculate summary statistics
summary_stats <- selected_revenue %>%
  group_by(variable) %>%
  summarise(
    Min = min(value),
    Q1 = quantile(value, 0.25),
    Median = median(value),
    Q3 = quantile(value, 0.75),
    Max = max(value)
  )

ggplot(selected_revenue, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() +
  geom_text(data=summary_stats, aes(x = variable, 
                               y = Max + 1000, 
                               label = paste("Min:", Min,
                                             "\nQ1:", Q1, 
                                             "\nMedian:", Median, 
                                             "\nQ3:", Q3, 
                                             "\nMax:", Max)),
            position = position_dodge(width = 0.75), 
            vjust = 0, hjust = 1, size = 2, color = "black") +
  labs(title = "Boxplots of Different Revenue Types", x = "Revenue Type", y = "Revenue")+
  scale_y_continuous(limits = c(0,12e+10))
```

From the boxplots above, we note that the minimum value for "revenue_foreign" is -\$4250, while this could have occurred due to errors in data entry, we note that it could also be due to negative tourism impacts i.e. refunds and cancellations as the negative foreign revenues occurred in Jul and Aug 2021 in Nakhon Pathom, coinciding with the time period when [Thailand announced a new 14-day COVID-19 restriction in Bangkok and surrounding provinces including Nakhon Pathom](https://www.tatnews.org/2021/07/thailand-announces-new-14-day-covid-19-restrictions-in-bangkok-and-5-surrounding-provinces/). As such, these entries were not removed from the data.

-   Tourist numbers

```{r}
selected_tourists <- tourism %>%
  filter(variable %in% c("no_tourist_all","no_tourist_thai", "no_tourist_foreign"))

# Calculate summary statistics
summary_stats <- selected_tourists %>%
  group_by(variable) %>%
  summarise(
    Min = min(value),
    Q1 = quantile(value, 0.25),
    Median = median(value),
    Q3 = quantile(value, 0.75),
    Max = max(value)
  )

ggplot(selected_tourists, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot() +
  geom_text(data=summary_stats, aes(x = variable, 
                               y = Max + 100000, 
                               label = paste("Min:", Min,
                                             "\nQ1:", Q1, 
                                             "\nMedian:", Median, 
                                             "\nQ3:", Q3, 
                                             "\nMax:", Max)),
            position = position_dodge(width = 0.75), 
            vjust = 0, hjust = 1, size = 2, color = "black") +
  labs(title = "Boxplots of Different Tourist Numbers", x = "Tourist Type", y = "Number of Tourists")+
  scale_y_continuous(limits = c(0,8e+6))
```

-   Occupancy

```{r}
# Calculate summary statistics
summary_stats <- tourism_wider %>%
  summarise(
    Min = min(no_tourist_stay),
    Q1 = quantile(no_tourist_stay, 0.25),
    Median = median(no_tourist_stay),
    Q3 = quantile(no_tourist_stay, 0.75),
    Max = max(no_tourist_stay)
  )

ggplot(tourism_wider, aes(x = "", y = no_tourist_stay)) +
  geom_boxplot(fill = "lightblue") +
  geom_text(data = summary_stats, aes(x = "", y = Max + 100000,
                                      label = paste("Min:", Min,
                                                     "\nQ1:", Q1,
                                                     "\nMedian:", Median,
                                                     "\nQ3:", Q3,
                                                     "\nMax:", Max)),
            vjust = 0, size = 2, color = "black") +
  labs(title = "Distribution of Number of Hotel Rooms Occupied",
       y = "Number of Occupied Hotel Rooms") +
  scale_y_continuous(limits = c(0,4e+6))+
  theme(axis.title.x = element_blank())
```

#### 5.1.2.5.5 Removing *date* variable

We remove the "date" variable to keep the data more tidy for further analysis.

```{r}
tourism <- tourism_wider %>%
  select(-date)
```

#### 5.1.2.6 Saving as a new rds file

We save the cleaned data as a new rds file:

```{r}
#| eval: false
tourism_cleaned <- write_rds(tourism,"data/rds/tourism_cleaned.rds")
```

```{r}
tourism_cleaned <- read_rds("data/rds/tourism_cleaned.rds")
```

```{r}
#| eval: false
#| echo: false
# to remove when cleaning up
grouped <- tourism_cleaned %>%
  group_by(year_month, province_eng, region_eng) %>%
  summarize(median_tot_revenue = median(revenue_all, na.rm = TRUE),
            median_foreign_revenue = median(revenue_foreign, na.rm = TRUE),
            median_thai_revenue = median(revenue_thai, na.rm = TRUE),
            median_tot_tourist = median(no_tourist_all, na.rm = TRUE),
            median_tot_foreign = median(no_tourist_foreign, na.rm = TRUE),
            median_tot_thai = median(no_tourist_thai, na.rm = TRUE),
            median_occup_rate = median(ratio_tourist_stay, na.rm = TRUE),
            median_occup_no = median(no_tourist_stay, na.rm = TRUE),
            .groups = 'drop')

print(head(grouped))
```

### 5.1.3 Creating a data frame for spatial analysis

```{r}
tourism_cleaned_spat <- tourism_cleaned %>%
  group_by(province_eng, region_eng) %>%
  summarize(median_tot_revenue = median(revenue_all, na.rm = TRUE),
            median_foreign_revenue = median(revenue_foreign, na.rm = TRUE),
            median_thai_revenue = median(revenue_thai, na.rm = TRUE),
            median_tot_tourist = median(no_tourist_all, na.rm = TRUE),
            median_tot_foreign = median(no_tourist_foreign, na.rm = TRUE),
            median_tot_thai = median(no_tourist_thai, na.rm = TRUE),
            median_occup_rate = median(ratio_tourist_stay, na.rm = TRUE),
            median_occup_no = median(no_tourist_stay, na.rm = TRUE),
            .groups = 'drop')
```

#### 5.1.3.1 Saving as a new rds file

We save the file as a new rds file:

```{r}
#| eval: false
tourism_cleaned_spat <- write_rds(tourism_cleaned_spat,"data/rds/tourism_cleaned_spat.rds")
```

```{r}
tourism_cleaned_spat <- read_rds("data/rds/tourism_cleaned_spat.rds")
```

### 5.1.4 Creating a data frame for temporal analysis

We plot the total revenue by year_month:

```{r}
tourism_cleaned_summary <- tourism_cleaned %>%
  mutate(year_month = as.character(year_month)) %>%
  group_by(year_month) %>%
  summarize(total_revenue = sum(revenue_all, na.rm = TRUE))

ggplot(tourism_cleaned_summary, aes(x = year_month, y = total_revenue)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Total Revenue by Year-Month", x = "Year-Month", y = "Total Revenue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Based on the distribution of total revenue across the year_month variable, it can be seen that temporally, we can split the data into 3 time periods, namely:

-   pre-COVID: Between Jan 2019 to Mar 2020

-   during COVID: Between Apr 2020 to Aug 2021

-   post-COVID: Between Sep 2021 to Feb 2023

```{r}
#| eval: false 
tourism_cleaned_temp <- tourism_cleaned %>%
  mutate(time_period = case_when(
    year_month >= "2019-01-01" & year_month <= "2020-03-01" ~ "Pre-COVID",
    year_month >= "2020-04-01" & year_month <= "2021-08-01" ~ "During-COVID",
    year_month >= "2021-09-01" & year_month <= "2023-02-01" ~ "Post-COVID",
    TRUE ~ NA_character_))
```

```{r}
#| eval: false 
tourism_cleaned_temp <- tourism_cleaned_temp %>%
  group_by(province_eng,time_period) %>%
  summarize(median_tot_revenue = median(revenue_all, na.rm = TRUE),
            median_foreign_revenue = median(revenue_foreign, na.rm = TRUE),
            median_thai_revenue = median(revenue_thai, na.rm = TRUE),
            median_tot_tourist = median(no_tourist_all, na.rm = TRUE),
            median_tot_foreign = median(no_tourist_foreign, na.rm = TRUE),
            median_tot_thai = median(no_tourist_thai, na.rm = TRUE),
            median_occup_rate = median(ratio_tourist_stay, na.rm = TRUE),
            median_occup_no = median(no_tourist_stay, na.rm = TRUE),
            .groups = 'drop')
```

#### 5.1.4.1 Saving as a new rds file

We save the file as a new rds file:

```{r}
#| eval: false 
tourism_cleaned_temp <- write_rds(tourism_cleaned_temp,"data/rds/tourism_cleaned_temp.rds")
```

```{r}
tourism_cleaned_temp <- read_rds("data/rds/tourism_cleaned_temp.rds")
```

### 5.2 Thailand Subnational Administrative Boundaries

### 5.2.1 Importing the shapefile

The code chunk below uses `st_read()` of **sf** package to import the Thailand Subnational Administrative Boundaries shapefile into R. There are a few different files representing different levels of administrative boundaries - level 0 (country), level 1 (province), level 2 (district) and level 3 (sub-district, tambon). As we are only interested in province level administrative boundaries, we will just load the file corresponding to level 1.

The imported shapefile will be a **simple features** **object** of **sf**.

```{r}
#| eval: false
province <- st_read(dsn = "data/rawdata",
                    layer = "tha_admbnda_adm1_rtsd_20220121")
```

We note that the simple features data has a multipolygon geometry and has 77 features and 16 fields. It is in WGS84 geographic coordinate system.

### 5.2.2 Removing the unwanted variables

Of the fields available, only "ADM1_EN" and "geometry" are essential hence the following code chunk keeps only these two variables in the simple features object:

```{r}
#| eval: false
province <- province %>%
  select(ADM1_EN)
```

### 5.2.3 Checking the name of the provinces

As we will be joining the *province* simple features object and the attribute data from *tourism_cleaned* using the province names (ADM1_EN in *province* simple features object and province_eng in *tourism_cleaned* dataframe), it is important to check through the naming of the provinces to ensure that they all match up.

We extract the unique province names from both *tourism_cleaned* and *province:*

```{r}
#| eval: false
unique_tour_prov <- tourism_cleaned %>%
  distinct(province_eng)
```

```{r}
#| eval: false
unique_shp_prov <- province %>%
  distinct(ADM1_EN)
```

We then combine via a full join and read through the list of province names for discrepancies:

```{r}
#| eval: false
combined_prov <- full_join(unique_shp_prov,unique_tour_prov,
                           by = c("ADM1_EN"="province_eng"))
```

```{r}
#| eval: false
#| echo: false
combined_prov <- write_rds(combined_prov,"data/rds/combined_prov.rds")
```

```{r}
#| echo: false
combined_prov <- read_rds("data/rds/combined_prov.rds")
```

```{r}
combined_prov <- combined_prov %>%
  arrange(ADM1_EN)

combined_prov
```

We note repeated entries for eight provinces which are spelt differently in the original *province* sf object vs *tourism_cleaned* dataframe:

-   Buri Ram vs Buriram

-   Chai Nat vs Chainat

-   Chon Buri vs Chonburi

-   Lop Buri vs Lopburi

-   Nong Bua Lam Phu vs Nong Bua Lamphu

-   Phangnga vs Phang Nga

-   Prachin Buri vs Prachinburi

-   Si Sa Ket vs Sisaket

#### 5.2.3.1 Adjusting the naming of provinces in *province* sf object

We utilise the following code chunk to adjust the naming of the eight provinces to be aligned with the naming in the *tourism_cleaned* dataframe to faciliate relational join in subsequent analysis. We also rename "ADM1_EN" to "province_eng" to faciliate the creation of timeseries cube in subsequent analysis.

```{r}
#| eval: false
province <- province %>%
  mutate(ADM1_EN = case_when(
    ADM1_EN == "Buri Ram" ~ "Buriram",
    ADM1_EN == "Chai Nat" ~ "Chainat",
    ADM1_EN == "Chon Buri" ~ "Chonburi",
    ADM1_EN == "Lop Buri" ~ "Lopburi",
    ADM1_EN == "Nong Bua Lam Phu" ~ "Nong Bua Lamphu",
    ADM1_EN == "Phangnga" ~ "Phang Nga",
    ADM1_EN == "Prachin Buri" ~ "Prachinburi",
    ADM1_EN == "Si Sa Ket" ~ "Sisaket",
    TRUE ~ ADM1_EN)) %>%
  rename(province_eng = ADM1_EN)
```

We save this as new rds file to avoid reloading the original datafile above:

```{r}
#| eval: false 
province <- write_rds(province,"data/rds/province.rds")
```

```{r}
province <- read_rds("data/rds/province.rds")
```

### 5.3 Performing relational join

### 5.3.1 Relational join with *tourism_cleaned* data frame

We then perform a left relational join to update the *province* sf object with the attribute fields of the *tourism_cleaned* data frame:

```{r}
combined_prov_tourism <- left_join(province,tourism_cleaned)
```

```{r}
glimpse(combined_prov_tourism)
```

We note that the *combined_prov_tourism* data has the same number of rows, 3848 rows, as the original *tourism_cleaned* data frame indicating that the cleaning up of the different province spellings was done accurately.

#### 5.3.1.1 Saving as a new rds file

We save the combined file as a new rds file and load it into the R environment for further analysis:

```{r}
#| eval: false
combined_data <- write_rds(combined_prov_tourism,"data/rds/combined_prov_tourism.rds")
```

```{r}
combined_data <- read_rds("data/rds/combined_prov_tourism.rds")
```

### 5.3.2 Relational join with *tourism_cleaned_spat* data frame

We also perform a left relational join to update the *province* sf object with the attribute fields of the *tourism_cleaned_spat* data frame:

```{r}
combined_tourism_spat <- left_join(province,tourism_cleaned_spat)
```

```{r}
glimpse(combined_tourism_spat)
```

#### 5.3.2.1 Saving as a new rds file

We save the combined file as a new rds file and load it into the R environment for further analysis:

```{r}
#| eval: false 
combined_data_spat <- write_rds(combined_tourism_spat,"data/rds/combined_data_spat.rds")
```

```{r}
combined_data_spat <- read_rds("data/rds/combined_data_spat.rds")
```

### 5.3.3 Relational join with *tourism_cleaned_temp* data frame

We also perform a left relational join to update the *province* sf object with the attribute fields of the *tourism_cleaned_temp* data frame:

```{r}
combined_tourism_temp <- left_join(province,tourism_cleaned_temp)
```

```{r}
glimpse(combined_tourism_temp)
```

#### 5.3.3.1 Saving as a new rds file

We save the combined file as a new rds file and load it into the R environment for further analysis:

```{r}
#| eval: false  
combined_data_temp <- write_rds(combined_tourism_temp,"data/rds/combined_data_temp.rds")
```

```{r}
combined_data_temp <- read_rds("data/rds/combined_data_temp.rds")
```

### 5.4 Creating a time series cube

We use [spacetime()](https://sfdep.josiahparry.com/articles/spacetime-s3.html) of sfdep to create a spatio-temporal cube:

```{r}
spt <- spacetime(
  tourism_cleaned,
  province,
  .loc_col = "province_eng",
  .time_col = "year_month"
)
```

### 5.4.1 Verifying space-time cube object

We utilise the following code chunk to verify if *spt* is indeed a space-time cube object:

```{r}
is_spacetime_cube(spt)
```

### 5.4.2 Saving as a new rds file

We save *spt* as a new rds file and load it into the R environment for further analysis:

```{r}
#| eval: false
spt <- write_rds(spt,"data/rds/spt.rds")
```

```{r}
spt <- read_rds("data/rds/spt.rds")
```

## 6. Key Indicators of the Tourism Economy of Thailand

From the above data, we note that there are several possible key indicators of the tourism economy of Thailand to analyse, namely: (i) Total revenue, (ii) Revenue generated from foreign tourists, (iii) Revenue generated from local/Thai tourists, (iv) Total number of tourists, (v) Number of foreign tourists, (vi) Number of local/Thai tourists and (vii) Rate of tourists who stay overnight. For our analysis, we will focus on the following indicators for reasons stated below:

\(i\) **Total revenue:** Revenue generated from both foreign and local tourists can indicate how well Thai's tourism economy is performing.

\(ii\) **Number of foreign tourists:** Based on [literature](https://www.adb.org/sites/default/files/linked-documents/54177-001-sd-12.pdf), Thailand recorded a total THB1.9 trillion receipts from foreign tourists (65% of the sector’s receipts) or 11.5% of its GDP in 2019. The daily foreign tourist spending was around \$192 per person, more than double of domestic tourists spending. The number of foreign tourists will hence be a strong indicator of how well the Thai tourism economy is performing i.e. the greater number of tourists, coupled with their higher propensity to spend, would be indicative of a booming tourism economy.

\(iii\) **Rate of tourists who stay overnight:** A higher rate of tourists who stay overnight can be indicative of how well the tourism economy is performing as tourists who stay for longer periods in Thailand are likely to incur more expenditure i.e. via spending on accommodation, more activities.

### 6.1 Visualising Indicators of Tourism Economy

We briefly visualise the distribution of these indicators:

::: panel-tabset
## Total Revenue

```{r}
tmap_mode("plot")
tm_shape(combined_data_spat)+
  tm_fill("median_tot_revenue",
          style = "quantile",
          title = "Median Total Revenue")+
  tm_borders(alpha = 0.5)+
  tm_layout(main.title = "Distribution of Median Total Revenue (Quantile classification)",main.title.position = "center",
            main.title.size = 0.5,
            legend.height = 0.45,
            legend.width = 0.35,
            legend.text.size = 0.5,
            legend.outside.size = 0.5)+
  tm_text("province_eng",size = 0.3)
```

## Number of Foreign Tourists

```{r}
tmap_mode("plot")
tm_shape(combined_data_spat)+
  tm_fill("median_tot_foreign",
          style = "quantile",
          title = "Median Number of Foreign Tourists")+
  tm_borders(alpha = 0.5)+
  tm_layout(main.title = "Distribution of Median Number of Foreign Tourists (Quantile classification)",main.title.position = "center",
            main.title.size = 0.5,
            legend.height = 0.45,
            legend.width = 0.35,
            legend.text.size = 0.5,
            legend.outside.size = 0.5)+
  tm_text("province_eng",size = 0.3)
```

## Rate of tourists who stay overnight

```{r}
tmap_mode("plot")
tm_shape(combined_data_spat)+
  tm_fill("median_occup_rate",
          style = "quantile",
          title = "Median Rate of Overnights Tourists")+
  tm_borders(alpha = 0.5)+
  tm_layout(main.title = "Distribution of Median Rate of Overnights Tourists (Quantile classification)",main.title.position = "center",
            main.title.size = 0.5,
            legend.height = 0.45,
            legend.width = 0.35,
            legend.text.size = 0.5,
            legend.outside.size = 0.5)+
  tm_text("province_eng",size = 0.3)
```
:::

## 7. Determining independence from space

### 7.1 Computing Distance-based Spatial Weights

There are two main ways of computing spatial weights - contiguity spatial weights or distance-based spatial weights. Based on the plot of the provinces of Thailand, we note that it would not be appropriate to utilise contiguity spatial weights as there would be provinces with too little neighbours. We will hence utilise distance-based spatial weights.

### 7.1.1 Generating centroids

A connectivity graph takes a point and displays a line to each neighbouring point. As we are working with multipolygons, we will need to get points to make connectivity graphs. As such, we will need to calculate centroids for each province.

```{r}
#| eval: false
centroids <- combined_data_spat %>%
  st_centroid() %>%  
  select(province_eng, geometry)
```

### 7.1.2 Saving as a new rds file

We save *centroids* as a new rds file and load it into the R environment for further analysis:

```{r}
#| eval: false
centroids <- write_rds(centroids,"data/rds/centroids.rds")
```

```{r}
centroids <- read_rds("data/rds/centroids.rds")
```

### 7.1.3 Visualising the centroids

We visualise where these centroids are:

```{r}
tmap_mode('plot')
tm_shape(province) +
  tm_fill()+
  tm_borders()+
  tm_shape(centroids)+
  tm_dots(col = "darkblue", size = 0.2, alpha = 0.5, title = "Centroids") +
  tm_text("province_eng", size = 0.5, col = "black") +
  tm_layout(main.title = "Centroids of Provinces", main.title.size = 0.5) 
```

We note that none of the centroids generated are in the water and are all located within the regions of provinces. This indicates that the centroids are appropriate for use and do not need to be shifted.

### 7.1.4 Converting centroids to coordinates

We convert the centroids to coordinates using the following code chunk to facilitate further analysis:

```{r}
coords <- st_coordinates(centroids)
```

### 7.1.5 Computing adaptive distance weight matrix

Given that the polygons differ in size, we will utilise adaptive distance weight matrix.

```{r}
knn6 <- st_knn(coords,k=6)
knn6
```

We display the content of the matrix using the code chunk below:

```{r}
str(knn6)
```

Based on the output from above, we note that each province has six neighbours.

```{r}
weights <- st_weights(knn6)
```

### 7.1.6 Plotting distance-based neighbours

```{r}
plot(combined_data_spat$geometry,border="lightgrey")
plot(knn6,coords,pch = 19, cex = 0.6, add = TRUE, col = "red")
```

### 7.2 Global Measures of Spatial Autocorrelation: Moran's I

Moran's I describe how features differ from the values in the study area as a whole.

H0 null hypothesis: There is no spatial autocorrelation in the indicator of tourism i.e. observed values are spatially randomly distributed and spatial location of the values have no influence on their similarity

H1 alternative hypothesis: There is spatial autocorrelation in the indicator of interest.

We set the confidence interval to be at 95%.

::: panel-tabset
## Total Revenue

```{r}
set.seed(1234)
moran_result <- global_moran_perm(combined_data_spat$median_tot_revenue,
                                  knn6,
                                  weights,
                                  nsim = 1999)
moran_result
```

We run a histogram of the results to determine if sufficient simulations have been run i.e. if the distribution of results seem to be close to a normal distribution. Based on the output below, nsim = 1999 seems to be sufficient.

```{r}
hist(moran_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I")

abline(v=0,
       col="red")
```

Based on the results above, we note that the p-value is 0.615, higher than the p-value of 0.05. This indicates that the p-value is not significant. There is insufficient evidence to reject the null hypothesis at the 95% confidence level.

Further, the Moran’s I value is close to zero and negative, which indicates that total revenue seem to occur randomly across provinces.

## Number of foreign tourists

```{r}
set.seed(1234)
moran_result <- global_moran_perm(combined_data_spat$median_tot_foreign,
                                  knn6,
                                  weights,
                                  nsim = 1999)
moran_result
```

```{r}
hist(moran_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I")

abline(v=0,
       col="red")
```

Based on the results above, we note that the p-value is 0.22, higher than the p-value of 0.05. This indicates that the p-value is not significant. There is insufficient evidence to reject the null hypothesis at the 95% confidence level.

Further, the Moran’s I value is positive but close to zero, which indicates that total revenue seem to occur randomly across provinces.

## Rate of tourists who stay overnight

```{r}
set.seed(1234)
moran_result <- global_moran_perm(combined_data_spat$median_occup_rate,
                                  knn6,
                                  weights,
                                  nsim = 1999)
moran_result
```

```{r}
hist(moran_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I")

abline(v=0,
       col="red")
```

Based on the results above, we note that the p-value is 0.022, smaller than the p-value of 0.05. This indicates that the p-value is significant. There is sufficient evidence to reject the null hypothesis at the 95% confidence level.

Further, the Moran’s I value is positive (0.14629) which indicates that the indicator (rate of tourists who stay overnight) has a moderate degree of positive spatial autocorrelation, that it is not randomly distributed across provinces and that nearby provinces are likely to have similar values.
:::

### 7.3 Global Measures of Spatial Autocorrelation: Geary's c

Similar to Moran's I, Geary's c is also a measure of spatial autocorrelation however it focuses more on the differences between immediate neigbours.

H0 null hypothesis: There is no spatial autocorrelation in the indicator of tourism i.e. observed values are spatially randomly distributed and spatial location of the values have no influence on their dissimilarity

H1 alternative hypothesis: There is spatial autocorrelation in the indicator of interest.

We set the confidence interval to be at 95%.

::: panel-tabset
## Total revenue

```{r}
set.seed(1234)
geary_result <- global_c_perm(combined_data_spat$median_tot_revenue,
                                  knn6,
                                  weights,
                                  nsim = 1999)
geary_result
```

We run a histogram of the results to determine if sufficient simulations have been run i.e. if the distribution of results seem to be close to a normal distribution. Based on the output below, nsim = 1999 seems to be sufficient.

```{r}
hist(geary_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Geary's c")

abline(v=1,
       col="red")
```

Based on the results above, we note that the p-value is 0.9595, higher than the p-value of 0.05. This indicates that the p-value is not significant. There is insufficient evidence to reject the null hypothesis at the 95% confidence level.

Like the result from Moran's I, the Geary's c result also indicates that total revenue seem to occur randomly across provinces.

## Number of foreign tourists

```{r}
set.seed(1234)
geary_result <- global_c_perm(combined_data_spat$median_tot_foreign,
                                  knn6,
                                  weights,
                                  nsim = 1999)
geary_result
```

```{r}
hist(geary_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Geary's c")

abline(v=1,
       col="red")
```

Based on the results above, we note that the p-value is 0.9575, higher than the p-value of 0.05. This indicates that the p-value is not significant. There is insufficient evidence to reject the null hypothesis at the 95% confidence level.

Like the result from Moran's I, the Geary's c result also indicates that number of foreign tourists seem to occur randomly across provinces.

## Rate of tourists who stay overnight

```{r}
set.seed(1234)
geary_result <- global_c_perm(combined_data_spat$median_occup_rate,
                                  knn6,
                                  weights,
                                  nsim = 1999)
geary_result
```

```{r}
hist(geary_result$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Geary's c")

abline(v=1,
       col="red")
```

Based on the results above, we note that the p-value is 0.008, smaller than the p-value of 0.05. This indicates that the p-value is significant. There is sufficient evidence to reject the null hypothesis at the 95% confidence level.

Further, the Geary's c value is slightly less than 1 (0.82128) which indicates that the indicator (rate of tourists who stay overnight) has a moderate degree of positive spatial autocorrelation, that it is not randomly distributed across provinces and that nearby provinces are likely to have similar values. This is a similar finding to the Moran's I result above.
:::

## 8. Determining independence from space and time
