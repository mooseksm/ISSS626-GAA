{
  "hash": "8678460945998214f4a83d21bbefc065",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-home Exercise 1\"\nauthor: \"Kock Si Min\"\ndate: September 2, 2024\ndate-modified: \"last-modified\"\ntoc: true\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  warning: false\n  message: false\n---\n\n\n## 1.2 Data Acquisition\n\n## 1.3 Installing and Launching R packages\n\n-   [**sf**](https://r-spatial.github.io/sf/) for importing, managing, and processing vector-based geospatial data, and\n\n-   [**spatstat**](https://spatstat.org/), which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer\n\n-   [**raster**](https://cran.r-project.org/web/packages/raster/) which reads, writes, manipulates, analyses and model of gridded spatial data (i.e.Â raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\n\n-   [**maptools**](https://cran.r-project.org/web/packages/maptools/index.html) which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert *Spatial* objects into *ppp* format of **spatstat**.\n\n-   [**tmap**](https://cran.r-project.org/web/packages/tmap/index.html) which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using [leaflet](https://leafletjs.com/) API.\n\n-   [**tidyverse**](https://www.tidyverse.org/) for performing data science tasks such as importing, wrangling and visualising data.\n\n-   [**spNetwork**](https://cran.r-project.org/web/packages/spNetwork/index.html) which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It can also be used to build spatial matrices (\\`listw' objects like in 'spdep' package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\nThe packages are loaded with the following code chunk:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf,spatstat,raster,tmap,tidyverse,spNetwork)\n```\n:::\n\n\n## Importing Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrdacc_sf <- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %>%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %>%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %>%\n  st_transform(crs = 32647)\n```\n:::\n\n\n-   Note that **incident_datetime** and **report_datetime** are kept in **datetime field**, so that easier for manipulation later on i.e. extracting day of week, time of day using [lubridate](https://lubridate.tidyverse.org/reference/index.html). Can be useful in determining the occurrence of incidents at a particular timing i.e. peak hour.\n\n-   when file is read in sf, can easily convert to ppp\n\n-   dissecting the code - it comes in 4 chunks:\n\n    -   the first to load the file\n\n    -   the second to filter missing values\n\n    -   the third is to get the coordinates and transform the crs\n\n    -   transform it\n\n-   without the filter function in between, running the code will give you error, this is because there are missing values for longitude and latitude\n\n## In-class notes from Prof Kam:\n\n-   An example is shown below to extract month and day of the *incident_datetime*:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrdacc_sf <- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %>%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 32467) %>%\n  mutate(Month_num = month(incident_datetime)) %>%\n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %>%\n  mutate(dayofweek = day(incident_datetime))\n```\n:::\n\n\n-   The 2nd [month](https://lubridate.tidyverse.org/reference/month.html) line is more specific and has order since its a factor.\n-   WGS 84 got [32467](https://epsg.io/32647) and [324648](https://epsg.io/32648) - take a good look at it before deciding which is the right one (above is just an example)\n-   note that there's hidden problem inside the data i.e. missing values (can mutate and omit missing values in the code above)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(rdacc_sf,\"data/rds/rdacc_sf.rds\")\n```\n:::\n\n\n-   write_rds will take care of all the objects within the dataset; once you got this file \"#\\| eval: false\" to avoid running the data wrangling code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc <- read_rds(\"data/rds/rdacc_sf.rds\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}